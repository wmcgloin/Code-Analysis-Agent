{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import networkx as nx\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def plot_network(\n",
    "#     G,\n",
    "#     node_size=1000,\n",
    "#     node_color=\"skyblue\",\n",
    "#     edge_color=\"gray\",\n",
    "#     font_size=10,\n",
    "#     title=\"Network Graph\",\n",
    "#     figsize=(12, 8),\n",
    "#     with_labels=True,\n",
    "#     layout=\"spring\",\n",
    "#     palette=\"husl\",\n",
    "#     k=0.1,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Plot a network graph with seaborn-style aesthetics.\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     G : networkx.Graph\n",
    "#         The network graph to visualize\n",
    "#     node_size : int or list\n",
    "#         Size of nodes (can be a single value or list for different sizes)\n",
    "#     node_color : str or list\n",
    "#         Color of nodes (can be a single value or list for different colors)\n",
    "#     edge_color : str\n",
    "#         Color of edges\n",
    "#     font_size : int\n",
    "#         Size of node labels\n",
    "#     title : str\n",
    "#         Title of the plot\n",
    "#     figsize : tuple\n",
    "#         Figure size (width, height)\n",
    "#     with_labels : bool\n",
    "#         Whether to show node labels\n",
    "#     layout : str\n",
    "#         Type of layout ('spring', 'circular', 'random', 'shell')\n",
    "#     palette : str\n",
    "#         Seaborn color palette to use if node_color is not specified\n",
    "\n",
    "#     Returns:\n",
    "#     --------\n",
    "#     fig, ax : tuple\n",
    "#         Matplotlib figure and axis objects\n",
    "#     \"\"\"\n",
    "#     # Set the style\n",
    "#     sns.set_style(\"whitegrid\")\n",
    "\n",
    "#     # Create figure\n",
    "#     fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "#     # Choose layout\n",
    "#     layouts = {\n",
    "#         \"spring\": nx.spring_layout,\n",
    "#         \"circular\": nx.circular_layout,\n",
    "#         \"random\": nx.random_layout,\n",
    "#         \"shell\": nx.shell_layout,\n",
    "#     }\n",
    "#     pos = layouts.get(layout, nx.spring_layout)(G,k)\n",
    "\n",
    "#     # If node_color is not specified, use seaborn palette\n",
    "#     if isinstance(node_color, str) and node_color == \"skyblue\":\n",
    "#         colors = sns.color_palette(palette, n_colors=len(G.nodes()))\n",
    "#     else:\n",
    "#         colors = node_color\n",
    "\n",
    "#     # Draw the network\n",
    "#     nx.draw(\n",
    "#         G,\n",
    "#         pos,\n",
    "#         node_color=colors,\n",
    "#         node_size=node_size,\n",
    "#         edge_color=edge_color,\n",
    "#         with_labels=with_labels,\n",
    "#         font_size=font_size,\n",
    "#         font_weight=\"bold\",\n",
    "#         ax=ax,\n",
    "#     )\n",
    "\n",
    "#     # Add title\n",
    "#     plt.title(title, fontsize=font_size + 4, pad=20)\n",
    "\n",
    "#     return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: USING langchain_experimental.graph_transformers main.\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "# llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "\n",
    "# from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "# # TypedDict\n",
    "# class Json(TypedDict):\n",
    "#     \"\"\"Json to return.\"\"\"\n",
    "\n",
    "#     setup: Annotated[dict, ..., \"The setup of the dict\"]\n",
    "#     depth: Annotated[int, ..., \"How many layers deep the dict is.\"]\n",
    "\n",
    "\n",
    "# from langchain_core.messages import HumanMessage, SystemMessage\n",
    "# from langchain_core.documents import Document\n",
    "\n",
    "# text = \"\"\"\n",
    "# Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "# She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "# Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "# She was, in 1906, the first woman to become a professor at the University of Paris.\n",
    "# \"\"\"\n",
    "\n",
    "# from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "# llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "# documents = [Document(page_content=text)]\n",
    "# logger.info(f\"documents:{documents}\")\n",
    "# graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "# for i, doc in enumerate(graph_documents):\n",
    "#     logger.info(f\"document #{i+1}\")\n",
    "#     nodes = doc.nodes\n",
    "#     relationships = doc.relationships\n",
    "#     for n in nodes:\n",
    "#         logger.info(f\"Nodes:{n}\")\n",
    "#     for r in relationships:\n",
    "#         logger.info(f\"Relationships:{r}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from plot_graph import plot_network\n",
    "# import networkx as nx\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# nodes = [str(node) for node in graph_documents[0].nodes]\n",
    "# relationships = [\n",
    "#     (str(rel.source), str(rel.target)) for rel in graph_documents[0].relationships\n",
    "# ]\n",
    "\n",
    "# G = nx.DiGraph()\n",
    "# G.add_nodes_from(nodes)\n",
    "# G.add_edges_from(relationships)\n",
    "\n",
    "# custom_colors = sns.color_palette(\"Set2\", n_colors=len(G.nodes()))\n",
    "# node_sizes = [3000 if d > 5 else 1000 for v, d in G.degree()]\n",
    "\n",
    "# fig, ax = plot_network(\n",
    "#     G,\n",
    "#     node_size=node_sizes,\n",
    "#     node_color=custom_colors,\n",
    "#     edge_color=\"#cccccc\",\n",
    "#     font_size=12,\n",
    "#     layout=\"spring\",\n",
    "#     palette=\"Set2\",\n",
    "# )\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'assignment-2-mcdonald-s'...\n",
      "Updating files:  27% (52/189)\n",
      "Updating files:  28% (53/189)\n",
      "Updating files:  29% (55/189)\n",
      "Updating files:  30% (57/189)\n",
      "Updating files:  31% (59/189)\n",
      "Updating files:  32% (61/189)\n",
      "Updating files:  33% (63/189)\n",
      "Updating files:  34% (65/189)\n",
      "Updating files:  35% (67/189)\n",
      "Updating files:  36% (69/189)\n",
      "Updating files:  37% (70/189)\n",
      "Updating files:  38% (72/189)\n",
      "Updating files:  39% (74/189)\n",
      "Updating files:  40% (76/189)\n",
      "Updating files:  41% (78/189)\n",
      "Updating files:  42% (80/189)\n",
      "Updating files:  43% (82/189)\n",
      "Updating files:  44% (84/189)\n",
      "Updating files:  45% (86/189)\n",
      "Updating files:  46% (87/189)\n",
      "Updating files:  47% (89/189)\n",
      "Updating files:  48% (91/189)\n",
      "Updating files:  49% (93/189)\n",
      "Updating files:  50% (95/189)\n",
      "Updating files:  51% (97/189)\n",
      "Updating files:  52% (99/189)\n",
      "Updating files:  53% (101/189)\n",
      "Updating files:  54% (103/189)\n",
      "Updating files:  55% (104/189)\n",
      "Updating files:  56% (106/189)\n",
      "Updating files:  57% (108/189)\n",
      "Updating files:  58% (110/189)\n",
      "Updating files:  59% (112/189)\n",
      "Updating files:  60% (114/189)\n",
      "Updating files:  61% (116/189)\n",
      "Updating files:  62% (118/189)\n",
      "Updating files:  63% (120/189)\n",
      "Updating files:  64% (121/189)\n",
      "Updating files:  65% (123/189)\n",
      "Updating files:  65% (124/189)\n",
      "Updating files:  66% (125/189)\n",
      "Updating files:  67% (127/189)\n",
      "Updating files:  68% (129/189)\n",
      "Updating files:  69% (131/189)\n",
      "Updating files:  70% (133/189)\n",
      "Updating files:  71% (135/189)\n",
      "Updating files:  72% (137/189)\n",
      "Updating files:  73% (138/189)\n",
      "Updating files:  74% (140/189)\n",
      "Updating files:  75% (142/189)\n",
      "Updating files:  76% (144/189)\n",
      "Updating files:  77% (146/189)\n",
      "Updating files:  78% (148/189)\n",
      "Updating files:  79% (150/189)\n",
      "Updating files:  80% (152/189)\n",
      "Updating files:  81% (154/189)\n",
      "Updating files:  82% (155/189)\n",
      "Updating files:  83% (157/189)\n",
      "Updating files:  84% (159/189)\n",
      "Updating files:  85% (161/189)\n",
      "Updating files:  86% (163/189)\n",
      "Updating files:  87% (165/189)\n",
      "Updating files:  88% (167/189)\n",
      "Updating files:  89% (169/189)\n",
      "Updating files:  90% (171/189)\n",
      "Updating files:  91% (172/189)\n",
      "Updating files:  92% (174/189)\n",
      "Updating files:  93% (176/189)\n",
      "Updating files:  94% (178/189)\n",
      "Updating files:  95% (180/189)\n",
      "Updating files:  96% (182/189)\n",
      "Updating files:  97% (184/189)\n",
      "Updating files:  98% (186/189)\n",
      "Updating files:  99% (188/189)\n",
      "Updating files: 100% (189/189)\n",
      "Updating files: 100% (189/189), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/DSAN6700-24Fall/assignment-2-mcdonald-s.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with sample langchain code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── src/\n",
      "│   ├── deduplication/\n",
      "│   │   ├── bloom_filter.py\n",
      "│   │   ├── dedup.py\n",
      "│   │   ├── LSH.py\n",
      "│   │   ├── LSHForest.py\n",
      "│   │   ├── LSHImproved.py\n",
      "│   │   ├── __init__.py\n",
      "│   │   ├── __main__.py\n",
      "│   ├── utils/\n",
      "│   │   ├── use_cases.py\n",
      "│   │   ├── utils.py\n",
      "│   │   ├── visualizations.py\n",
      "│   │   ├── visualization_lsh.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def generate_repo_tree(repo_path, indent=\"\"):\n",
    "    tree_string = \"\"\n",
    "    for root, dirs, files in os.walk(repo_path):\n",
    "        # Filter out __pycache__ and hidden directories\n",
    "        dirs[:] = [d for d in dirs if d != \"__pycache__\" and not d.startswith(\".\")]\n",
    "        files = [f for f in files if not f.startswith(\".\")]\n",
    "\n",
    "        level = root.replace(repo_path, \"\").count(os.sep)\n",
    "        indent = \"│   \" * level + \"├── \"  # Formatting the tree\n",
    "        tree_string += f\"{indent}{os.path.basename(root)}/\\n\"\n",
    "\n",
    "        sub_indent = \"│   \" * (level + 1) + \"├── \"\n",
    "        for file in files:\n",
    "            tree_string += f\"{sub_indent}{file}\\n\"\n",
    "\n",
    "    return tree_string\n",
    "\n",
    "# Set your repo path\n",
    "repo_path = \"./assignment-2-mcdonald-s/src\"  # Change this to your cloned repo path\n",
    "\n",
    "# Generate tree and store as string\n",
    "repo_tree_string = generate_repo_tree(repo_path)\n",
    "\n",
    "# Print the repo tree\n",
    "print(repo_tree_string)\n",
    "\n",
    "# Store it as a variable to feed into an LLM\n",
    "llm_input = f\"Here is the repository structure:\\n{repo_tree_string}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the LSH.py file\n",
    "current_file = \"src/deduplication/LSH.py\"\n",
    "lsh_file_path = f\"assignment-2-mcdonald-s/{current_file}\"\n",
    "\n",
    "# Read the contents of the file\n",
    "with open(lsh_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    lsh_code = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-17 22:23:01,513] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashlib which is a package is imported and used in LSH which is a class.  \n",
      "re which is a package is imported and used in LSH which is a class.  \n",
      "defaultdict which is a package is imported and used in LSH which is a class.  \n",
      "combinations which is a package is imported and used in LSH which is a class.  \n",
      "clean_document which is a function is imported from utils.utils and is used in compute_minhash_signatures which is a method.  \n",
      "shingle which is a function is imported from utils.utils and is used in compute_minhash_signatures which is a method.  \n",
      "minhash which is a function is imported from utils.utils and is used in compute_minhash_signatures which is a method.  \n",
      "Parallel which is a package is imported from joblib and is used in compute_minhash_signatures which is a method.  \n",
      "delayed which is a package is imported from joblib and is used in compute_minhash_signatures which is a method.  \n",
      "\n",
      "LSH which is a class is defined in module LSH.  \n",
      "__init__ is a method defined in LSH which is a class.  \n",
      "remove_duplicates is a method defined in LSH which is a class.  \n",
      "compute_minhash_signatures is a method defined in LSH which is a class.  \n",
      "banding is a method defined in LSH which is a class.  \n",
      "num_hashes is a parameter of __init__ which is a method.  \n",
      "num_bands is a parameter of __init__ which is a method.  \n",
      "rows_per_band is a parameter of __init__ which is a method.  \n",
      "k is a parameter of __init__ which is a method.  \n",
      "doc_id is a parameter of remove_duplicates which is a method.  \n",
      "doc is a parameter of remove_duplicates which is a method.  \n",
      "docs is a parameter of compute_minhash_signatures which is a method.  \n",
      "signatures is a parameter of banding which is a method.  \n",
      "sig is a variable in banding which is a method.  \n",
      "band_idx is a variable in banding which is a method.  \n",
      "start is a variable in banding which is a method.  \n",
      "band is a variable in banding which is a method.  \n",
      "doc_ids is a variable in banding which is a method.  \n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "    You are an expert in analyzing Python code and generating structured natural language descriptions for graph-based querying in Cypher. Given a Python codebase, extract meaningful relationships between functions, classes, parameters, and imported modules. \n",
    "    You will be given a repository tree structure and a specific file and a code of the specific file.\n",
    "    \n",
    "    Return the given code as natural language description suitable for cypher querying.\n",
    "    Only explain relationships between functions, classes, parameters, and imported modules.\n",
    "    Do not give explanations for the code logic or functionality.\n",
    "    Do not use adjectives and adverbs. \n",
    "    Only describe the code and do not give an overall summary.\n",
    "    Do not use ambiguous pronouns and use exact names in every description.\n",
    "    Explain each class, function, and variable separately and do not include explanations such as 'as mentioned before' or anything that refers to a previous explanation.\n",
    "\n",
    "    Each outermost class or method should be connected to the source file referred as modules\n",
    "        - Example(Class LSH is defined in module LSH, method deduplication is defined in Module LSH)\n",
    "    Each imported package should be connected to the function, method or class where it was used.\n",
    "\n",
    "    Use the structure so that the node id ad type are used in the format {id} which is a {type}.\n",
    "\n",
    "\n",
    "    Example Output (Structured Natural Language):\n",
    "    LSH is a module that defines the LSH which is a class, which consists of hash_function which is a method.\n",
    "    LSH which is a class inherits from BaseLSH which is a module.\n",
    "    numpy which is a package is imported and used in hash_function which is a method.\n",
    "    \n",
    "\n",
    "    Provide a structured response that allows for easy conversion into Cypher queries.\n",
    "    \"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        system_prompt\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        f'''\n",
    "        Tree:\n",
    "        {repo_tree_string}\n",
    "\n",
    "        Current File:\n",
    "        {current_file}\n",
    "\n",
    "        Code:\n",
    "        {lsh_code}\n",
    "        '''\n",
    "    ),\n",
    "]\n",
    "\n",
    "# structured_llm = llm.with_structured_output(Json)\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allowed_nodes = [\"Person\", \"Organization\", \"Location\", \"Award\", \"ResearchField\"]\n",
    "# allowed_relationships = [\n",
    "#     (\"Person\", \"SPOUSE\", \"Person\"),\n",
    "#     (\"Person\", \"AWARD\", \"Award\"),\n",
    "#     (\"Person\", \"WORKS_AT\", \"Organization\"),\n",
    "#     (\"Organization\", \"IN_LOCATION\", \"Location\"),\n",
    "#     (\"Person\", \"FIELD_OF_RESEARCH\", \"ResearchField\")\n",
    "# ]\n",
    "# node_properties=[\"birth_date\", \"death_date\"]\n",
    "# relationship_properties=[\"start_date\"]\n",
    "# props_defined = LLMGraphTransformer(\n",
    "#   llm=llm, \n",
    "#   allowed_nodes=allowed_nodes,\n",
    "#   allowed_relationships=allowed_relationships,\n",
    "#   node_properties=node_properties,\n",
    "#   relationship_properties=relationship_properties\n",
    "# )\n",
    "# data = await props_defined.aconvert_to_graph_documents(documents)\n",
    "# graph.add_graph_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-17 22:23:08,267] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:09,286] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:12,398] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:13,382] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:14,746] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:16,085] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:17,745] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:19,113] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:20,681] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:21,627] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:22,551] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:23,445] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:24,339] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:27,620] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:28,890] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:29,924] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:31,378] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:32,324] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:33,585] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:34,618] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:36,370] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:37,221] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:39,347] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:41,494] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:42,575] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:44,850] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-17 22:23:45,879] p18144 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=1000,\n",
    "    # chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        r\"\\n\\n\",\n",
    "        r\"\\n\",\n",
    "        r\"\\\\n\"\n",
    "    ],\n",
    "    is_separator_regex=True,\n",
    "    keep_separator=False,\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([response.content])\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "# llm_transformer_props = LLMGraphTransformer(\n",
    "#     llm=llm,\n",
    "#     allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "#     allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    "#     node_properties=[\"born_year\"],\n",
    "# )\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "# logger.info(f\"documents:{documents}\")\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='hashlib which is a package is imported and used in LSH which is a class.  '),\n",
       " Document(metadata={}, page_content='re which is a package is imported and used in LSH which is a class.  '),\n",
       " Document(metadata={}, page_content='defaultdict which is a package is imported and used in LSH which is a class.  '),\n",
       " Document(metadata={}, page_content='combinations which is a package is imported and used in LSH which is a class.  '),\n",
       " Document(metadata={}, page_content='clean_document which is a function is imported from utils.utils and is used in compute_minhash_signatures which is a method.  '),\n",
       " Document(metadata={}, page_content='shingle which is a function is imported from utils.utils and is used in compute_minhash_signatures which is a method.  '),\n",
       " Document(metadata={}, page_content='minhash which is a function is imported from utils.utils and is used in compute_minhash_signatures which is a method.  '),\n",
       " Document(metadata={}, page_content='Parallel which is a package is imported from joblib and is used in compute_minhash_signatures which is a method.  '),\n",
       " Document(metadata={}, page_content='delayed which is a package is imported from joblib and is used in compute_minhash_signatures which is a method.  '),\n",
       " Document(metadata={}, page_content='LSH which is a class is defined in module LSH.  '),\n",
       " Document(metadata={}, page_content='__init__ is a method defined in LSH which is a class.  '),\n",
       " Document(metadata={}, page_content='remove_duplicates is a method defined in LSH which is a class.  '),\n",
       " Document(metadata={}, page_content='compute_minhash_signatures is a method defined in LSH which is a class.  '),\n",
       " Document(metadata={}, page_content='banding is a method defined in LSH which is a class.  '),\n",
       " Document(metadata={}, page_content='num_hashes is a parameter of __init__ which is a method.  '),\n",
       " Document(metadata={}, page_content='num_bands is a parameter of __init__ which is a method.  '),\n",
       " Document(metadata={}, page_content='rows_per_band is a parameter of __init__ which is a method.  '),\n",
       " Document(metadata={}, page_content='k is a parameter of __init__ which is a method.  '),\n",
       " Document(metadata={}, page_content='doc_id is a parameter of remove_duplicates which is a method.  '),\n",
       " Document(metadata={}, page_content='doc is a parameter of remove_duplicates which is a method.  '),\n",
       " Document(metadata={}, page_content='docs is a parameter of compute_minhash_signatures which is a method.  '),\n",
       " Document(metadata={}, page_content='signatures is a parameter of banding which is a method.  '),\n",
       " Document(metadata={}, page_content='sig is a variable in banding which is a method.  '),\n",
       " Document(metadata={}, page_content='band_idx is a variable in banding which is a method.  '),\n",
       " Document(metadata={}, page_content='start is a variable in banding which is a method.  '),\n",
       " Document(metadata={}, page_content='band is a variable in banding which is a method.  '),\n",
       " Document(metadata={}, page_content='doc_ids is a variable in banding which is a method.  ')]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = response.content\n",
    "\n",
    "# from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "# llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "# documents = [Document(page_content=text)]\n",
    "# # logger.info(f\"documents:{documents}\")\n",
    "# graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-17 22:23:45,931] p18144 {406922825.py:2} INFO - document #1\n",
      "[2025-03-17 22:23:45,933] p18144 {406922825.py:6} INFO - Nodes:id='Hashlib' type='Package' properties={}\n",
      "[2025-03-17 22:23:45,934] p18144 {406922825.py:6} INFO - Nodes:id='Lsh' type='Class' properties={}\n",
      "[2025-03-17 22:23:45,935] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Lsh', type='Class', properties={}) target=Node(id='Hashlib', type='Package', properties={}) type='USES' properties={}\n",
      "[2025-03-17 22:23:45,936] p18144 {406922825.py:2} INFO - document #2\n",
      "[2025-03-17 22:23:45,937] p18144 {406922825.py:6} INFO - Nodes:id='Re' type='Package' properties={}\n",
      "[2025-03-17 22:23:45,938] p18144 {406922825.py:6} INFO - Nodes:id='Lsh' type='Class' properties={}\n",
      "[2025-03-17 22:23:45,939] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Lsh', type='Class', properties={}) target=Node(id='Re', type='Package', properties={}) type='IMPORTS' properties={}\n",
      "[2025-03-17 22:23:45,941] p18144 {406922825.py:2} INFO - document #3\n",
      "[2025-03-17 22:23:45,941] p18144 {406922825.py:6} INFO - Nodes:id='Defaultdict' type='Package' properties={}\n",
      "[2025-03-17 22:23:45,942] p18144 {406922825.py:6} INFO - Nodes:id='Lsh' type='Class' properties={}\n",
      "[2025-03-17 22:23:45,943] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Lsh', type='Class', properties={}) target=Node(id='Defaultdict', type='Package', properties={}) type='IMPORTS' properties={}\n",
      "[2025-03-17 22:23:45,944] p18144 {406922825.py:2} INFO - document #4\n",
      "[2025-03-17 22:23:45,944] p18144 {406922825.py:6} INFO - Nodes:id='Combinations' type='Package' properties={}\n",
      "[2025-03-17 22:23:45,945] p18144 {406922825.py:6} INFO - Nodes:id='Lsh' type='Class' properties={}\n",
      "[2025-03-17 22:23:45,946] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Lsh', type='Class', properties={}) target=Node(id='Combinations', type='Package', properties={}) type='IMPORTS' properties={}\n",
      "[2025-03-17 22:23:45,947] p18144 {406922825.py:2} INFO - document #5\n",
      "[2025-03-17 22:23:45,948] p18144 {406922825.py:6} INFO - Nodes:id='Clean_Document' type='Function' properties={}\n",
      "[2025-03-17 22:23:45,948] p18144 {406922825.py:6} INFO - Nodes:id='Utils.Utils' type='Module' properties={}\n",
      "[2025-03-17 22:23:45,949] p18144 {406922825.py:6} INFO - Nodes:id='Compute_Minhash_Signatures' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,949] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Clean_Document', type='Function', properties={}) target=Node(id='Compute_Minhash_Signatures', type='Method', properties={}) type='USED_IN' properties={}\n",
      "[2025-03-17 22:23:45,950] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Utils.Utils', type='Module', properties={}) target=Node(id='Clean_Document', type='Function', properties={}) type='IMPORTS' properties={}\n",
      "[2025-03-17 22:23:45,951] p18144 {406922825.py:2} INFO - document #6\n",
      "[2025-03-17 22:23:45,952] p18144 {406922825.py:6} INFO - Nodes:id='Shingle' type='Function' properties={}\n",
      "[2025-03-17 22:23:45,952] p18144 {406922825.py:6} INFO - Nodes:id='Utils.Utils' type='Module' properties={}\n",
      "[2025-03-17 22:23:45,953] p18144 {406922825.py:6} INFO - Nodes:id='Compute_Minhash_Signatures' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,954] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Shingle', type='Function', properties={}) target=Node(id='Utils.Utils', type='Module', properties={}) type='IMPORTS' properties={}\n",
      "[2025-03-17 22:23:45,955] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Compute_Minhash_Signatures', type='Method', properties={}) target=Node(id='Shingle', type='Function', properties={}) type='USES' properties={}\n",
      "[2025-03-17 22:23:45,956] p18144 {406922825.py:2} INFO - document #7\n",
      "[2025-03-17 22:23:45,956] p18144 {406922825.py:6} INFO - Nodes:id='Minhash' type='Function' properties={}\n",
      "[2025-03-17 22:23:45,957] p18144 {406922825.py:6} INFO - Nodes:id='Utils.Utils' type='Module' properties={}\n",
      "[2025-03-17 22:23:45,958] p18144 {406922825.py:6} INFO - Nodes:id='Compute_Minhash_Signatures' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,958] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Minhash', type='Function', properties={}) target=Node(id='Utils.Utils', type='Module', properties={}) type='IMPORTS' properties={}\n",
      "[2025-03-17 22:23:45,959] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Compute_Minhash_Signatures', type='Method', properties={}) target=Node(id='Minhash', type='Function', properties={}) type='USES' properties={}\n",
      "[2025-03-17 22:23:45,960] p18144 {406922825.py:2} INFO - document #8\n",
      "[2025-03-17 22:23:45,960] p18144 {406922825.py:6} INFO - Nodes:id='Parallel' type='Package' properties={}\n",
      "[2025-03-17 22:23:45,961] p18144 {406922825.py:6} INFO - Nodes:id='Joblib' type='Library' properties={}\n",
      "[2025-03-17 22:23:45,961] p18144 {406922825.py:6} INFO - Nodes:id='Compute_Minhash_Signatures' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,962] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Parallel', type='Package', properties={}) target=Node(id='Joblib', type='Library', properties={}) type='IMPORTS' properties={}\n",
      "[2025-03-17 22:23:45,962] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Parallel', type='Package', properties={}) target=Node(id='Compute_Minhash_Signatures', type='Method', properties={}) type='USED_IN' properties={}\n",
      "[2025-03-17 22:23:45,963] p18144 {406922825.py:2} INFO - document #9\n",
      "[2025-03-17 22:23:45,964] p18144 {406922825.py:6} INFO - Nodes:id='Delayed' type='Package' properties={}\n",
      "[2025-03-17 22:23:45,964] p18144 {406922825.py:6} INFO - Nodes:id='Joblib' type='Library' properties={}\n",
      "[2025-03-17 22:23:45,965] p18144 {406922825.py:6} INFO - Nodes:id='Compute_Minhash_Signatures' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,966] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Delayed', type='Package', properties={}) target=Node(id='Joblib', type='Library', properties={}) type='IMPORTS' properties={}\n",
      "[2025-03-17 22:23:45,967] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Delayed', type='Package', properties={}) target=Node(id='Compute_Minhash_Signatures', type='Method', properties={}) type='USED_IN' properties={}\n",
      "[2025-03-17 22:23:45,967] p18144 {406922825.py:2} INFO - document #10\n",
      "[2025-03-17 22:23:45,968] p18144 {406922825.py:6} INFO - Nodes:id='Lsh' type='Class' properties={}\n",
      "[2025-03-17 22:23:45,969] p18144 {406922825.py:6} INFO - Nodes:id='Lsh_Module' type='Module' properties={}\n",
      "[2025-03-17 22:23:45,969] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Lsh', type='Class', properties={}) target=Node(id='Lsh_Module', type='Module', properties={}) type='DEFINED_IN' properties={}\n",
      "[2025-03-17 22:23:45,970] p18144 {406922825.py:2} INFO - document #11\n",
      "[2025-03-17 22:23:45,970] p18144 {406922825.py:6} INFO - Nodes:id='Lsh' type='Class' properties={}\n",
      "[2025-03-17 22:23:45,971] p18144 {406922825.py:6} INFO - Nodes:id='__Init__' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,971] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='__Init__', type='Method', properties={}) target=Node(id='Lsh', type='Class', properties={}) type='DEFINED_IN' properties={}\n",
      "[2025-03-17 22:23:45,972] p18144 {406922825.py:2} INFO - document #12\n",
      "[2025-03-17 22:23:45,972] p18144 {406922825.py:6} INFO - Nodes:id='Remove_Duplicates' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,973] p18144 {406922825.py:6} INFO - Nodes:id='Lsh' type='Class' properties={}\n",
      "[2025-03-17 22:23:45,973] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Lsh', type='Class', properties={}) target=Node(id='Remove_Duplicates', type='Method', properties={}) type='DEFINES' properties={}\n",
      "[2025-03-17 22:23:45,974] p18144 {406922825.py:2} INFO - document #13\n",
      "[2025-03-17 22:23:45,974] p18144 {406922825.py:6} INFO - Nodes:id='Lsh' type='Class' properties={}\n",
      "[2025-03-17 22:23:45,974] p18144 {406922825.py:6} INFO - Nodes:id='Compute_Minhash_Signatures' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,975] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Lsh', type='Class', properties={}) target=Node(id='Compute_Minhash_Signatures', type='Method', properties={}) type='DEFINES' properties={}\n",
      "[2025-03-17 22:23:45,975] p18144 {406922825.py:2} INFO - document #14\n",
      "[2025-03-17 22:23:45,976] p18144 {406922825.py:6} INFO - Nodes:id='Banding' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,977] p18144 {406922825.py:6} INFO - Nodes:id='Lsh' type='Class' properties={}\n",
      "[2025-03-17 22:23:45,977] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Banding', type='Method', properties={}) target=Node(id='Lsh', type='Class', properties={}) type='DEFINED_IN' properties={}\n",
      "[2025-03-17 22:23:45,977] p18144 {406922825.py:2} INFO - document #15\n",
      "[2025-03-17 22:23:45,978] p18144 {406922825.py:6} INFO - Nodes:id='__Init__' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,978] p18144 {406922825.py:6} INFO - Nodes:id='Num_Hashes' type='Parameter' properties={}\n",
      "[2025-03-17 22:23:45,978] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='__Init__', type='Method', properties={}) target=Node(id='Num_Hashes', type='Parameter', properties={}) type='HAS_PARAMETER' properties={}\n",
      "[2025-03-17 22:23:45,979] p18144 {406922825.py:2} INFO - document #16\n",
      "[2025-03-17 22:23:45,980] p18144 {406922825.py:6} INFO - Nodes:id='__Init__' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,980] p18144 {406922825.py:6} INFO - Nodes:id='Num_Bands' type='Parameter' properties={}\n",
      "[2025-03-17 22:23:45,980] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='__Init__', type='Method', properties={}) target=Node(id='Num_Bands', type='Parameter', properties={}) type='HAS_PARAMETER' properties={}\n",
      "[2025-03-17 22:23:45,981] p18144 {406922825.py:2} INFO - document #17\n",
      "[2025-03-17 22:23:45,981] p18144 {406922825.py:6} INFO - Nodes:id='__Init__' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,981] p18144 {406922825.py:6} INFO - Nodes:id='Rows_Per_Band' type='Parameter' properties={}\n",
      "[2025-03-17 22:23:45,982] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='__Init__', type='Method', properties={}) target=Node(id='Rows_Per_Band', type='Parameter', properties={}) type='HAS_PARAMETER' properties={}\n",
      "[2025-03-17 22:23:45,982] p18144 {406922825.py:2} INFO - document #18\n",
      "[2025-03-17 22:23:45,982] p18144 {406922825.py:6} INFO - Nodes:id='K' type='Parameter' properties={}\n",
      "[2025-03-17 22:23:45,983] p18144 {406922825.py:6} INFO - Nodes:id='__Init__' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,983] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='__Init__', type='Method', properties={}) target=Node(id='K', type='Parameter', properties={}) type='HAS_PARAMETER' properties={}\n",
      "[2025-03-17 22:23:45,984] p18144 {406922825.py:2} INFO - document #19\n",
      "[2025-03-17 22:23:45,984] p18144 {406922825.py:6} INFO - Nodes:id='Remove_Duplicates' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,984] p18144 {406922825.py:6} INFO - Nodes:id='Doc_Id' type='Parameter' properties={}\n",
      "[2025-03-17 22:23:45,984] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Remove_Duplicates', type='Method', properties={}) target=Node(id='Doc_Id', type='Parameter', properties={}) type='HAS_PARAMETER' properties={}\n",
      "[2025-03-17 22:23:45,985] p18144 {406922825.py:2} INFO - document #20\n",
      "[2025-03-17 22:23:45,985] p18144 {406922825.py:6} INFO - Nodes:id='Remove_Duplicates' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,986] p18144 {406922825.py:6} INFO - Nodes:id='Doc' type='Parameter' properties={}\n",
      "[2025-03-17 22:23:45,986] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Remove_Duplicates', type='Method', properties={}) target=Node(id='Doc', type='Parameter', properties={}) type='HAS_PARAMETER' properties={}\n",
      "[2025-03-17 22:23:45,986] p18144 {406922825.py:2} INFO - document #21\n",
      "[2025-03-17 22:23:45,987] p18144 {406922825.py:6} INFO - Nodes:id='Compute_Minhash_Signatures' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,987] p18144 {406922825.py:6} INFO - Nodes:id='Docs' type='Parameter' properties={}\n",
      "[2025-03-17 22:23:45,987] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Compute_Minhash_Signatures', type='Method', properties={}) target=Node(id='Docs', type='Parameter', properties={}) type='HAS_PARAMETER' properties={}\n",
      "[2025-03-17 22:23:45,988] p18144 {406922825.py:2} INFO - document #22\n",
      "[2025-03-17 22:23:45,988] p18144 {406922825.py:6} INFO - Nodes:id='Signatures' type='Parameter' properties={}\n",
      "[2025-03-17 22:23:45,988] p18144 {406922825.py:6} INFO - Nodes:id='Banding' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,989] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Signatures', type='Parameter', properties={}) target=Node(id='Banding', type='Method', properties={}) type='PARAMETER_OF' properties={}\n",
      "[2025-03-17 22:23:45,989] p18144 {406922825.py:2} INFO - document #23\n",
      "[2025-03-17 22:23:45,989] p18144 {406922825.py:6} INFO - Nodes:id='Sig' type='Variable' properties={}\n",
      "[2025-03-17 22:23:45,990] p18144 {406922825.py:6} INFO - Nodes:id='Banding' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,990] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Sig', type='Variable', properties={}) target=Node(id='Banding', type='Method', properties={}) type='IS_A' properties={}\n",
      "[2025-03-17 22:23:45,990] p18144 {406922825.py:2} INFO - document #24\n",
      "[2025-03-17 22:23:45,992] p18144 {406922825.py:6} INFO - Nodes:id='Band_Idx' type='Variable' properties={}\n",
      "[2025-03-17 22:23:45,993] p18144 {406922825.py:6} INFO - Nodes:id='Banding' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,993] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Band_Idx', type='Variable', properties={}) target=Node(id='Banding', type='Method', properties={}) type='IS_A' properties={}\n",
      "[2025-03-17 22:23:45,993] p18144 {406922825.py:2} INFO - document #25\n",
      "[2025-03-17 22:23:45,994] p18144 {406922825.py:6} INFO - Nodes:id='Start' type='Variable' properties={}\n",
      "[2025-03-17 22:23:45,994] p18144 {406922825.py:6} INFO - Nodes:id='Banding' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,995] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Start', type='Variable', properties={}) target=Node(id='Banding', type='Method', properties={}) type='IS_USED_IN' properties={}\n",
      "[2025-03-17 22:23:45,995] p18144 {406922825.py:2} INFO - document #26\n",
      "[2025-03-17 22:23:45,995] p18144 {406922825.py:6} INFO - Nodes:id='Band' type='Variable' properties={}\n",
      "[2025-03-17 22:23:45,996] p18144 {406922825.py:6} INFO - Nodes:id='Banding' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,996] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Band', type='Variable', properties={}) target=Node(id='Banding', type='Method', properties={}) type='IS_VARIABLE_IN' properties={}\n",
      "[2025-03-17 22:23:45,998] p18144 {406922825.py:2} INFO - document #27\n",
      "[2025-03-17 22:23:45,998] p18144 {406922825.py:6} INFO - Nodes:id='Banding' type='Method' properties={}\n",
      "[2025-03-17 22:23:45,998] p18144 {406922825.py:6} INFO - Nodes:id='Doc_Ids' type='Variable' properties={}\n",
      "[2025-03-17 22:23:45,998] p18144 {406922825.py:8} INFO - Relationships:source=Node(id='Banding', type='Method', properties={}) target=Node(id='Doc_Ids', type='Variable', properties={}) type='INCLUDES' properties={}\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(graph_documents):\n",
    "    logger.info(f\"document #{i+1}\")\n",
    "    nodes = doc.nodes\n",
    "    relationships = doc.relationships\n",
    "    for n in nodes:\n",
    "        logger.info(f\"Nodes:{n}\")\n",
    "    for r in relationships:\n",
    "        logger.info(f\"Relationships:{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with legend saved as graph.html\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create Pyvis network\n",
    "net = Network(notebook=True, cdn_resources='in_line', height=\"1000px\", width=\"100%\")\n",
    "\n",
    "# Create a NetworkX graph for analysis\n",
    "G = nx.Graph()\n",
    "\n",
    "# Dictionary to store node attributes\n",
    "node_types = {}\n",
    "\n",
    "# Add nodes and edges, extracting types\n",
    "for graph in graph_documents:\n",
    "    for rel in graph.relationships:\n",
    "        source, target = str(rel.source.id), str(rel.target.id)\n",
    "        source_type = rel.source.type\n",
    "        target_type = rel.target.type\n",
    "        rel_type = rel.type  # Relationship type (e.g., 'IMPORTS')\n",
    "\n",
    "        # Store node types\n",
    "        node_types[source] = source_type\n",
    "        node_types[target] = target_type\n",
    "\n",
    "        # Add nodes if not already added\n",
    "        G.add_node(source)\n",
    "        G.add_node(target)\n",
    "\n",
    "        # Add edge with label\n",
    "        G.add_edge(source, target, label=rel_type)\n",
    "\n",
    "# Get unique node types and assign colors\n",
    "unique_types = list(set(node_types.values()))\n",
    "color_map = plt.get_cmap(\"tab10\")  # Use a categorical colormap\n",
    "type_colors = {t: color_map(i / len(unique_types)) for i, t in enumerate(unique_types)}\n",
    "\n",
    "# Convert colors to RGBA format\n",
    "type_colors_rgba = {\n",
    "    t: f'rgba({int(c[0] * 255)}, {int(c[1] * 255)}, {int(c[2] * 255)}, 0.8)' for t, c in type_colors.items()\n",
    "}\n",
    "\n",
    "# Determine node sizes based on degrees\n",
    "degrees = dict(G.degree())\n",
    "min_size, max_size = 10, 50\n",
    "size_scale = {node: min_size + (max_size - min_size) * (deg / max(degrees.values())) for node, deg in degrees.items()}\n",
    "\n",
    "# Add nodes with dynamic colors and sizes\n",
    "for node in G.nodes():\n",
    "    node_type = node_types.get(node, \"default\")\n",
    "    net.add_node(\n",
    "        node,\n",
    "        label=node,  # Show node ID\n",
    "        size=size_scale[node],  # Adjust size\n",
    "        color=type_colors_rgba.get(node_type, \"gray\")  # Assign color based on type\n",
    "    )\n",
    "\n",
    "# Add edges with labels for relationship type\n",
    "for edge in G.edges(data=True):\n",
    "    source, target, attr = edge\n",
    "    rel_label = attr.get(\"label\", \"\")  # Get relationship type\n",
    "    net.add_edge(source, target, title=rel_label, label=rel_label)  # Show label on hover and as text\n",
    "\n",
    "# Save the graph\n",
    "net.save_graph(\"graph.html\")\n",
    "\n",
    "# Generate legend HTML block\n",
    "legend_html = \"\"\"\n",
    "<div id=\"legend\" style=\"position: absolute; top: 10px; left: 10px; background: white; padding: 10px; border-radius: 8px; box-shadow: 0px 0px 5px rgba(0,0,0,0.2); font-family: Arial, sans-serif; z-index: 1000;\">\n",
    "    <h4 style=\"margin: 0; padding-bottom: 5px;\">Node Legend</h4>\n",
    "\"\"\"\n",
    "\n",
    "for node_type, color in type_colors_rgba.items():\n",
    "    legend_html += f'<div style=\"display: flex; align-items: center; margin-bottom: 5px;\"><div style=\"width: 15px; height: 15px; background:{color}; margin-right: 5px; border-radius: 50%;\"></div> {node_type}</div>'\n",
    "\n",
    "legend_html += \"</div>\"\n",
    "\n",
    "# Inject the legend into the HTML file\n",
    "with open(\"graph.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Insert the legend just before closing </body> tag\n",
    "html_content = html_content.replace(\"</body>\", legend_html + \"</body>\")\n",
    "\n",
    "with open(\"graph.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(html_content)\n",
    "\n",
    "print(\"Graph with legend saved as graph.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyvis.network import Network\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Create Pyvis network\n",
    "# net = Network(notebook=True, cdn_resources='in_line', height=\"1000px\", width=\"100%\")\n",
    "\n",
    "# # Create a NetworkX graph for analysis\n",
    "# G = nx.Graph()\n",
    "\n",
    "# # Dictionary to store node attributes\n",
    "# node_types = {}\n",
    "\n",
    "# # Add nodes and edges, extracting types\n",
    "# for graph in graph_documents:\n",
    "#     for rel in graph.relationships:\n",
    "#         source, target = str(rel.source.id), str(rel.target.id)\n",
    "#         source_type = rel.source.type\n",
    "#         target_type = rel.target.type\n",
    "#         rel_type = rel.type  # Relationship type (e.g., 'IMPORTS')\n",
    "\n",
    "#         # Store node types\n",
    "#         node_types[source] = source_type\n",
    "#         node_types[target] = target_type\n",
    "\n",
    "#         # Add nodes if not already added\n",
    "#         G.add_node(source)\n",
    "#         G.add_node(target)\n",
    "\n",
    "#         # Add edge with label\n",
    "#         G.add_edge(source, target, label=rel_type)\n",
    "\n",
    "# # Get unique node types and assign colors\n",
    "# unique_types = list(set(node_types.values()))\n",
    "# color_map = plt.get_cmap(\"tab10\")  # Use a categorical colormap\n",
    "# type_colors = {t: color_map(i / len(unique_types)) for i, t in enumerate(unique_types)}\n",
    "\n",
    "# # Convert colors to RGBA format\n",
    "# type_colors_rgba = {\n",
    "#     t: f'rgba({int(c[0] * 255)}, {int(c[1] * 255)}, {int(c[2] * 255)}, 0.8)' for t, c in type_colors.items()\n",
    "# }\n",
    "\n",
    "# # Determine node sizes based on degrees\n",
    "# degrees = dict(G.degree())\n",
    "# min_size, max_size = 10, 50\n",
    "# size_scale = {node: min_size + (max_size - min_size) * (deg / max(degrees.values())) for node, deg in degrees.items()}\n",
    "\n",
    "# # Add nodes with dynamic colors and sizes\n",
    "# for node in G.nodes():\n",
    "#     node_type = node_types.get(node, \"default\")\n",
    "#     net.add_node(\n",
    "#         node,\n",
    "#         label=node,  # Show node ID\n",
    "#         size=size_scale[node],  # Adjust size\n",
    "#         color=type_colors_rgba.get(node_type, \"gray\")  # Assign color based on type\n",
    "#     )\n",
    "\n",
    "# # Add edges with labels for relationship type\n",
    "# for edge in G.edges(data=True):\n",
    "#     source, target, attr = edge\n",
    "#     rel_label = attr.get(\"label\", \"\")  # Get relationship type\n",
    "#     net.add_edge(source, target, title=rel_label, label=rel_label)  # Show label on hover and as text\n",
    "\n",
    "# # Save and display\n",
    "# net.save_graph(\"graph.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not connect to Memgraph database. Please ensure that the url is correct",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:409\u001b[39m, in \u001b[36mBoltSocketBase._connect_secure\u001b[39m\u001b[34m(cls, resolved_address, timeout, keep_alive, ssl_context)\u001b[39m\n\u001b[32m    408\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33m[#0000]  C: <OPEN> \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, resolved_address)\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m \u001b[43ms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m s.settimeout(t)\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceUnavailable\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt_socket.py:328\u001b[39m, in \u001b[36mBoltSocket.connect\u001b[39m\u001b[34m(cls, address, tcp_timeout, deadline, custom_resolver, ssl_context, keep_alive)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     s = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect_secure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresolved_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcp_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssl_context\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m     agreed_version, handshake, response = s._handshake(\n\u001b[32m    332\u001b[39m         resolved_address, deadline\n\u001b[32m    333\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:426\u001b[39m, in \u001b[36mBoltSocketBase._connect_secure\u001b[39m\u001b[34m(cls, resolved_address, timeout, keep_alive, ssl_context)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[32m    427\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to establish connection to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    428\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_address\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m (reason \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    429\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mServiceUnavailable\u001b[39m: Failed to establish connection to ResolvedIPv6Address(('::1', 3000, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceUnavailable\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\langchain_community\\graphs\\memgraph_graph.py:332\u001b[39m, in \u001b[36mMemgraphGraph.__init__\u001b[39m\u001b[34m(self, url, username, password, database, refresh_schema, driver_config)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_driver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify_connectivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.ServiceUnavailable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\driver.py:1082\u001b[39m, in \u001b[36mDriver.verify_connectivity\u001b[39m\u001b[34m(self, **config)\u001b[39m\n\u001b[32m   1081\u001b[39m session_config = \u001b[38;5;28mself\u001b[39m._read_session_config(config)\n\u001b[32m-> \u001b[39m\u001b[32m1082\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_server_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\driver.py:1297\u001b[39m, in \u001b[36mDriver._get_server_info\u001b[39m\u001b[34m(self, session_config)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._session(session_config) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_server_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:183\u001b[39m, in \u001b[36mSession._get_server_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAD_ACCESS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m server_info = \u001b[38;5;28mself\u001b[39m._connection.server_info\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:136\u001b[39m, in \u001b[36mSession._connect\u001b[39m\u001b[34m(self, access_mode, **acquire_kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43macquire_kwargs\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:199\u001b[39m, in \u001b[36mWorkspace._connect\u001b[39m\u001b[34m(self, access_mode, auth, **acquire_kwargs)\u001b[39m\n\u001b[32m    198\u001b[39m acquire_kwargs_.update(acquire_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[38;5;28mself\u001b[39m._connection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43macquire_kwargs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    201\u001b[39m     target_db.guessed\n\u001b[32m    202\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pinned_database\n\u001b[32m   (...)\u001b[39m\u001b[32m    206\u001b[39m     \u001b[38;5;66;03m# support SSR.\u001b[39;00m\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# => we need to fall back to explicit home database resolution\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:662\u001b[39m, in \u001b[36mBoltPool.acquire\u001b[39m\u001b[34m(self, access_mode, timeout, database, bookmarks, auth, liveness_check_timeout, database_callback)\u001b[39m\n\u001b[32m    661\u001b[39m deadline = Deadline.from_timeout_or_deadline(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mliveness_check_timeout\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:408\u001b[39m, in \u001b[36mIOPool._acquire\u001b[39m\u001b[34m(self, address, auth, deadline, liveness_check_timeout)\u001b[39m\n\u001b[32m    407\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33m[#0000]  _: <POOL> trying to hand out new connection\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:230\u001b[39m, in \u001b[36mIOPool._acquire_new_later.<locals>.connection_creator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     connection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopener\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeadline\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ServiceUnavailable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:624\u001b[39m, in \u001b[36mBoltPool.open.<locals>.opener\u001b[39m\u001b[34m(addr, auth_manager, deadline)\u001b[39m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopener\u001b[39m(addr, auth_manager, deadline):\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBolt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauth_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrouting_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:369\u001b[39m, in \u001b[36mBolt.open\u001b[39m\u001b[34m(cls, address, auth_manager, deadline, routing_context, pool_config)\u001b[39m\n\u001b[32m    367\u001b[39m     deadline = Deadline(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m s, protocol_version, handshake, data = \u001b[43mBoltSocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtcp_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnection_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_resolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m pool_config.protocol_version = protocol_version\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt_socket.py:376\u001b[39m, in \u001b[36mBoltSocket.connect\u001b[39m\u001b[34m(cls, address, tcp_timeout, deadline, custom_resolver, ssl_context, keep_alive)\u001b[39m\n\u001b[32m    375\u001b[39m error_strs = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, errors))\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ServiceUnavailable(\n\u001b[32m    377\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt connect to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddress\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (resolved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maddress_strs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m):\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    378\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_strs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    379\u001b[39m ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merrors\u001b[39;00m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mServiceUnavailable\u001b[39m: Couldn't connect to localhost:3000 (resolved to ('[::1]:3000', '127.0.0.1:3000')):\nFailed to establish connection to ResolvedIPv6Address(('::1', 3000, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\nFailed to establish connection to ResolvedIPv4Address(('127.0.0.1', 3000)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m username = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mMEMGRAPH_USERNAME\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m password = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mMEMGRAPH_PASSWORD\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m graph = \u001b[43mMemgraphGraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musername\u001b[49m\u001b[43m=\u001b[49m\u001b[43musername\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefresh_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JaeHoBahng\\Desktop\\Georgetown\\2025_Spring\\DSAN_6725\\project\\spring-2025-final-project-project-group-2\\.venv\\Lib\\site-packages\\langchain_community\\graphs\\memgraph_graph.py:334\u001b[39m, in \u001b[36mMemgraphGraph.__init__\u001b[39m\u001b[34m(self, url, username, password, database, refresh_schema, driver_config)\u001b[39m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28mself\u001b[39m._driver.verify_connectivity()\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.ServiceUnavailable:\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    335\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not connect to Memgraph database. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    336\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure that the url is correct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    337\u001b[39m     )\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j.exceptions.AuthError:\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not connect to Memgraph database. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure that the username and password are correct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Could not connect to Memgraph database. Please ensure that the url is correct"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/integrations/graphs/memgraph/\n",
    "\n",
    "from langchain_community.graphs import MemgraphGraph\n",
    "from langchain_community.chains.graph_qa.memgraph import MemgraphQAChain\n",
    "import os\n",
    "\n",
    "url = os.environ.get(\"MEMGRAPH_URI\", \"bolt://localhost:7687\")\n",
    "username = os.environ.get(\"MEMGRAPH_USERNAME\", \"\")\n",
    "password = os.environ.get(\"MEMGRAPH_PASSWORD\", \"\")\n",
    " \n",
    "graph = MemgraphGraph(\n",
    "    url=url, username=username, password=password, refresh_schema=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-15 12:22:31,826] p16596 {memgraph_graph.py:450} INFO - Schema generation with SHOW SCHEMA INFO query failed. Set --schema-info-enabled=true to use SHOW SCHEMA INFO query. Falling back to alternative queries.\n"
     ]
    }
   ],
   "source": [
    "# Make sure the database is empty\n",
    "graph.query(\"STORAGE MODE IN_MEMORY_ANALYTICAL\")\n",
    "graph.query(\"DROP GRAPH\")\n",
    "graph.query(\"STORAGE MODE IN_MEMORY_TRANSACTIONAL\")\n",
    " \n",
    "# Create KG\n",
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-15 12:22:31,854] p16596 {memgraph_graph.py:450} INFO - Schema generation with SHOW SCHEMA INFO query failed. Set --schema-info-enabled=true to use SHOW SCHEMA INFO query. Falling back to alternative queries.\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node labels and properties (name and type) are:\n",
      "- labels: (:Function)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Detail)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Class)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Instruction)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Object)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Variable)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Parameter)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Attribute)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Decorator)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Property)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Argument)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Type)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Agent type)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Component)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Method)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Library)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Concept)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Parser)\n",
      "  properties:\n",
      "    - id: string\n",
      "- labels: (:Message)\n",
      "  properties:\n",
      "    - id: string\n",
      "\n",
      "Nodes are connected with the following relationships:\n",
      "(:Method)-[:CALLS]->(:Method)\n",
      "(:Method)-[:USES]->(:Argument)\n",
      "(:Method)-[:USES]->(:Attribute)\n",
      "(:Method)-[:USES]->(:Detail)\n",
      "(:Method)-[:USES]->(:Instruction)\n",
      "(:Method)-[:VALIDATES]->(:Parameter)\n",
      "(:Method)-[:CALLS]->(:Function)\n",
      "(:Method)-[:HAS_PARAMETER]->(:Parameter)\n",
      "(:Method)-[:HAS_PARAMETER]->(:Argument)\n",
      "(:Method)-[:HAS_PARAMETER]->(:Attribute)\n",
      "(:Method)-[:HAS_PARAMETER]->(:Detail)\n",
      "(:Method)-[:HAS_PARAMETER]->(:Instruction)\n",
      "(:Method)-[:CREATES_INSTANCE]->(:Class)\n",
      "(:Class)-[:RELATED_TO]->(:Class)\n",
      "(:Method)-[:CONSTRUCTS]->(:Class)\n",
      "(:Concept)-[:USES]->(:Parser)\n",
      "(:Message)-[:IMPORTS]->(:)\n",
      "(:Method)-[:DETERMINES]->(:Variable)\n",
      "(:Library)-[:IMPORTS]->(:Concept)\n",
      "(:Library)-[:ENABLES]->(:Concept)\n",
      "(:Concept)-[:VALIDATES]->(:Function)\n",
      "(:Class)-[:RELATED_TO]->(:Type)\n",
      "(:Library)-[:IMPORTS]->(:Function)\n",
      "(:Library)-[:IMPORTS]->(:Component)\n",
      "(:Concept)-[:RELATED_TO]->(:Type)\n",
      "(:Method)-[:CREATES]->(:Class)\n",
      "(:Method)-[:GENERATES]->(:Variable)\n",
      "(:Class)-[:HAS_ATTRIBUTE]->(:Attribute)\n",
      "(:Method)-[:USES]->(:Parameter)\n",
      "(:Method)-[:RETURNS]->(:Object)\n",
      "(:Concept)-[:USES]->(:Library)\n",
      "(:Concept)-[:RELATED_TO]->(:Class)\n",
      "(:Class)-[:USES]->(:Parser)\n",
      "(:Class)-[:INTERACTS_WITH]->(:Concept)\n",
      "(:Class)-[:INTERACTS_WITH]->(:Class)\n",
      "(:Class)-[:INHERITS_FROM]->(:Concept)\n",
      "(:Library)-[:IMPORTS]->(:Type)\n",
      "(:Class)-[:VALIDATES]->(:Function)\n",
      "(:Class)-[:INHERITS_FROM]->(:Class)\n",
      "(:Method)-[:CREATES]->(:Variable)\n",
      "(:Method)-[:REQUIRES]->(:Attribute)\n",
      "(:Class)-[:DECORATED_WITH]->(:Decorator)\n",
      "(:Property)-[:RETURNS]->(:)\n",
      "(:Method)-[:CREATES_INSTANCE]->(:Parser)\n",
      "(:Attribute)-[:INSTANTIATES]->(:Parser)\n",
      "(:Method)-[:REQUIRES]->(:Argument)\n",
      "(:Property)-[:RETURNS]->(:Agent type)\n",
      "(:Method)-[:RETURNS]->(:Component)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMGRAPH_GENERATION_TEMPLATE = \"\"\"\n",
    "Your task is to directly translate natural language inquiry into precise and executable Cypher query for Memgraph database. \n",
    "You will utilize a provided database schema to understand the structure, nodes and relationships within the Memgraph database.\n",
    "Instructions: \n",
    "- Use provided node and relationship labels and property names from the\n",
    "schema which describes the database's structure. Upon receiving a user\n",
    "question, synthesize the schema to craft a precise Cypher query that\n",
    "directly corresponds to the user's intent. \n",
    "- Generate valid executable Cypher queries on top of Memgraph database. \n",
    "Any explanation, context, or additional information that is not a part \n",
    "of the Cypher query syntax should be omitted entirely. \n",
    "- Use Memgraph MAGE procedures instead of Neo4j APOC procedures. \n",
    "- Do not include any explanations or apologies in your responses. \n",
    "- Do not include any text except the generated Cypher statement.\n",
    "- For queries that ask for information or functionalities outside the direct\n",
    "generation of Cypher queries, use the Cypher query format to communicate\n",
    "limitations or capabilities. For example: RETURN \"I am designed to generate\n",
    "Cypher queries based on the provided schema only.\"\n",
    "Schema: \n",
    "{schema}\n",
    "\n",
    "With all the above information and instructions, generate Cypher query for the\n",
    "user question. \n",
    "\n",
    "The question is:\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\",temperature=0)\n",
    "schema = graph.schema\n",
    "\n",
    "MEMGRAPH_GENERATION_TEMPLATE = \"\"\"Your task is to directly translate natural language inquiry into precise and executable Cypher query for Memgraph database. \n",
    "You will utilize a provided database schema to understand the structure, nodes and relationships within the Memgraph database.\n",
    "Instructions: \n",
    "- Use provided node and relationship labels and property names from the\n",
    "schema which describes the database's structure. Upon receiving a user\n",
    "question, synthesize the schema to craft a precise Cypher query that\n",
    "directly corresponds to the user's intent. \n",
    "- Generate valid executable Cypher queries on top of Memgraph database. \n",
    "Any explanation, context, or additional information that is not a part \n",
    "of the Cypher query syntax should be omitted entirely. \n",
    "- Use Memgraph MAGE procedures instead of Neo4j APOC procedures. \n",
    "- Do not use atomic operations in your Cypher queries.\n",
    "- Do not include any explanations or apologies in your responses. \n",
    "- Do not include any text except the generated Cypher statement.\n",
    "- For queries that ask for information or functionalities outside the direct\n",
    "generation of Cypher queries, use the Cypher query format to communicate\n",
    "limitations or capabilities. For example: RETURN \"I am designed to generate\n",
    "Cypher queries based on the provided schema only.\"\n",
    "Schema: \n",
    "{schema}\n",
    "\n",
    "With all the above information and instructions, generate Cypher query for the\n",
    "user question. \n",
    "If the user asks about PS5, Play Station 5 or PS 5, that is the platform called PlayStation 5.\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "\n",
    "MEMGRAPH_GENERATION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], template=MEMGRAPH_GENERATION_TEMPLATE\n",
    ")\n",
    "\n",
    "chain = MemgraphQAChain.from_llm(\n",
    "    llm,\n",
    "    cypher_prompt=MEMGRAPH_GENERATION_PROMPT,\n",
    "    graph=graph,\n",
    "    model_id=\"gpt-4o-turbo\",\n",
    "    return_intermediate_steps=True,\n",
    "    allow_dangerous_requests=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-15 12:22:33,195] p16596 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "[2025-03-15 12:22:33,611] p16596 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate Steps :  [{'query': \"MATCH (c:Class {id: 'Conversationalagent'})<-[:CREATES_INSTANCE]-(m:Method) RETURN m\"}, {'context': []}]\n",
      "Final Response :  I don't know the answer.\n"
     ]
    }
   ],
   "source": [
    "q = \"what methods are related to class Conversationalagent?\"\n",
    "response = chain.invoke(q)\n",
    "print(\"Intermediate Steps : \", response['intermediate_steps'])\n",
    "print(\"Final Response : \", response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\"MATCH (c:Class {id: 'Conversationalagent'})-[:TAKES_PARAMETER]->(p:Parameter) RETURN p.id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-15 12:22:34,433] p16596 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "MATCH (n)-[r]->(m) WHERE n.id = 'Conversationalagent' RETURN n, r, m\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'n': {'id': 'Conversationalagent'}, 'r': ({'id': 'Conversationalagent'}, 'INHERITS_FROM', {'id': 'Agent'}), 'm': {'id': 'Agent'}}, {'n': {'id': 'Conversationalagent'}, 'r': ({'id': 'Conversationalagent'}, 'INHERITS_FROM', {'id': 'Agent'}), 'm': {'id': 'Agent'}}, {'n': {'id': 'Conversationalagent'}, 'r': ({'id': 'Conversationalagent'}, 'DECORATED_WITH', {'id': '@Deprecated'}), 'm': {'id': '@Deprecated'}}, {'n': {'id': 'Conversationalagent'}, 'r': ({'id': 'Conversationalagent'}, 'HAS_ATTRIBUTE', {'id': 'Ai_Prefix'}), 'm': {'id': 'Ai_Prefix'}}, {'n': {'id': 'Conversationalagent'}, 'r': ({'id': 'Conversationalagent'}, 'HAS_ATTRIBUTE', {'id': 'Output_Parser'}), 'm': {'id': 'Output_Parser'}}]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-15 12:22:35,237] p16596 {_client.py:1025} INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what is related to the id Conversationalagent',\n",
       " 'result': 'The id Conversationalagent is related to the following: it inherits from the id Agent, is decorated with @Deprecated, and has attributes Ai_Prefix and Output_Parser.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "qa_chainn = GraphCypherQAChain.from_llm(graph=graph, llm=llm, verbose=True,allow_dangerous_requests=True)\n",
    "response = qa_chainn.invoke({\"query\": \"what is related to the id Conversationalagent\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'c': {'id': 'Conversationalagent'},\n",
       "  'r': ({'id': 'Conversationalagent'}, 'INHERITS_FROM', {'id': 'Agent'}),\n",
       "  'n': {'id': 'Agent'}},\n",
       " {'c': {'id': 'Conversationalagent'},\n",
       "  'r': ({'id': 'Conversationalagent'}, 'INHERITS_FROM', {'id': 'Agent'}),\n",
       "  'n': {'id': 'Agent'}},\n",
       " {'c': {'id': 'Conversationalagent'},\n",
       "  'r': ({'id': 'Conversationalagent'},\n",
       "   'DECORATED_WITH',\n",
       "   {'id': '@Deprecated'}),\n",
       "  'n': {'id': '@Deprecated'}},\n",
       " {'c': {'id': 'Conversationalagent'},\n",
       "  'r': ({'id': 'Conversationalagent'}, 'HAS_ATTRIBUTE', {'id': 'Ai_Prefix'}),\n",
       "  'n': {'id': 'Ai_Prefix'}},\n",
       " {'c': {'id': 'Conversationalagent'},\n",
       "  'r': ({'id': 'Conversationalagent'},\n",
       "   'HAS_ATTRIBUTE',\n",
       "   {'id': 'Output_Parser'}),\n",
       "  'n': {'id': 'Output_Parser'}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\"MATCH (c)-[r]->(n) WHERE c.id = 'Conversationalagent' RETURN c, r, n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "Schema:\n",
    "{schema}\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "Examples: Here are a few examples of generated Cypher statements for particular questions:\n",
    "# How many people played in Top Gun?\n",
    "MATCH (m:Movie {{name:\"Top Gun\"}})<-[:ACTED_IN]-()\n",
    "RETURN count(*) AS numberOfActors\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "\n",
    "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
    ")\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatOpenAI(temperature=0),\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
    "    allow_dangerous_requests=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_transformer_filtered = LLMGraphTransformer(\n",
    "#     llm=llm,\n",
    "#     allowed_nodes=[\"Person\", \"Nationality\", \"Concept\"],\n",
    "#     allowed_relationships=[\"NATIONALITY\", \"INVOLVED_IN\", \"COLLABORATES_WITH\"],\n",
    "# )\n",
    "# graph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(\n",
    "#     documents\n",
    "# )\n",
    "\n",
    "# print(f\"Nodes:{graph_documents_filtered[0].nodes}\")\n",
    "# print(f\"Relationships:{graph_documents_filtered[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change \\n to \\\\n\n",
    "\n",
    "code = '''\n",
    "# An agent designed to hold a conversation in addition to using tools.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, List, Optional, Sequence\n",
    "\n",
    "from langchain_core._api import deprecated\n",
    "from langchain_core.callbacks import BaseCallbackManager\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.tools import BaseTool\n",
    "from pydantic import Field\n",
    "\n",
    "from langchain._api.deprecation import AGENT_DEPRECATION_WARNING\n",
    "from langchain.agents.agent import Agent, AgentOutputParser\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents.conversational.output_parser import ConvoOutputParser\n",
    "from langchain.agents.conversational.prompt import FORMAT_INSTRUCTIONS, PREFIX, SUFFIX\n",
    "from langchain.agents.utils import validate_tools_single_input\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "@deprecated(\n",
    "    \"0.1.0\",\n",
    "    message=AGENT_DEPRECATION_WARNING,\n",
    "    removal=\"1.0\",\n",
    ")\n",
    "class ConversationalAgent(Agent):\n",
    "    \"\"\"An agent that holds a conversation in addition to using tools.\"\"\"\n",
    "\n",
    "    ai_prefix: str = \"AI\"\n",
    "    \"\"\"Prefix to use before AI output.\"\"\"\n",
    "    output_parser: AgentOutputParser = Field(default_factory=ConvoOutputParser)\n",
    "    \"\"\"Output parser for the agent.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def _get_default_output_parser(\n",
    "        cls, ai_prefix: str = \"AI\", **kwargs: Any\n",
    "    ) -> AgentOutputParser:\n",
    "        return ConvoOutputParser(ai_prefix=ai_prefix)\n",
    "\n",
    "    @property\n",
    "    def _agent_type(self) -> str:\n",
    "        \"\"\"Return Identifier of agent type.\"\"\"\n",
    "        return AgentType.CONVERSATIONAL_REACT_DESCRIPTION\n",
    "\n",
    "    @property\n",
    "    def observation_prefix(self) -> str:\n",
    "        \"\"\"Prefix to append the observation with.\n",
    "\n",
    "        Returns:\n",
    "            \"Observation: \"\n",
    "        \"\"\"\n",
    "        return \"Observation: \"\n",
    "\n",
    "    @property\n",
    "    def llm_prefix(self) -> str:\n",
    "        \"\"\"Prefix to append the llm call with.\n",
    "\n",
    "        Returns:\n",
    "            \"Thought: \"\n",
    "        \"\"\"\n",
    "        return \"Thought:\"\n",
    "\n",
    "    @classmethod\n",
    "    def create_prompt(\n",
    "        cls,\n",
    "        tools: Sequence[BaseTool],\n",
    "        prefix: str = PREFIX,\n",
    "        suffix: str = SUFFIX,\n",
    "        format_instructions: str = FORMAT_INSTRUCTIONS,\n",
    "        ai_prefix: str = \"AI\",\n",
    "        human_prefix: str = \"Human\",\n",
    "        input_variables: Optional[List[str]] = None,\n",
    "    ) -> PromptTemplate:\n",
    "        \"\"\"Create prompt in the style of the zero-shot agent.\n",
    "\n",
    "        Args:\n",
    "            tools: List of tools the agent will have access to, used to format the\n",
    "                prompt.\n",
    "            prefix: String to put before the list of tools. Defaults to PREFIX.\n",
    "            suffix: String to put after the list of tools. Defaults to SUFFIX.\n",
    "            format_instructions: Instructions on how to use the tools. Defaults to\n",
    "                FORMAT_INSTRUCTIONS\n",
    "            ai_prefix: String to use before AI output. Defaults to \"AI\".\n",
    "            human_prefix: String to use before human output.\n",
    "                Defaults to \"Human\".\n",
    "            input_variables: List of input variables the final prompt will expect.\n",
    "                Defaults to [\"input\", \"chat_history\", \"agent_scratchpad\"].\n",
    "\n",
    "        Returns:\n",
    "            A PromptTemplate with the template assembled from the pieces here.\n",
    "        \"\"\"\n",
    "        tool_strings = \"\\\\n\".join(\n",
    "            [f\"> {tool.name}: {tool.description}\" for tool in tools]\n",
    "        )\n",
    "        tool_names = \", \".join([tool.name for tool in tools])\n",
    "        format_instructions = format_instructions.format(\n",
    "            tool_names=tool_names, ai_prefix=ai_prefix, human_prefix=human_prefix\n",
    "        )\n",
    "        template = \"\\\\n\\\\n\".join([prefix, tool_strings, format_instructions, suffix])\n",
    "        if input_variables is None:\n",
    "            input_variables = [\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
    "        return PromptTemplate(template=template, input_variables=input_variables)\n",
    "\n",
    "    @classmethod\n",
    "    def _validate_tools(cls, tools: Sequence[BaseTool]) -> None:\n",
    "        super()._validate_tools(tools)\n",
    "        validate_tools_single_input(cls.__name__, tools)\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm_and_tools(\n",
    "        cls,\n",
    "        llm: BaseLanguageModel,\n",
    "        tools: Sequence[BaseTool],\n",
    "        callback_manager: Optional[BaseCallbackManager] = None,\n",
    "        output_parser: Optional[AgentOutputParser] = None,\n",
    "        prefix: str = PREFIX,\n",
    "        suffix: str = SUFFIX,\n",
    "        format_instructions: str = FORMAT_INSTRUCTIONS,\n",
    "        ai_prefix: str = \"AI\",\n",
    "        human_prefix: str = \"Human\",\n",
    "        input_variables: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Agent:\n",
    "        \"\"\"Construct an agent from an LLM and tools.\n",
    "\n",
    "        Args:\n",
    "            llm: The language model to use.\n",
    "            tools: A list of tools to use.\n",
    "            callback_manager: The callback manager to use. Default is None.\n",
    "            output_parser: The output parser to use. Default is None.\n",
    "            prefix: The prefix to use in the prompt. Default is PREFIX.\n",
    "            suffix: The suffix to use in the prompt. Default is SUFFIX.\n",
    "            format_instructions: The format instructions to use.\n",
    "                Default is FORMAT_INSTRUCTIONS.\n",
    "            ai_prefix: The prefix to use before AI output. Default is \"AI\".\n",
    "            human_prefix: The prefix to use before human output.\n",
    "                Default is \"Human\".\n",
    "            input_variables: The input variables to use. Default is None.\n",
    "            **kwargs: Any additional keyword arguments to pass to the agent.\n",
    "\n",
    "        Returns:\n",
    "            An agent.\n",
    "        \"\"\"\n",
    "        cls._validate_tools(tools)\n",
    "        prompt = cls.create_prompt(\n",
    "            tools,\n",
    "            ai_prefix=ai_prefix,\n",
    "            human_prefix=human_prefix,\n",
    "            prefix=prefix,\n",
    "            suffix=suffix,\n",
    "            format_instructions=format_instructions,\n",
    "            input_variables=input_variables,\n",
    "        )\n",
    "        llm_chain = LLMChain(  # type: ignore[misc]\n",
    "            llm=llm,\n",
    "            prompt=prompt,\n",
    "            callback_manager=callback_manager,\n",
    "        )\n",
    "        tool_names = [tool.name for tool in tools]\n",
    "        _output_parser = output_parser or cls._get_default_output_parser(\n",
    "            ai_prefix=ai_prefix\n",
    "        )\n",
    "        return cls(\n",
    "            llm_chain=llm_chain,\n",
    "            allowed_tools=tool_names,\n",
    "            ai_prefix=ai_prefix,\n",
    "            output_parser=_output_parser,\n",
    "            **kwargs,\n",
    "        )\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import importlib.util\n",
    "\n",
    "# Save the code as a file\n",
    "with open(\"agent_code.py\", \"w\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "# Dynamically load the module\n",
    "spec = importlib.util.spec_from_file_location(\"agent_code\", \"agent_code.py\")\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods: ['__copy__', '__deepcopy__', '__delattr__', '__eq__', '__getattr__', '__getstate__', '__init__', '__iter__', '__pretty__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__str__', '_calculate_keys', '_check_frozen', '_construct_scratchpad', '_copy_and_set_values', '_fix_text', '_iter', 'aplan', 'copy', 'dict', 'get_allowed_tools', 'get_full_inputs', 'json', 'model_copy', 'model_dump', 'model_dump_json', 'model_post_init', 'plan', 'return_stopped_response', 'save', 'tool_run_logging_kwargs', 'validate_prompt']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the class\n",
    "ConversationalAgent = getattr(module, \"ConversationalAgent\")\n",
    "\n",
    "# List all methods of the class\n",
    "methods = inspect.getmembers(ConversationalAgent, predicate=inspect.isfunction)\n",
    "print(\"Methods:\", [method[0] for method in methods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import importlib.util\n",
    "\n",
    "# Save the code as a file\n",
    "with open(\"agent_code.py\", \"w\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "# Dynamically load the module\n",
    "spec = importlib.util.spec_from_file_location(\"agent_code\", \"agent_code.py\")\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)\n",
    "\n",
    "# Retrieve the class\n",
    "ConversationalAgent = getattr(module, \"ConversationalAgent\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent_code.ConversationalAgent"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConversationalAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Code for method 'from_llm_and_tools':\n",
      "\n",
      "    @classmethod\n",
      "    def from_llm_and_tools(\n",
      "        cls,\n",
      "        llm: BaseLanguageModel,\n",
      "        tools: Sequence[BaseTool],\n",
      "        callback_manager: Optional[BaseCallbackManager] = None,\n",
      "        output_parser: Optional[AgentOutputParser] = None,\n",
      "        prefix: str = PREFIX,\n",
      "        suffix: str = SUFFIX,\n",
      "        format_instructions: str = FORMAT_INSTRUCTIONS,\n",
      "        ai_prefix: str = \"AI\",\n",
      "        human_prefix: str = \"Human\",\n",
      "        input_variables: Optional[List[str]] = None,\n",
      "        **kwargs: Any,\n",
      "    ) -> Agent:\n",
      "        \"\"\"Construct an agent from an LLM and tools.\n",
      "\n",
      "        Args:\n",
      "            llm: The language model to use.\n",
      "            tools: A list of tools to use.\n",
      "            callback_manager: The callback manager to use. Default is None.\n",
      "            output_parser: The output parser to use. Default is None.\n",
      "            prefix: The prefix to use in the prompt. Default is PREFIX.\n",
      "            suffix: The suffix to use in the prompt. Default is SUFFIX.\n",
      "            format_instructions: The format instructions to use.\n",
      "                Default is FORMAT_INSTRUCTIONS.\n",
      "            ai_prefix: The prefix to use before AI output. Default is \"AI\".\n",
      "            human_prefix: The prefix to use before human output.\n",
      "                Default is \"Human\".\n",
      "            input_variables: The input variables to use. Default is None.\n",
      "            **kwargs: Any additional keyword arguments to pass to the agent.\n",
      "\n",
      "        Returns:\n",
      "            An agent.\n",
      "        \"\"\"\n",
      "        cls._validate_tools(tools)\n",
      "        prompt = cls.create_prompt(\n",
      "            tools,\n",
      "            ai_prefix=ai_prefix,\n",
      "            human_prefix=human_prefix,\n",
      "            prefix=prefix,\n",
      "            suffix=suffix,\n",
      "            format_instructions=format_instructions,\n",
      "            input_variables=input_variables,\n",
      "        )\n",
      "        llm_chain = LLMChain(  # type: ignore[misc]\n",
      "            llm=llm,\n",
      "            prompt=prompt,\n",
      "            callback_manager=callback_manager,\n",
      "        )\n",
      "        tool_names = [tool.name for tool in tools]\n",
      "        _output_parser = output_parser or cls._get_default_output_parser(\n",
      "            ai_prefix=ai_prefix\n",
      "        )\n",
      "        return cls(\n",
      "            llm_chain=llm_chain,\n",
      "            allowed_tools=tool_names,\n",
      "            ai_prefix=ai_prefix,\n",
      "            output_parser=_output_parser,\n",
      "            **kwargs,\n",
      "        )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to get the full source code of a specific method\n",
    "def get_method_source(class_obj, method_name):\n",
    "    \"\"\"Retrieve the full source code of a method from a class.\"\"\"\n",
    "    try:\n",
    "        method = getattr(class_obj, method_name)\n",
    "        return inspect.getsource(method)\n",
    "    except AttributeError:\n",
    "        return f\"Method '{method_name}' not found.\"\n",
    "    except TypeError:\n",
    "        return f\"Could not retrieve source for '{method_name}'.\"\n",
    "\n",
    "# Example Usage: Get the code for a specific method\n",
    "method_name = \"from_llm_and_tools\"  # Change this to the method you want\n",
    "# ConversationalAgent = 'agent_code.ConversationalAgent'\n",
    "\n",
    "method_code = get_method_source(ConversationalAgent, method_name)\n",
    "\n",
    "print(f\"\\nCode for method '{method_name}':\\n\")\n",
    "print(method_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'ConversationalAgent' found in: ./agent_code.py\n",
      "\n",
      "Could not retrieve source for class 'ConversationalAgent'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import inspect\n",
    "import importlib.util\n",
    "\n",
    "def find_python_files(root_dir):\n",
    "    \"\"\"Find all Python files in the root directory and subdirectories.\"\"\"\n",
    "    python_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            if file.endswith(\".py\"):\n",
    "                python_files.append(os.path.join(dirpath, file))\n",
    "    return python_files\n",
    "\n",
    "def load_module_from_path(file_path):\n",
    "    \"\"\"Dynamically load a Python module from a file path.\"\"\"\n",
    "    module_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    try:\n",
    "        spec.loader.exec_module(module)\n",
    "        return module\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_class_source(module, class_name):\n",
    "    \"\"\"Retrieve the source code of a class if it exists in a module.\"\"\"\n",
    "    class_obj = getattr(module, class_name, None)\n",
    "    if class_obj:\n",
    "        try:\n",
    "            return inspect.getsourcefile(ConversationalAgent)\n",
    "        except TypeError:\n",
    "            return f\"Could not retrieve source for class '{class_name}'.\"\n",
    "    return None\n",
    "\n",
    "def search_for_class(root_dir, class_name=\"ConversationalAgent\"):\n",
    "    \"\"\"Search for the given class in all Python files within the root directory.\"\"\"\n",
    "    python_files = find_python_files(root_dir)\n",
    "    for file in python_files:\n",
    "        module = load_module_from_path(file)\n",
    "        if module:\n",
    "            class_source = get_class_source(module, class_name)\n",
    "            if class_source:\n",
    "                print(f\"Class '{class_name}' found in: {file}\\n\")\n",
    "                print(class_source)\n",
    "                return  # Stop after finding the first occurrence\n",
    "    print(f\"Class '{class_name}' not found in any file.\")\n",
    "\n",
    "# Run the search\n",
    "root_repo_path = \"./\"  # Change this to your actual repo path\n",
    "search_for_class(root_repo_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'ConversationalAgent' not found in any file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import inspect\n",
    "import importlib.util\n",
    "\n",
    "def find_python_files(root_dir):\n",
    "    \"\"\"Find all Python files in the root directory and subdirectories.\"\"\"\n",
    "    python_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            if file.endswith(\".py\"):\n",
    "                python_files.append(os.path.join(dirpath, file))\n",
    "    return python_files\n",
    "\n",
    "def load_module_from_path(file_path):\n",
    "    \"\"\"Dynamically load a Python module from a file path.\"\"\"\n",
    "    module_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    try:\n",
    "        spec.loader.exec_module(module)\n",
    "        return module\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_class_source(module, search_name):\n",
    "    \"\"\"Retrieve the source code of a class if it exists in a module.\"\"\"\n",
    "    class_obj = getattr(module, search_name, None)\n",
    "    if class_obj:\n",
    "        try:\n",
    "            return inspect.getsource(class_obj)  # Extract class definition only\n",
    "        except TypeError:\n",
    "            return None  # Unable to get source, likely a built-in or compiled class\n",
    "    return None\n",
    "\n",
    "def search_for_class(root_dir, search_name):\n",
    "    \"\"\"Search for the given class in all Python files within the root directory.\"\"\"\n",
    "    python_files = find_python_files(root_dir)\n",
    "    for file in python_files:\n",
    "        module = load_module_from_path(file)\n",
    "        if module:\n",
    "            class_source = get_class_source(module, search_name)\n",
    "            if class_source:\n",
    "                print(f\"Class '{search_name}' found in: {file}\\n\")\n",
    "                print(class_source)  # Print only the class definition\n",
    "                return  # Stop after finding the first occurrence\n",
    "    print(f\"Class '{search_name}' not found in any file.\")\n",
    "\n",
    "# Run the search\n",
    "root_repo_path = \"./\"  # Change this to your actual repo path\n",
    "search_for_class(root_repo_path, search_name = 'ConversationalAgent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'ConversationalAgent'\n",
    "class_obj = getattr(module, class_name, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent_code.ConversationalAgent"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'_agent_type' found in class 'Agent' in: ./agent_code.py\n",
      "\n",
      "    @property\n",
      "    def _agent_type(self) -> str:\n",
      "        \"\"\"Return Identifier of an agent type.\"\"\"\n",
      "        raise NotImplementedError\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import inspect\n",
    "import importlib.util\n",
    "\n",
    "def find_python_files(root_dir):\n",
    "    \"\"\"Find all Python files in the root directory and subdirectories.\"\"\"\n",
    "    python_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            if file.endswith(\".py\"):\n",
    "                python_files.append(os.path.join(dirpath, file))\n",
    "    return python_files\n",
    "\n",
    "def load_module_from_path(file_path):\n",
    "    \"\"\"Dynamically load a Python module from a file path.\"\"\"\n",
    "    module_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    try:\n",
    "        spec.loader.exec_module(module)\n",
    "        return module\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_source(obj):\n",
    "    \"\"\"Retrieve the source code of a function, method, class, or property.\"\"\"\n",
    "    try:\n",
    "        if isinstance(obj, classmethod):\n",
    "            return inspect.getsource(obj.__func__)  # Unwrap class method\n",
    "        elif isinstance(obj, staticmethod):\n",
    "            return inspect.getsource(obj.__func__)  # Unwrap static method\n",
    "        elif isinstance(obj, property):\n",
    "            return inspect.getsource(obj.fget)  # Get property getter\n",
    "        else:\n",
    "            return inspect.getsource(obj)  # Default for functions, methods, classes\n",
    "    except TypeError:\n",
    "        return None  # If the object is not directly accessible\n",
    "\n",
    "def search_for_name(root_dir, name):\n",
    "    \"\"\"Search for a class, function, or method in all Python files within the root directory.\"\"\"\n",
    "    python_files = find_python_files(root_dir)\n",
    "    \n",
    "    for file in python_files:\n",
    "        module = load_module_from_path(file)\n",
    "        if not module:\n",
    "            continue\n",
    "        \n",
    "        # 1️⃣ First, search for a class or function at the module level\n",
    "        obj = getattr(module, name, None)\n",
    "        if obj:\n",
    "            source_code = get_source(obj)\n",
    "            if source_code:\n",
    "                print(f\"'{name}' found in: {file}\\n\")\n",
    "                print(source_code)\n",
    "                return  # Stop after finding the first occurrence\n",
    "\n",
    "        # 2️⃣ Next, search inside classes for methods and properties\n",
    "        for class_name, class_obj in inspect.getmembers(module, inspect.isclass):\n",
    "            # Search for class methods, instance methods, and properties\n",
    "            for method_name, method_obj in inspect.getmembers(class_obj):\n",
    "                if method_name == name:\n",
    "                    source_code = get_source(method_obj)\n",
    "                    if source_code:\n",
    "                        print(f\"'{name}' found in class '{class_name}' in: {file}\\n\")\n",
    "                        print(source_code)\n",
    "                        return  # Stop after finding the first occurrence\n",
    "\n",
    "    print(f\"'{name}' not found in any file.\")\n",
    "\n",
    "# Run the search\n",
    "root_repo_path = \"./\"  # Change this to your actual repo path\n",
    "search_for_name(root_repo_path, \"_agent_type\")  # Change to search for any class, method, or function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ConversationalAgent' not found in any file.\n"
     ]
    }
   ],
   "source": [
    "search_for_name(root_repo_path, \"ConversationalAgent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
