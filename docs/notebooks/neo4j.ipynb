{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graph-RAG with Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to Natural Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── src/\n",
      "│   ├── deduplication/\n",
      "│   │   ├── bloom_filter.py\n",
      "│   │   ├── dedup.py\n",
      "│   │   ├── LSH.py\n",
      "│   │   ├── LSHForest.py\n",
      "│   │   ├── LSHImproved.py\n",
      "│   │   ├── __init__.py\n",
      "│   │   ├── __main__.py\n",
      "│   ├── utils/\n",
      "│   │   ├── use_cases.py\n",
      "│   │   ├── utils.py\n",
      "│   │   ├── visualizations.py\n",
      "│   │   ├── visualization_lsh.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def generate_repo_tree(repo_path, indent=\"\"):\n",
    "    tree_string = \"\"\n",
    "    for root, dirs, files in os.walk(repo_path):\n",
    "        # Filter out __pycache__ and hidden directories\n",
    "        dirs[:] = [d for d in dirs if d != \"__pycache__\" and not d.startswith(\".\")]\n",
    "        files = [f for f in files if not f.startswith(\".\")]\n",
    "\n",
    "        level = root.replace(repo_path, \"\").count(os.sep)\n",
    "        indent = \"│   \" * level + \"├── \"  # Formatting the tree\n",
    "        tree_string += f\"{indent}{os.path.basename(root)}/\\n\"\n",
    "\n",
    "        sub_indent = \"│   \" * (level + 1) + \"├── \"\n",
    "        for file in files:\n",
    "            tree_string += f\"{sub_indent}{file}\\n\"\n",
    "\n",
    "    return tree_string\n",
    "\n",
    "# Set your repo path\n",
    "repo_path = \"./assignment-2-mcdonald-s/src\"  # Change this to your cloned repo path\n",
    "\n",
    "# Generate tree and store as string\n",
    "repo_tree_string = generate_repo_tree(repo_path)\n",
    "\n",
    "# Print the repo tree\n",
    "print(repo_tree_string)\n",
    "\n",
    "# Store it as a variable to feed into an LLM\n",
    "# llm_input = f\"Here is the repository structure:\\n{repo_tree_string}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "    You are an expert in analyzing Python code and generating structured natural language descriptions for graph-based querying in Cypher. \n",
    "    Given a Python codebase, extract meaningful relationships between functions, classes, and imported modules. \n",
    "    \n",
    "    Only use the list of types provided below:\n",
    "    - class : classes defined in a module\n",
    "    - method : methods defined in a class\n",
    "    - function : functions defined in a module\n",
    "    - module : python scripts defined within the repository. Exclude .py when mentioning the module name.\n",
    "    - package : packages imported that are not modules.\n",
    "    Do not include information on variables, parameters, arguments.\n",
    "    Python scripts must be modules and pre defined packages such as numpy and pandas must be packages\n",
    "\n",
    "    When generating the structured natural language description, follow these rules:    \n",
    "    - Do not give explanations for the code logic or functionality.\n",
    "    - Do not use adjectives and adverbs. \n",
    "    - Only describe the code and do not give an overall summary.\n",
    "    - Do not use ambiguous pronouns and use exact names in every description.\n",
    "    - Explain each class, function separately and do not include explanations such as 'as mentioned before' or anything that refers to a previous explanation.\n",
    "    - make each description sufficient for a standalone statement for one relationship in the graph.    \n",
    "    - Each class and funciton should be connected to the module where it was defined.\n",
    "    - Each imported package should be connected to the function, method or class where it was used.\n",
    "    - Always include an explanation on how the outermost class or method is connected to the module where it is defined.\n",
    "    - If the outermost layer is an 'if __name__ == \"__main__\":' block, then the outermost layer is whatever is inside the block. Plus whatever is defined outside the block. Make sure to mention the connection between the module and the closses and functions.\n",
    "    - When mentioning modules, take note of the current file path(relative repository) given in input, and change slashes to dots and remove the .py extension.\n",
    "    - If a function or class is used in another function or class, make sure to mention the connection between them.\n",
    "    - \n",
    "            \n",
    "    Natural language should follow a similar format as below:\n",
    "        {source.id} is a {source.type} with properties {source.properties} defined in {target.id} which is a {target.type}.        \n",
    "    Example: \n",
    "    - When mentioning classes, always refer them as {relative_repository}.{module_name}.{class_name}\n",
    "    - When mentioning methods, always refer to them as {relative_repository}.{module_name}.{class_name}.{method_name}\n",
    "    - When mentioning functions, always refer them as {relative_repository}.{module_name}.{function_name}\n",
    "    - If the file path is deduplication/LSH.py and there is a class LSH in it, the module is deduplication.LSH and the class is deduplication.LSH.LSH.\n",
    "\n",
    "    Example:\n",
    "    deduplication.LSHImproved.LSHImproved is a module that defines the class deduplication.LSH.lsh_base, which consists of  method deduplication.LSH.lsh_base.hash_function.\n",
    "    deduplication.LSH.lsh_base is a class and inherits from the class utils.utils.BaseLSH.\n",
    "    numpy is a package and is used in the method deduplication.LSH.lsh_base.hash_function.\n",
    "    bitarray is a package and is used in the deduplication.bloom_filter.BloomFilter_KM_Opt.__init__ method of the class deduplication.bloom_filter.BloomFilter_KM_Opt.  \n",
    "    deduplication.LSH.lsh_base is a class defined in the module deduplication.LSH.\n",
    "    \n",
    "    If a module from our repository is imported in another module in our repository, refer to it as the entire path of the module.\n",
    "    Example:\n",
    "    code within deduplication\\\\__main__.py : from deduplication.LSHImproved import LSHImproved\n",
    "    Natural Language Description:\n",
    "    The Class deduplication.LSHImproved.LSHImproved is imported into the module deduplication.__main__.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "i = 0\n",
    "descriptions = {}\n",
    "\n",
    "for root, dirs, files in os.walk(repo_path):\n",
    "    \n",
    "    # Skip hidden directories (e.g., .git, .idea, __pycache__)\n",
    "    dirs[:] = [d for d in dirs if not d.startswith(\".\") and d != \"__pycache__\"]\n",
    "\n",
    "    for file in files:\n",
    "        if file.startswith(\".\"):\n",
    "            continue  # Skip hidden files\n",
    "\n",
    "        file_path = os.path.join(root, file)\n",
    "        relative_path = os.path.relpath(file_path, repo_path)\n",
    "        print(relative_path)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                lsh_code = f.read()\n",
    "\n",
    "            messages = [\n",
    "                SystemMessage(system_prompt),\n",
    "                HumanMessage(f'''\n",
    "                    Tree:\n",
    "                    {repo_tree_string}\n",
    "\n",
    "                    Current File Path:\n",
    "                    {relative_path}\n",
    "\n",
    "                    Code:\n",
    "                    {lsh_code}\n",
    "                ''')\n",
    "            ]\n",
    "\n",
    "            response = llm.invoke(messages)\n",
    "            descriptions[relative_path] = response.content\n",
    "            i += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "        \n",
    "        # if i > 1:\n",
    "        #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in descriptions:\n",
    "    print(i)\n",
    "    print(descriptions[i])\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are an expert text editor. Your goal is to modyfy the text in a way that it is consistent with the given repository tree and file path.\n",
    "    Keep in mind this natural language is meant to be used for graph-based querying in Cypher.\n",
    "    Only output the modified text, do not give any explanations or anything else.\n",
    "    The only change you have to make is to modify potential node ids, so they are consistent and can be connected by a graph.\n",
    "    \n",
    "    Rules:\n",
    "    - When mentioning modules, take note of the current file path(relative repository) given in input, and change slashes to dots and remove the .py extension.\n",
    "    - This means that the current file path or module name should be the beginning of all classes/methods/functions defined in the module.    \n",
    "    - When mentioning classes, always refer them as {module_location_name}.{class_name}\n",
    "    - When mentioning methods, always refer to them as {module_location_name}.{class_name}.{method_name}\n",
    "    - When mentioning functions, always refer them as {module_location_name}.{function_name}\n",
    "\n",
    "    Example: \n",
    "    - if the relative path is deduplication/LSH.py and there is a class LSH in it, the module is deduplication.LSH and the class is deduplication.LSH.LSH.\n",
    "    - Given the current file path deduplication\\\\dedup.py\n",
    "        'deduplication.Baseline is a class defined in deduplication.dedup' is extremely incorrect. \n",
    "        The correct description is 'deduplication.dedup.Baseline is a class defined in deduplication.dedup'\n",
    "    \n",
    "    \n",
    "    Example:\n",
    "    - If the file location is deduplication/LSH.py and there is a class LSH in it, the module should be deduplication.LSH and the class should be deduplication.LSH.LSH. in the natural language description.\n",
    "    - If the original text is bloom_filter.BloomFilter is a class, and the current file is deduplication\\\\bloom_filter.py, the modified text should be deduplication.bloom_filter.BloomFilter is a class.\n",
    "    - If my current module imports a function from a module 'utils.utils import clean_document' the modified text should be utils.utils.clean_document is a function.\n",
    "\"\"\"\n",
    "\n",
    "refined_descriptions = {}\n",
    "for i in descriptions:\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(system_prompt),\n",
    "        HumanMessage(f'''\n",
    "                     \n",
    "            Repository Tree:\n",
    "            {repo_tree_string}\n",
    "\n",
    "            Current File Path:\n",
    "            {i}\n",
    "\n",
    "            Natural Language Desccription:\n",
    "            {descriptions[i]}\n",
    "        ''')\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    refined_descriptions[i] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in refined_descriptions:\n",
    "    print(i)\n",
    "    print(refined_descriptions[i])\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "description_document = []\n",
    "# for i in descriptions:\n",
    "for i in refined_descriptions:\n",
    "    \n",
    "    document = Document(\n",
    "        # page_content = descriptions[i],\n",
    "        page_content = refined_descriptions[i],\n",
    "        metadata = {\"source\": i}\n",
    "    )\n",
    "    \n",
    "    description_document.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     # Set a really small chunk size, just to show.\n",
    "#     chunk_size=1000,\n",
    "#     # chunk_overlap=100,\n",
    "#     length_function=len,\n",
    "#     is_separator_regex=False,\n",
    "# )\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     separators=[\n",
    "#         r\"\\n\\n\",\n",
    "#         r\"\\n\",\n",
    "#         r\"\\\\n\"\n",
    "#     ],\n",
    "#     is_separator_regex=True,\n",
    "#     keep_separator=False,\n",
    "#     chunk_size=500,\n",
    "#     chunk_overlap=0,\n",
    "# )\n",
    "\n",
    "# docs = text_splitter.create_documents([description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language to GraphDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate, PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "a = \"\"\"# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrificing accuracy. Do not add any information that is not explicitly mentioned in the text.\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'.- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.\\n\"\"\"\n",
    "# Define the prompt template with variables\n",
    "system_prompt = a\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(system_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"\"\"\n",
    "                A period does not mean an end of a sentence. It is part of a node id. Only a line break means an end of a sentence.\n",
    "                Take this into account when identifying node ids.\n",
    "\n",
    "                When translating names into node ids, do not shorten anything. use the entire name as it is.\n",
    "                For example, if the class name is deduplication.LSHForest.LSHForest, do not shorten it to LSHForest or deduplication.LSHForest.\n",
    "                Use the full name deduplication.LSHForest.LSHForest.\n",
    "                Here is the text to analyze:\\n\\n{input}\"\"\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"class\", \"method\", \"function\",'package','module'],\n",
    "    # allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    "    # node_properties=['defined_in'],\n",
    "    # prompt=chat_prompt\n",
    ")\n",
    "\n",
    "\n",
    "# llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "# logger.info(f\"documents:{documents}\")\n",
    "# graph_documents = llm_transformer.convert_to_graph_documents(docs)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(description_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_documents[6].relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refined_descriptions['deduplication\\\\LSHForest.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create Pyvis network\n",
    "net = Network(notebook=True, cdn_resources='in_line', height=\"1000px\", width=\"100%\")\n",
    "\n",
    "# Create a NetworkX graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Dictionary to track unique nodes and metadata\n",
    "node_metadata = {}\n",
    "\n",
    "# Helper to create a hashable key from type, id, and properties\n",
    "def make_node_key(node):\n",
    "    return (\n",
    "        node.type,\n",
    "        node.id,\n",
    "        tuple(sorted(node.properties.items()))\n",
    "    )\n",
    "\n",
    "# Add nodes and edges\n",
    "for graph in graph_documents:\n",
    "    for rel in graph.relationships:\n",
    "        if rel.source.type == \"Package\" or rel.target.type == \"Package\":\n",
    "            continue  # Skip packages entirely\n",
    "        # Get full, unique node keys\n",
    "        source_key = make_node_key(rel.source)\n",
    "        target_key = make_node_key(rel.target)\n",
    "        rel_type = rel.type\n",
    "\n",
    "        # Store node metadata\n",
    "        node_metadata[source_key] = {\n",
    "            \"id\": rel.source.id,\n",
    "            \"type\": rel.source.type,\n",
    "            \"properties\": rel.source.properties\n",
    "        }\n",
    "        node_metadata[target_key] = {\n",
    "            \"id\": rel.target.id,\n",
    "            \"type\": rel.target.type,\n",
    "            \"properties\": rel.target.properties\n",
    "        }\n",
    "\n",
    "        # Add nodes and edges\n",
    "        G.add_node(source_key)\n",
    "        G.add_node(target_key)\n",
    "        G.add_edge(source_key, target_key, label=rel_type)\n",
    "\n",
    "# Get unique types for coloring\n",
    "unique_types = list(set(meta[\"type\"] for meta in node_metadata.values()))\n",
    "color_map = plt.get_cmap(\"tab10\")\n",
    "type_colors = {t: color_map(i / len(unique_types)) for i, t in enumerate(unique_types)}\n",
    "type_colors_rgba = {\n",
    "    t: f'rgba({int(c[0]*255)}, {int(c[1]*255)}, {int(c[2]*255)}, 0.8)' for t, c in type_colors.items()\n",
    "}\n",
    "\n",
    "# Degree-based sizing\n",
    "degrees = dict(G.degree())\n",
    "min_size, max_size = 10, 50\n",
    "max_degree = max(degrees.values()) if degrees else 1\n",
    "size_scale = {\n",
    "    node: min_size + (max_size - min_size) * (deg / max_degree)\n",
    "    for node, deg in degrees.items()\n",
    "}\n",
    "\n",
    "# Add nodes to Pyvis\n",
    "for node_key in G.nodes():\n",
    "    metadata = node_metadata[node_key]\n",
    "    label = metadata[\"id\"]\n",
    "    node_type = metadata[\"type\"]\n",
    "    properties = metadata.get(\"properties\", {})\n",
    "    color = type_colors_rgba.get(node_type, \"gray\")\n",
    "\n",
    "    # Property display\n",
    "    props_html = \"<br>\".join(f\"{k}: {v}\" for k, v in properties.items()) if properties else \"No properties\"\n",
    "\n",
    "    net.add_node(\n",
    "        str(node_key),  # string key for Pyvis\n",
    "        label=label,\n",
    "        size=size_scale[node_key],\n",
    "        color=color,\n",
    "        title=f\"<b>{node_type}</b> ({label})<br>{props_html}\"\n",
    "    )\n",
    "\n",
    "# Add edges\n",
    "for source, target, attr in G.edges(data=True):\n",
    "    rel_label = attr.get(\"label\", \"\")\n",
    "    net.add_edge(str(source), str(target), title=rel_label, label=rel_label)\n",
    "\n",
    "# Save graph\n",
    "net.save_graph(\"graph_simple.html\")\n",
    "\n",
    "# Build legend\n",
    "legend_html = \"\"\"\n",
    "<div id=\"legend\" style=\"position: absolute; top: 10px; left: 10px; background: white; padding: 10px; border-radius: 8px; box-shadow: 0px 0px 5px rgba(0,0,0,0.2); font-family: Arial, sans-serif; z-index: 1000;\">\n",
    "    <h4 style=\"margin: 0; padding-bottom: 5px;\">Node Legend</h4>\n",
    "\"\"\"\n",
    "\n",
    "for node_type, color in type_colors_rgba.items():\n",
    "    legend_html += f'<div style=\"display: flex; align-items: center; margin-bottom: 5px;\"><div style=\"width: 15px; height: 15px; background:{color}; margin-right: 5px; border-radius: 50%;\"></div> {node_type}</div>'\n",
    "\n",
    "legend_html += \"</div>\"\n",
    "\n",
    "# Inject legend\n",
    "with open(\"graph_simple.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "html_content = html_content.replace(\"</body>\", legend_html + \"</body>\")\n",
    "\n",
    "with open(\"graph_simple.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(html_content)\n",
    "\n",
    "print(\"Graph with fully disambiguated nodes saved as graph_simple.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# URI = os.getenv(\"NEO4J_URI\")\n",
    "# USER = os.getenv(\"NEO4J_USERNAME\")\n",
    "# PWD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# print(\"Trying:\", URI)\n",
    "\n",
    "# driver = GraphDatabase.driver(uri=URI, auth=(USER, PWD))\n",
    "\n",
    "# try:\n",
    "#     driver.verify_connectivity()\n",
    "#     print(\"✅ Connected to Aura!\")\n",
    "# except Exception as e:\n",
    "#     print(\"❌ Still not working:\", e)\n",
    "# finally:\n",
    "#     driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create / Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# You can pass the path if the file isn't in the same directory\n",
    "load_dotenv(dotenv_path='../../.env')\n",
    "\n",
    "# Access your variables\n",
    "url = os.getenv('NEO4J_URI')\n",
    "username = os.getenv('NEO4J_USERNAME')\n",
    "password = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "enhanced_graph = Neo4jGraph(url=url, username=username, password=password, enhanced_schema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add graphdocuments do Neo4j Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents\n",
    "# graph.add_graph_documents(graph_documents)\n",
    "\n",
    "\n",
    "\n",
    "# graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "# graph.query(QUERY, genre=\"action\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "- **Class**\n",
      "  - `id`: STRING Example: \"Deduplication.Bloom_Filter.Bloomfilter\"\n",
      "- **Method**\n",
      "  - `id`: STRING Example: \"Deduplication.Bloom_Filter.Bloomfilter.__Init__\"\n",
      "- **Package**\n",
      "  - `id`: STRING Example: \"Math\"\n",
      "- **Module**\n",
      "  - `id`: STRING Available options: ['Deduplication.Lsh', 'Utils.Utils', 'Joblib', 'Deduplication.__Init__', 'Deduplication.__Main__', 'Utils.Use_Cases', 'Src.Utils.Utils', 'Utils.Visualizations', 'Utils.Visualization_Lsh']\n",
      "- **Function**\n",
      "  - `id`: STRING Example: \"Utils.Utils.Split_Dict\"\n",
      "- **Chunk**\n",
      "  - `id`: STRING Available options: ['d66006059fd78d63f3df90cc1059639a', '0e3dcb4502853979d12357690a95ec17', 'c438c6bcdcf8e4fab227f29f8e7ff204', '97fe701ec38057594464beaa2df0710e', 'b54f9286e684373498c4504b4edd9910', '5b50a72c3a4954b0ff7a0421be4f99b9', 'fb28d41771e717255f0d8f6c799ede32', '58e6f14dd2e6c6702cf333f2335c499c', '540d3356e5beffef02e4c68164709a8f']\n",
      "  - `text`: STRING Available options: ['How many artists are there?', 'Which actors played in the movie Casino?', 'How many movies has Tom Hanks acted in?', \"List all the genres of the movie Schindler's List\", 'Which actors have worked in movies from both the c', 'Which directors have made movies with at least thr', 'Identify movies where directors also played a role', 'Find the actor with the highest number of movies i', 'How is the Utils.Utils module related to the Dedup']\n",
      "  - `question`: STRING Available options: ['How many artists are there?', 'Which actors played in the movie Casino?', 'How many movies has Tom Hanks acted in?', \"List all the genres of the movie Schindler's List\", 'Which actors have worked in movies from both the c', 'Which directors have made movies with at least thr', 'Identify movies where directors also played a role', 'Find the actor with the highest number of movies i', 'How is the Utils.Utils module related to the Dedup']\n",
      "  - `query`: STRING Available options: ['MATCH (a:Person)-[:ACTED_IN]->(:Movie) RETURN coun', \"MATCH (m:Movie {title: 'Casino'})<-[:ACTED_IN]-(a)\", \"MATCH (a:Person {name: 'Tom Hanks'})-[:ACTED_IN]->\", \"MATCH (m:Movie {title: 'Schindler's List'})-[:IN_G\", 'MATCH (a:Person)-[:ACTED_IN]->(:Movie)-[:IN_GENRE]', 'MATCH (d:Person)-[:DIRECTED]->(m:Movie)<-[:ACTED_I', 'MATCH (p:Person)-[:DIRECTED]->(m:Movie), (p)-[:ACT', 'MATCH (a:Actor)-[:ACTED_IN]->(m:Movie) RETURN a.na', \"MATCH path = (m1:Module {id: 'Utils.Utils'})-[*..5\"]\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Class)-[:INCLUDES]->(:Method)\n",
      "(:Class)-[:USES]->(:Package)\n",
      "(:Class)-[:CONTAINS]->(:Method)\n",
      "(:Class)-[:INHERITS]->(:Class)\n",
      "(:Class)-[:DEFINES]->(:Method)\n",
      "(:Class)-[:IMPORTS]->(:Package)\n",
      "(:Class)-[:METHOD_OF]->(:Method)\n",
      "(:Class)-[:DEFINED_IN]->(:Module)\n",
      "(:Class)-[:DEFINED_IN]->(:Method)\n",
      "(:Method)-[:USES]->(:Package)\n",
      "(:Method)-[:USES]->(:Method)\n",
      "(:Method)-[:USES]->(:Module)\n",
      "(:Method)-[:USES]->(:Function)\n",
      "(:Method)-[:USED_IN]->(:Function)\n",
      "(:Method)-[:USED_IN]->(:Package)\n",
      "(:Method)-[:CALLS]->(:Method)\n",
      "(:Method)-[:CALLS]->(:Function)\n",
      "(:Method)-[:READS]->(:Class)\n",
      "(:Method)-[:PROCESSES]->(:Class)\n",
      "(:Method)-[:INITIALIZES]->(:Class)\n",
      "(:Method)-[:INITIALIZES]->(:Function)\n",
      "(:Method)-[:DEFINED_IN]->(:Class)\n",
      "(:Module)-[:CONTAINS]->(:Class)\n",
      "(:Module)-[:USES]->(:Package)\n",
      "(:Module)-[:DEFINES]->(:Function)\n",
      "(:Module)-[:DEFINES]->(:Method)\n",
      "(:Module)-[:IMPORTS]->(:Class)\n",
      "(:Module)-[:IMPORTS]->(:Function)\n",
      "(:Module)-[:IMPORTS]->(:Package)\n",
      "(:Module)-[:CALLS]->(:Function)\n",
      "(:Function)-[:USES]->(:Package)\n",
      "(:Function)-[:USES]->(:Class)\n",
      "(:Function)-[:USES]->(:Function)\n",
      "(:Function)-[:USES]->(:Module)\n",
      "(:Function)-[:CALLS]->(:Class)\n",
      "(:Function)-[:DEFINED_IN]->(:Module)\n",
      "(:Function)-[:USED_IN]->(:Package)\n"
     ]
    }
   ],
   "source": [
    "enhanced_graph.refresh_schema()\n",
    "print(enhanced_graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement GRAPH-RAG\n",
    "https://python.langchain.com/v0.1/docs/use_cases/graph/prompting/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual GraphRAG Chain**\n",
    "\n",
    "https://python.langchain.com/docs/tutorials/graph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GraphCypherQAChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How is the Utils.Utils module related to the Deduplicatioin.__Main__ module?',\n",
       " 'result': \"I don't know the answer.\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_neo4j import GraphCypherQAChain\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.chains.graph_qa.prompts import CYPHER_GENERATION_PROMPT, CYPHER_QA_PROMPT\n",
    "\n",
    "\n",
    "# from langchain_core.prompts import SystemMessagePromptTemplate, PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# cypher_prompt = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "# Instructions:\n",
    "# Use only the provided relationship types and properties in the schema.\n",
    "# Translate user input into available nodes.\n",
    "# Do not use any other relationship types or properties that are not provided.\n",
    "\n",
    "# Schema:\n",
    "# {schema}\n",
    "# Note: Do not include any explanations or apologies in your responses.\n",
    "\n",
    "# Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "# Do not include any text except the generated Cypher statement.\n",
    "\n",
    "# Guidelines:\n",
    "# Always try and use MATCH path ..... RETURN path to get the entire relationship and do not gnenerate query that returns paris of nodes.\n",
    "# Never use relationships that include packages : WHERE NONE(n IN nodes(path) WHERE n:Package)\n",
    "\n",
    "# Example:\n",
    "# Question : \"How is the Utils.Utils module related to the Deduplicatioin.__Main__ module?\"\n",
    "# Cypher Query : MATCH path = (m1:Module {{id: 'Utils.Utils'}})-[*..8]-(m2:Module {{id: 'Deduplication.__Main__'}}) WHERE NONE(n IN nodes(path) WHERE n:Package) RETURN path\n",
    "\n",
    "\n",
    "# The question is:\n",
    "# {question}\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(cypher_prompt)\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# chain = GraphCypherQAChain.from_llm(\n",
    "#     graph=enhanced_graph, \n",
    "#     llm=llm, \n",
    "#     verbose=True, \n",
    "#     allow_dangerous_requests=True, \n",
    "#     validate_cypher=True,\n",
    "#     # cypher_prompt=prompt\n",
    "# )\n",
    "# response = chain.invoke({\"query\": \"How is the Utils.Utils module related to the Deduplicatioin.__Main__ module?\"})\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = graph.query(\"\"\"\n",
    "# MATCH path = (m1:Module {id: 'Utils.Utils'})-[*..5]-(m2:Module {id: 'Deduplication.__Main__'}) WHERE NONE(n IN nodes(path) WHERE n:Package) RETURN path\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant that helps to form nice and human understandable answers.\n",
      "The information part contains the provided information that you must use to construct an answer.\n",
      "The provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
      "Make the answer sound as a response to the question. Do not mention that you based the result on the given information.\n",
      "Here is an example:\n",
      "\n",
      "Question: Which managers own Neo4j stocks?\n",
      "Context:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\n",
      "Helpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\n",
      "\n",
      "Follow this example when generating answers.\n",
      "If the provided information is empty, say that you don't know the answer.\n",
      "Information:\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "# print(CYPHER_QA_PROMPT.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizable GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from typing import Annotated, List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    question: str\n",
    "    next_action: str\n",
    "    cypher_statement: str\n",
    "    cypher_errors: List[str]\n",
    "    database_records: List[dict]\n",
    "    steps: Annotated[List[str], add]\n",
    "\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "    steps: List[str]\n",
    "    cypher_statement: str\n",
    "    cypher_results: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Literal\n",
    "\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from pydantic import BaseModel, Field\n",
    "\n",
    "# guardrails_system = \"\"\"\n",
    "# As an intelligent assistant, your primary objective is to decide whether a given question is related to a GRAPH database or not. \n",
    "# If the question is related, output \"graph\". Otherwise, output \"end\".\n",
    "# \"\"\"\n",
    "# guardrails_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             guardrails_system,\n",
    "#         ),\n",
    "#         (\n",
    "#             \"human\",\n",
    "#             (\"{question}\"),\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# class GuardrailsOutput(BaseModel):\n",
    "#     decision: Literal[\"movie\", \"end\"] = Field(\n",
    "#         description=\"Decision on whether the question is related to a graph database\"\n",
    "#     )\n",
    "\n",
    "\n",
    "# guardrails_chain = guardrails_prompt | llm.with_structured_output(GuardrailsOutput)\n",
    "\n",
    "\n",
    "# def guardrails(state: InputState) -> OverallState:\n",
    "#     \"\"\"\n",
    "#     Decides if the question is related to a graph database or not.\n",
    "#     \"\"\"\n",
    "#     guardrails_output = guardrails_chain.invoke({\"question\": state.get(\"question\")})\n",
    "#     database_records = None\n",
    "#     if guardrails_output.decision == \"end\":\n",
    "#         database_records = \"This questions is not about a graph database. Therefore I cannot answer this question.\"\n",
    "#     return {\n",
    "#         \"next_action\": guardrails_output.decision,\n",
    "#         \"database_records\": database_records,\n",
    "#         \"steps\": [\"guardrail\"],\n",
    "\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_neo4j import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"How is the Utils.Utils module related to the Deduplicatioin.__Main__ module?\",\n",
    "        \"query\": \"MATCH path = (m1:Module {id: 'Utils.Utils'})-[*..5]-(m2:Module {id: 'Deduplication.__Main__'}) WHERE NONE(n IN nodes(path) WHERE n:Package) RETURN path\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How is the Utils.Utils module related to the Deduplicatioin.__Main__ module?\",\n",
    "        \"query\": \"MATCH path = (m1:Module {id: 'Utils.Utils'})-[*..5]-(m2:Module {id: 'Deduplication.__Main__'}) WHERE NONE(n IN nodes(path) WHERE n:Package) RETURN path\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples, OpenAIEmbeddings(), Neo4jVector, k=5, input_keys=[\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "text2cypher_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"Given an input question, convert it to a Cypher query. No pre-amble.\"\n",
    "                \"Do not wrap the response in any backticks or anything else. Respond with a Cypher statement only!\"\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"\"\"You are a Neo4j expert. Given an input question, create a syntactically correct Cypher query to run.\n",
    "                Do not wrap the response in any backticks or anything else. Respond with a Cypher statement only!\n",
    "                Here is the schema information\n",
    "                {schema}\n",
    "                \n",
    "                Below are a number of examples of questions and their corresponding Cypher queries.\n",
    "                {fewshot_examples}\n",
    "                \n",
    "                User input: {question}\n",
    "                Cypher query:\"\"\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "text2cypher_chain = text2cypher_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "def generate_cypher(state: OverallState) -> OverallState:\n",
    "    \"\"\"\n",
    "    Generates a cypher statement based on the provided schema and user input\n",
    "    \"\"\"\n",
    "    NL = \"\\n\"\n",
    "    fewshot_examples = (NL * 2).join(\n",
    "        [\n",
    "            f\"Question: {el['question']}{NL}Cypher:{el['query']}\"\n",
    "            for el in example_selector.select_examples(\n",
    "                {\"question\": state.get(\"question\")}\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    generated_cypher = text2cypher_chain.invoke(\n",
    "        {\n",
    "            \"question\": state.get(\"question\"),\n",
    "            \"fewshot_examples\": fewshot_examples,\n",
    "            \"schema\": enhanced_graph.schema,\n",
    "        }\n",
    "    )\n",
    "    print(generated_cypher)\n",
    "    return {\"cypher_statement\": generated_cypher, \"steps\": [\"generate_cypher\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "validate_cypher_system = \"\"\"\n",
    "You are a Cypher expert reviewing a statement written by a junior developer.\n",
    "\"\"\"\n",
    "\n",
    "validate_cypher_user = \"\"\"You must check the following:\n",
    "* Are there any syntax errors in the Cypher statement?\n",
    "* Are there any missing or undefined variables in the Cypher statement?\n",
    "* Are any node labels missing from the schema?\n",
    "* Are any relationship types missing from the schema?\n",
    "* Are any of the properties not included in the schema?\n",
    "* Does the Cypher statement include enough information to answer the question?\n",
    "\n",
    "Examples of good errors:\n",
    "* Label (:Foo) does not exist, did you mean (:Bar)?\n",
    "* Property bar does not exist for label Foo, did you mean baz?\n",
    "* Relationship FOO does not exist, did you mean FOO_BAR?\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "The question is:\n",
    "{question}\n",
    "\n",
    "The Cypher statement is:\n",
    "{cypher}\n",
    "\n",
    "Make sure you don't make any mistakes!\"\"\"\n",
    "\n",
    "validate_cypher_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            validate_cypher_system,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (validate_cypher_user),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class Property(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a filter condition based on a specific node property in a graph in a Cypher statement.\n",
    "    \"\"\"\n",
    "\n",
    "    node_label: str = Field(\n",
    "        description=\"The label of the node to which this property belongs.\"\n",
    "    )\n",
    "    property_key: str = Field(description=\"The key of the property being filtered.\")\n",
    "    property_value: str = Field(\n",
    "        description=\"The value that the property is being matched against.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ValidateCypherOutput(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the validation result of a Cypher query's output,\n",
    "    including any errors and applied filters.\n",
    "    \"\"\"\n",
    "\n",
    "    errors: Optional[List[str]] = Field(\n",
    "        description=\"A list of syntax or semantical errors in the Cypher statement. Always explain the discrepancy between schema and Cypher statement\"\n",
    "    )\n",
    "    filters: Optional[List[Property]] = Field(\n",
    "        description=\"A list of property-based filters applied in the Cypher statement.\"\n",
    "    )\n",
    "\n",
    "\n",
    "validate_cypher_chain = validate_cypher_prompt | llm.with_structured_output(\n",
    "    ValidateCypherOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j.chains.graph_qa.cypher_utils import CypherQueryCorrector, Schema\n",
    "\n",
    "# Cypher query corrector is experimental\n",
    "corrector_schema = [Schema(el[\"start\"], el[\"type\"], el[\"end\"]) for el in enhanced_graph.structured_schema.get(\"relationships\")]\n",
    "cypher_query_corrector = CypherQueryCorrector(corrector_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_statement = \"MATCH path = (m1:Module {id: 'Utils.Utils'})-[*..5]-(m2:Module {id: 'Deduplication.__Main__'}) WHERE NONE(n IN nodes(path) WHERE n:Package) RETURN path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cypher_query_corrector(cypher_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_graph.query(f\"EXPLAIN {cypher_statement}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j.exceptions import CypherSyntaxError\n",
    "\n",
    "\n",
    "def validate_cypher(state: OverallState) -> OverallState:\n",
    "    \"\"\"\n",
    "    Validates the Cypher statements and maps any property values to the database.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    mapping_errors = []\n",
    "    # Check for syntax errors\n",
    "    try:\n",
    "        enhanced_graph.query(f\"EXPLAIN {state.get('cypher_statement')}\")\n",
    "    except CypherSyntaxError as e:\n",
    "        errors.append(e.message)\n",
    "    # # Experimental feature for correcting relationship directions\n",
    "    # corrected_cypher = cypher_query_corrector(state.get(\"cypher_statement\"))\n",
    "    # if not corrected_cypher:\n",
    "    #     errors.append(\"The generated Cypher statement doesn't fit the graph schema\")\n",
    "    # if not corrected_cypher == state.get(\"cypher_statement\"):\n",
    "    #     print(\"Relationship direction was corrected\")\n",
    "    # Use LLM to find additional potential errors and get the mapping for values\n",
    "    llm_output = validate_cypher_chain.invoke(\n",
    "        {\n",
    "            \"question\": state.get(\"question\"),\n",
    "            \"schema\": enhanced_graph.schema,\n",
    "            \"cypher\": state.get(\"cypher_statement\"),\n",
    "        }\n",
    "    )\n",
    "    if llm_output.errors:\n",
    "        errors.extend(llm_output.errors)\n",
    "    if llm_output.filters:\n",
    "        for filter in llm_output.filters:\n",
    "            # Do mapping only for string values\n",
    "            if (\n",
    "                not [\n",
    "                    prop\n",
    "                    for prop in enhanced_graph.structured_schema[\"node_props\"][\n",
    "                        filter.node_label\n",
    "                    ]\n",
    "                    if prop[\"property\"] == filter.property_key\n",
    "                ][0][\"type\"]\n",
    "                == \"STRING\"\n",
    "            ):\n",
    "                continue\n",
    "            mapping = enhanced_graph.query(\n",
    "                f\"MATCH (n:{filter.node_label}) WHERE toLower(n.`{filter.property_key}`) = toLower($value) RETURN 'yes' LIMIT 1\",\n",
    "                {\"value\": filter.property_value},\n",
    "            )\n",
    "            if not mapping:\n",
    "                print(\n",
    "                    f\"Missing value mapping for {filter.node_label} on property {filter.property_key} with value {filter.property_value}\"\n",
    "                )\n",
    "                mapping_errors.append(\n",
    "                    f\"Missing value mapping for {filter.node_label} on property {filter.property_key} with value {filter.property_value}\"\n",
    "                )\n",
    "    if mapping_errors:\n",
    "        next_action = \"end\"\n",
    "    elif errors:\n",
    "        next_action = \"correct_cypher\"\n",
    "    else:\n",
    "        next_action = \"execute_cypher\"\n",
    "\n",
    "    return {\n",
    "        \"next_action\": next_action,\n",
    "        # \"cypher_statement\": corrected_cypher,\n",
    "        \"cypher_errors\": errors,\n",
    "        \"steps\": [\"validate_cypher\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_cypher_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are a Cypher expert reviewing a statement written by a junior developer. \"\n",
    "                \"You need to correct the Cypher statement based on the provided errors. No pre-amble.\"\n",
    "                \"Do not wrap the response in any backticks or anything else. Respond with a Cypher statement only!\"\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"\"\"Check for invalid syntax or semantics and return a corrected Cypher statement.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not wrap the response in any backticks or anything else.\n",
    "Respond with a Cypher statement only!\n",
    "\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "\n",
    "The question is:\n",
    "{question}\n",
    "\n",
    "The Cypher statement is:\n",
    "{cypher}\n",
    "\n",
    "The errors are:\n",
    "{errors}\n",
    "\n",
    "Corrected Cypher statement: \"\"\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "correct_cypher_chain = correct_cypher_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "def correct_cypher(state: OverallState) -> OverallState:\n",
    "    \"\"\"\n",
    "    Correct the Cypher statement based on the provided errors.\n",
    "    \"\"\"\n",
    "    corrected_cypher = correct_cypher_chain.invoke(\n",
    "        {\n",
    "            \"question\": state.get(\"question\"),\n",
    "            \"errors\": state.get(\"cypher_errors\"),\n",
    "            \"cypher\": state.get(\"cypher_statement\"),\n",
    "            \"schema\": enhanced_graph.schema,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"next_action\": \"validate_cypher\",\n",
    "        \"cypher_statement\": corrected_cypher,\n",
    "        \"steps\": [\"correct_cypher\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_results = \"I couldn't find any relevant information in the database\"\n",
    "\n",
    "\n",
    "def execute_cypher(state: OverallState) -> OverallState:\n",
    "    \"\"\"\n",
    "    Executes the given Cypher statement.\n",
    "    \"\"\"\n",
    "\n",
    "    records = enhanced_graph.query(state.get(\"cypher_statement\"))\n",
    "    return {\n",
    "        \"database_records\": records if records else no_results,\n",
    "        \"next_action\": \"end\",\n",
    "        \"steps\": [\"execute_cypher\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"\"\"Use the following results retrieved from a database to provide\n",
    "a succinct, definitive answer to the user's question.\n",
    "\n",
    "Respond as if you are answering the question directly.\n",
    "One full connection in the graph is one answer.\n",
    "\n",
    "Results: {results}\n",
    "Question: {question}\"\"\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "generate_final_chain = generate_final_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "def generate_final_answer(state: OverallState) -> OutputState:\n",
    "    \"\"\"\n",
    "    Decides if the question is related to movies.\n",
    "    \"\"\"\n",
    "    final_answer = generate_final_chain.invoke(\n",
    "        {\"question\": state.get(\"question\"), \"results\": state.get(\"database_records\")}\n",
    "    )\n",
    "    print(state.get('database_records'))\n",
    "    return {\"answer\": final_answer, \"steps\": [\"generate_final_answer\"], 'cypher_results': state.get('database_records')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def guardrails_condition(\n",
    "#     state: OverallState,\n",
    "# ) -> Literal[\"generate_cypher\", \"generate_final_answer\"]:\n",
    "#     if state.get(\"next_action\") == \"end\":\n",
    "#         return \"generate_final_answer\"\n",
    "#     elif state.get(\"next_action\") == \"movie\":\n",
    "#         return \"generate_cypher\"\n",
    "\n",
    "\n",
    "def validate_cypher_condition(\n",
    "    state: OverallState,\n",
    ") -> Literal[\"generate_final_answer\", \"correct_cypher\", \"execute_cypher\"]:\n",
    "    if state.get(\"next_action\") == \"end\":\n",
    "        return \"generate_final_answer\"\n",
    "    elif state.get(\"next_action\") == \"correct_cypher\":\n",
    "        return \"correct_cypher\"\n",
    "    elif state.get(\"next_action\") == \"execute_cypher\":\n",
    "        return \"execute_cypher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAITCAIAAAAsPkQxAAAAAXNSR0IArs4c6QAAIABJREFUeJzs3XdcE/f/B/DPZbECYYNMQXCgiAoutAKCDMWBE8U960TFveuuitsWFCvubd0VFRUVrXWhokwBlb1HAgEyfn9cvyk/DQEx8Em49/PRRx/JJbm8khwvP3e53BFisRgBAABl0HAHAACAJgWtBwCgFmg9AAC1QOsBAKgFWg8AQC3QegAAamHgDgBArSorhAWZVeVlwvIygUAgFlQpwV5WKmo0BotQ12Soa9GNzFVxxwFSQOsBhcMrrU56xUuN5RXnV2npMdU16eqaDC1dJlKGfUtFQpSTVllexmOq0D7FlVvba1h1UG/VURN3LvAfAvZSBopDJBQ/uVaQn1mpZ8Ky7sA2tVHDneiHVFYIU97x0pMqMj9WOA/Us+0M3acQoPWAonj/d8mD83nOA/U6u+rgziJnpYXVT64VVJYL+401UteEFSzMoPWAQnhwPldVndZjgD7uII2oIKvy8m+ZnuOMzFur485CadB6AL87J3KMrVTte3FwB2kKl3/L6DVI38BMBXcQ6oLWA5hd/i3DphO7gzMlKo90+bcMux5arbvAZj48YH89gNOjy3kt7TQoVXkIoSGzTJ/fLizMrsIdhKKg9QA2Ca/KGExaJ1dt3EEwGLPU4sGFXFjTwgJaD2ATdT6vS18qVh5CiCAIq/Ya0VcLcAehImg9gMfLu0UdemmpqNFxB8Gms5tO/PPSCq4QdxDKgdYDGIjF4s8J5c6+zXk/lfroM8wgJqoYdwrKgdYDGKS846mowbKHLFqrxz4pwZ2CcmDJAxikxvKsOmg08ZMuXbr02rVrDXigh4dHZmZmIyRCqhp0HUNWVmpFY8wc1AZaD2BQnFdtbd/UrRcXF9eAR2VnZxcXN+JKaGtH9pek8sabP/gWtB5oanyesCi3qvG+x7h8+fLIkSN79erl7u6+ePHinJwchJCTk1NmZuYvv/zi6uqKEBIKhSEhIUOGDHF2dvbx8dm6dWtFxb8DLg8Pj1OnTs2bN69nz56PHj3y9fVFCA0aNCgoKKgx0mpoMfLTYce9JgWtB5oar1SgodVYv8B//fr1xo0bR48effbs2T179hQXFy9btgwhdPPmTYTQ4sWLr1y5ghA6depUeHj4rFmzzpw5s3bt2qioqAMHDpBzYDAYly5dsrGxCQ0N7dq165YtWxBCJ06cWL9+fWME1tBi8EoFjTFnUBs4/ANoarxSoYZWYw30Pn78qKKiMnDgQAaDYWZmtnXr1qysLIQQh8NBCKmrq5MXfHx8evbsaWNjgxCysLDw9PSMjo4m50AQhKqq6rx588irGhoaCCEtLS3ygtxpcOi8Eth5pUlB64GmJhaJWY32Ba6TkxNBEFOnTh08eHD37t1NTEz09PS+vZu2tvaNGzc2btyYm5srEAjKy8vV1f87DkrHjh0bKd636AyCpQqrXE0K3m7Q1NS1GCV51Y0085YtWx45csTMzGzfvn2DBg2aOHFibGzst3fbvn17WFjYyJEjDx06dOrUKT8/v5q3stnsRor3LW6xgM4gmuzpALQewEBDi84rbcR1Oltb240bN965cyc0NJROp8+fP7+q6v99XSAUCq9cuTJhwoT+/fubmprq6+tzudzGyyNbo67vA6mg9UBTU9dk6BozRaJG+eF9bGzs27dvEUJ0Ot3R0XHmzJnFxcUFBf/+3JX8tb9IJBIKheQGPoQQj8d7+PCh7AMBNN5hAirLhQbmcKy9JgWtBzBQVaenvOM1xpyfPHmycOHCyMjI9PT0hISEM2fOtGjRwtjYWEVFRUVF5dWrVwkJCQRBtGnT5vr16+np6UlJSfPnz+/Vq1dpaWlaWppA8PXXqVpaWgihx48fp6SkNEbgxFdcY0s4lVqTgtYDGLRsr5H2vlFab/LkyX5+frt37x4+fPjs2bPFYvHevXsJgkAITZw48e7du7NmzaqoqFizZo1QKBw5cuTy5cv9/f1nz55tbGw8fvz43Nzcr2bYrl07Z2fnXbt2bdu2Te5pRULxl8Ryy3ZNvcM2xcGxlAEGFVzB7RM5g382xR0Es7QPvE9xPJdhhriDUAuM9QAGamyGjhHrDeUPN/LkWgHVjiOtCGB/PYBHr4H6ocs+OrhIP6qoUCh0d3eXelNVVRWLxZJ6k5WV1ZEjR+Qa8z/h4eHh4eFSb2Kz2bV9C9y2bduQkBCpNyW8KNM3Zem1gK8ymhqs4QJsYqKKCULs0Ef62W/LysqkTq+srGSxWOSmuq/QaLRG+gUF+bxf7QEjUV1dzWQypd5Ep9Nr7v9c0/WwTJfhBpra0h8IGg+0HsDpelhm+x6cpj/qFHaUfeGKALbrAZx8p5o8vJRXkF2JO0iTun8u18hCFSoPFxjrAczEIvHZ4C99hhqYtFLDnaUpPLiQ28JKtY2jFu4g1AVjPYAZQSP8F1s8vVkQ908p7iyNSyQS/3kgQ9uABZWHF4z1gKJ4cj3/c1y580B9i7bSN/8rtee3C+Ofl7mNNDCzbYavTrlA6wEFkpdR+eRavoYWw6SVmlV7DTW20v8sP/cL/0tC+Ys7RQ4u2t28dWk0OLwKftB6QOGkJ5UnvChLfc/TN1HRNmRqaDE0tBjqWnSRCHeyeqATqKSwmlciFCNxwosydU1GKweNjj9ps1Rga5KigNYDiisrrSI/vYpXKuCVCmgEUS7XE2aXl5enpaXZ2dnJcZ4IIU0dplgs1uDQNXWZptZqbG34IYDCgdYDFJWYmLh27drTp0/jDgKaGoy6AQDUAq0HAKAWaD1AUTQazdLSEncKgAG0HqAokUj06dMn3CkABtB6gLqa8lxoQHFA6wHqwnhqNIARtB6gKIIg9PX1cacAGEDrAYoSi8X5+fm4UwAMoPUARREEYW1tjTsFwABaD1CUWCxupFPcAgUHrQcAoBZoPUBRBEFwOHBWRiqC1gMUJRaLS0pKcKcAGEDrAYoiCEJbW/rZeEHzBq0HKEosFhcXF+NOATCA1gMAUAu0HqAogiBMTU1xpwAYQOsBihKLxRkZGbhTAAyg9QAA1AKtByiKIAgrKyvcKQAG0HqAosRicWpqKu4UAANoPQAAtUDrAYqCY65QFrQeoCg45gplQesBAKgFWg9QFJwZkrKg9QBFwZkhKQtaDwBALdB6gLrgfLjUBK0HqAvOh0tN0HqAogiCMDc3x50CYACtByhKLBZ/+fIFdwqAAbQeAIBaoPUARREEoaenhzsFwABaD1CUWCwuKCjAnQJgAK0HKAqOPkBZ0HqAouDoA5QFrQcoikajwbGUqQlaD1CUSCSCYylTE7QeoCiCIIyMjHCnABgQYrEYdwYAmo6/vz+Px0MICQSC0tJSXV1dhFBVVVVERATuaKCJwFgPUMvAgQNzcnKysrLy8vIqKyuzsrKysrI0NTVx5wJNB1oPUMuIESMsLCxqTiEIwsXFBV8i0NSg9QC1sFisIUOG0Ol0yRQLC4vhw4djDQWaFLQeoJyRI0eampqSlwmCcHNza9GiBe5QoOlA6wHKYbFYw4YNI4d7FhYWI0aMwJ0INCloPUBFI0eONDExIQd6sP8K1TBwBwBKQCQUF+VWlRYImtNeToP7Tb9//75zJ7+UWB7uLHLDYBJ6LVgaWvB3LQvsrwfq8OFZ6Ye/S/nlIiNL1YoyIe44QBZ1LfqnDzwjS1XX4QZsbeg+6aD1gCyx0SVp8RV9hhkRBIE7C6ivotzKh+ez/WabanCg+KSA7XqgVgkvylLjyl2GG0PlKRcdQxXfGRZHN6ThDqKgoPWAdGKR+F10ifMg2NKvlOgMopuPwT8RcNhUKaD1gHS8UmFpYTVLBZYQZaWpw8xM4eNOoYhgmQbSlRULDMxVcacADaepyxQKcIdQSNB6oBZixOfCN7ZKTCxGvBKoPSmg9QAA1AKtBwCgFmg9AAC1QOsBAKgFWg8AQC3QegAAaoHWAwBQC7QeAIBaoPUAANQCrQcAoBZoPQAAtUDrAdB0Nm5eNTdwCu4UVAetB5q5Py+f27ptHe4UQIFA64FmLjExDncEoFjgsPpAbgQCwW+/77wbeUsoFPT5yb2Xs8vqtYsuXbito6OLEIq8F3H+/IlPn1PV1NT7unlNnTJbVVUVIeQ3rN+4gCk5udn37kdUVJTb23detHCVnp4+OcMTJw/fu387JyfLwMBoxPCAwYOGI4RSUz9Onjpq04adB8P2qamq/f7bMaFQeOz4ocjIW3n5uVpanF7OLjOmB6qpqc1fOP3Nm1cIoYiI6wdDT9ratElMig8L25+QGCcQVHfp3G32rCBj47pPAR4Rcf302aNZWRnGxib+o8b7eA/648jvl/48c+FcBPkqEEIXL54+GLbvwvmIrb+updPo7dt3vPTnmeLiopaW1gsWrGjbxo68G51Of/T4/sFD+7KzM83NLZcsXiu5qba3aMhQj7EBk5+/+Pv16+c3rz9iMODP9ofAWA/IzYWLp65dvzR92tzfDxzT1zcIObgHIUSj0RBCjx8/2LhppaNj90MHTy9ZvPbho8jgXZvIRzEYjNNnj7ZsaX365LU/ws4lJcUfPxFG3hQSuufsueMBoycdDjs7YnjA/gM7bty8jBBiMpkIoaPHDo4aOW7xojXkU586HT558qzDh84sWbw2+klU2B8HEEIb1+9sbdu2r5vn5Ut3ra1scnKyFwbNIGi0XcGhwTtCSstKghbPrKqqkv26oh5Gbtux3ttr4N49h30H+G3bvv5B1F0fn8E8Hu/J04f/3e1RZO9erppsTQad8fr188zM9GPhly6cj+BwtNf9skQkEpF3y83Jvnbt4pJFa3buCCEIYsvWNeR02W/RteuXrK1sdgWHkicvBz8CWg/ITcTt6717ufoO8LOwaDll8iwjQ2PJTafOhDs4dJk2dY6ZqXmP7r2mTZ179+5fubk55K2WFlY+3oMYDIahoVG3rs4JCR8QQlwu98rV86NGjvPy8jUzNR88aLiXp++p0+EIIUQQCKFOnZx8vAdZW9sghDzcfUJ/P9HXzdPMzKKrUw83V88XL/5GCLHZbDqDwWSxOBxtOp1+9doFgiBWrdxkbW3Tto3dimUbsrIyoh5Gyn5d5y+c7N3L1X/U+Dat240YHuA/anxBfl4LYxPHLt3u3L1J3qegID829o239yDyqlAknDVzoYqKiiZbc/y4aTk52TFvXpI3FRYVrFyx0d6+k719p6F+/p8/p3G5XNlvEUEQqiqqM6bPa9++I5y56cdB6wH5EIvF6emfO7R3kEzp3duNvCASiRIT45wce0hu6uTgiBBKSUkir1pb20pu0tTUKi0rRQh9/JgoEAhqPsrBwTEzM728vJy8amdnL7mJw9F+9k/0rDkTR/r3Hzrc89r1i2Vlpd+GjIuLbdumvSZbk7xqZGTcooVpcnKC7JeWmBjX5n8roQihGdPnDRs2GiHUv/+Q58+fFhUVIoQePrqnr2/g2KUbeR9LCysVFRXycsuWrRBCGRlfyKvmZpYcjjZ5WUdbFyFUUVFe51vUvn1H2SFB/cEGAiAffD5fIBCoqatLpmhpcSQ3CYXC8KOhx44fqvmQgsJ88oKkIEjkYKa8nIcQWhA0QzK6Ic/dXFj073m/NDTYkofs27/9zt2bCwKXt+/goMJSOX3m6L37Ed+G5PG4SckJnt49JVOqq6slMWp7XdXV1aqqat/e9FNvNzZb8969iGHDRj98GOnZbwC5Oo8QUlP7730gt81xuWX/XlX7b1bkSxOLxXW+RTVfLPhB0HpAPshN7Hz+fyflkoy2VFVVGQzGUD//Af2H1HyIto6ujBmSf+crV2y0trKpOd3QwCg3L6fmFKFQePOvK+PGTu3Xrz85hcfj1jZPe/tOQQtW1pxYs6G+paqqqqqqSlbwV5hMpoe7z/2oO337er199zpo4X+zrXl/XjmPHMPKfpYGvEWgYaD1gHwwmUxDQ6P4hPeSKY8f3ycv0Gg0W9u2OTlZFhYtySnV1dW5eTlaMovA2tqWyWQWFRVauPz7qOLiIoIgWCzWV/cUiURCoVAytCS/ZJAMuySDRIRQu3YdIm5fNzExk3wN+uXLJ/L7YhlsbNq8ffsKBUwmr+47sAMhNHf2IoTQgP5DLl46feHiKTs7ezMzC8lDUtM+lpSWcLQ4kl1nLMxbyniKhr1FoGFgux6QG5c+HlFRd+/dv52RmR5+NDQvP1dyk/+o8Q8f3Tt1OvzLl09JyQmbt6yeFziFx5MygJJgs9m+vkPDj4beu387MyvjdcyLRUtmSd3fmMlk2tq0ibh9PSMz/ePHpBWr5nfv3qusrPTz5zSBQKDJ1kxOTkhKTigpKR7oO6yiovzXbeuSkhPS0z8fOx42acrI+Pj3Up6+huHDxjx/8feR8JD4hA8XL525fPlcu7YdyJusrFq1a9fh7Lnj3l4Daz5EU1Nrx44NaWkpCYlxoQf3mJqa29t3kv0sDXiLQMPAWA/IzaSJPxcVFWzfsV5FRdXd3XvsmMmbt65hMJgIoT4/9V2xfMPpM+FHwkM0NNgdOjjsCg7V0NCQPcNZPy/QZGsePLS3oCBfV1fPuWefKZNnS73n4kVrtu9YP3nKSGNjk8mTZrZr2+F97JuZs8eHHTrj5+e/ZeuaeYFTflm3vVvXnjuDQw8e3DsvcAqdTm/ZstXGDTtrfisilUsf9/mBy86dP3H6zFEjoxbz5i7xcPeW3Nrnp76pqckufTxqPqSlpXX37r2WrwjML8izsWnzy7rtdX732rC3CDQAIRn8A1BTVir/8ZV870lm9X+IQCDgcsu0tXXIq8eOh13688zlS3cbLSN+YrF49txJrW3bzg9cJpm4dt0SLrcseMfvWKOh0sLqyJOZ41dZ4o2hgGANF8jNyVNHxowd9CDqbkZm+uPoB5f+POPl6Ys7VGPh8/kpKcnBOzd9/pwaMGYy7jjgO8AaLpCbgDGTqqoqQ0J3FxYWGBoYDeg/ZPy4abhD1cvylfNjY2Ok3jSgv9/PMwK/nZ72KWXW7AmWllabNuwyMDBs/IxAbmANF0jXgDVc5VVQkF9VLf13aerqGpz/fTusXGANtzYw1gMA1bnzCmhOYLseAIBaoPUAANQCrQcAoBZoPQAAtUDrAQCoBVoPAEAt0HoAAGqB1gMAUAu0HgCAWqD1gHR0OmJrM3GnAA0nFol1W3x9BFYArQdqpWeqkvKuDHcK0HD5mZUsFpxQTQpoPSAdnU7YdNLM+VyBOwhooMJMvpU9HJRUCmg9UCu3kQaPLuZUVghxBwHf7fX9ArFIbNtJE3cQRQRHmgKy8HnCY5s+OXrosbWZ2gYsWFgUnEgkzkvnF2TykVjcdxQc9U86aD1Qt+d3CjOSK8QiVJJfjTuL3IhFomqB4Nszrik1fVNVBhO16qhh2xlGebWC1gMUlZiYuHbt2tOnT+MOApoabNcDAFALtB4AgFqg9QBFEQRhbW2NOwXAAFoPUJRYLE5JScGdAmAArQcoiiAIU1NT3CkABtB6gKLEYnFGRgbuFAADaD1AUTQazdISzhVLRdB6gKJEItGnT59wpwAYQOsBioLtepQFrQcoCrbrURa0HgCAWqD1AEURBGFubo47BcAAWg9QlFgs/vLlC+4UAANoPQAAtUDrAepqZgfXA/UErQeoq6qqCncEgAG0HqAuDQ04mQ4VQesB6uLxeLgjAAyg9QAA1AKtByiKIAhDQziLGBVB6wGKEovFubm5uFMADKD1AADUAq0HKAp+kUZZ0HqAouAXaZQFrQcAoBZoPUBRcGZIyoLWAxQFZ4akLGg9AAC1QOsBioLzZlAWtB6gKDhvBmVB6wGKIghCU1MTdwqAAbQeoCixWFxWVoY7BcAAWg8AQC3QeoCiaDSapaUl7hQAA2g9QFEikejTp0+4UwAMoPUARREEYWVlhTsFwABaD1CUWCxOTU3FnQJgAK0HKIogCNiuR03QeoCixGIxbNejJmg9QFGwXY+yCLFYjDsDAE1n6tSpVVVVYrG4vLw8Ozu7VatWYrGYz+efP38edzTQRBi4AwDQpOzt7Y8fPy65+uHDB4QQnCyNUmANF1DLmDFjWrRo8dXErl27YooDMIDWA9RiYGDg4eFRc8OOkZHR2LFjsYYCTQpaD1DO6NGjzczMyMtisdjR0dHW1hZ3KNB0oPUA5RgaGnp6epKXjY2NYaBHNdB6gIr8/f0tLCzEYnGXLl1at26NOw5oUvAdLmiI0sJqgiBwp2g4Fo3j4TowIiJihN/4siIB7jg/hEZDGhz4Q/4OsL8e+A556ZXP7xSmxvJMW6kX51XhjgMQQkjbkFWQWdnGSbP3YH3cWZQDtB6or+y0isgzeT8NNeIYsGg0JR7oNT8VXEH2p4q3DwpHL7GgM+CjqQO0HqiXrLSK++fyB84wxx0E1CovveLJ1dyxy+GQCnWAbzNAvby4XeQ+xhh3CiCLgZmabRdOTFQR7iCKDloP1I3PE2an8dU1mbiDgDpocBgZyXzcKRQdtB6oW3FetXlbDdwpQN10jFQQbLKqC7QeqJtYjMoKq3GnAHUTi1BRLny3XgdoPQAAtUDrAQCoBVoPAEAt0HoAAGqB1gMAUAu0HgCAWqD1AADUAq0HAKAWaD0AALVA6wEAqAVaDwBALdB6QFGsXbckaNFMhFBKSrKbu9O7dzHf3udB1F03d6eSkmIcARto4+ZVcwOn4E4B/gOtBxSOvoHh/MBlJiZmDZ7Dn5fPbd22Tq6hQPMBJxkBCkdLU2vwoOE/MofExDj5xQHNDYz1gPzdirjmO8iluvq/g1OdPnPU07snl8sVCoVHwkPGjhvi5eM8YpTP7j1bKyoqvnp4zTVcgUCwZ++vAwe5DhjYZ+OmlTweV3K32mY1f+H0WxHXIiKuu7k7JSUnIIQSk+KXLJ0z2M99wMA+q9csys7Oqs+riIi4PnHyCC8f5wmThv916ypC6I8jv/sOcuHz/zts58WLp718nMu4ZStXL1yzdvHZc8dHjR7g5eM84+ex8QkfJHej0+mPHt8fN2FoP68ek6eOktwkEAjCj4aOnzjMy8d57Hi/K1cvSB4yZKjHhYunli6f5+ndUyBQ7rO4KRpoPSB/HTt24fF4L1/9I5ny8GFkj+692Wz2hYunTp0Onzx51uFDZ5YsXhv9JCrsjwMyZnXqdPj1G3/OmrUwNOSkvX3n4yfCJDfVNquN63e2tm3b183z8qW71lY2OTnZC4NmEDTaruDQ4B0hpWUlQYtnVlXVcRC6qIeR23as9/YauHfPYd8Bftu2r38QddfHZzCPx3vy9OF/d3sU2buXqyZbk0FnvH79PDMz/Vj4pQvnIzgc7XW/LBGJROTdcnOyr127uGTRmp07QgiC2LJ1DTk9JHTP2XPHA0ZPOhx2dsTwgP0Hdty4eZm8icFgXLt+ydrKZldwKJ1Ob9DnAKSDNVwgfyYtTC0sWj5+fL9H914IoZyc7PiED/7+ExBCHu4+XZ16WlvbIITMzCzcXD2f/RMtY1a379zo3cvVx3sQQsjM1DwpKV7SC7XNis1m0xkMJovF4WgjhK5eu0AQxKqVmzTZmgihFcs2jA4YGPUwsp+Hj4znPX/hZO9erv6jxiOE2rRuV1hYUJCf18LFxLFLtzt3b/Z180QIFRTkx8a++XXrPvIhQpFw1syFKioqKioq48dNmxs4JebNyy6duyKECosKfv/tGJlnqJ//juCNXC4XIXTl6vmAMZO8vHwlr+7U6fAB/YcghAiCUFVRnTF9nlw/GYBgrAcai5urZ/STKHKw8/BRpIaGRo/uvRFCHI72s3+iZ82ZONK//9DhnteuXywrK61tJtXV1RkZX9q2bS+Z0q5dB8nles4qLi62bZv2ZOUhhIyMjFu0ME1OTpCdPzExrk0bO8nVGdPnDRs2GiHUv/+Q58+fFhUVIoQePrqnr2/g2KUbeR9LCysVFRXycsuWrRBCGRlfyKvmZpZk5SGEdLR1EUIVFeUfPyYKBAInxx6SZ3FwcMzMTC8vLyevtm/fUXZI0DAw1gONoq+b59FjB2Nj33Ts2DnqYWTvXm5kI+zbv/3O3ZsLApe37+CgwlI5febovfsRtc2kgl+BEGKxVCRT1NTUJZfrOSsej5uUnODp3VMypbq6uqAwX0Z4Pp9fXV2tqqr27U0/9XZjszXv3YsYNmz0w4eRnv0G0Gi0b7OpqqoihLjcsn+vqv03K4IgEEJisbi8nIcQWhA0g5xCTiQHhurq6gghDQ22jJCgwaD1QKOwsGhpbW3z6PF9ExOz9+/fThg/nfz+4eZfV8aNndqvX3/ybjW/nfiWqorqV/eR9Ej9Z6Whwba37xS0YGXNiTUbSsrzqqqqqqqSrfQVJpPp4e5zP+pO375eb9+9Dlr432xr3p9XzkMIaWpqyXgWstRWrthobWVTc7qhgZGMR4EfB2u4oLG4uXr+/exx9JMoHR1dcvOWSCQSCoVaWhzyDuQ3AzLOQ89isYyNWnz8mCiZ8vLlM/JCnbOSXG7XrkNGxhcTEzMLi5bkfwRB6Onpyw5vY9Pm7dtXkqv7DuzYd2AHeXlA/yHv37+9cPGUnZ29mZmF5D6paR9LSkvIy+SuMxbmLWU8hbW1LZPJLCoqlATT0uJwONosFkt2NvCDoPVAY3Fz80xP/3zt+kVX137kt5BMJtPWpk3E7esZmekfPyatWDW/e/deZWWlnz+n1bZzRt++Xo+jH1y/8WdKSvK58yck2+Nkz0qTrZmcnJCUnFBSUjzQd1hFRfmv29YlJSekp38+djxs0pSR8fHvZYcfPmzM8xd/HwkPiU/4cPHSmcuXz7Vr++8mRSurVu3adTh77ri318CaD9HU1NqxY0NaWkpCYlzowT2mpub29p1kPAWbzfb1HRp+NPTe/duZWRmvY14sWjILdq5uAtB6oLGYmpi1tm378WOSR19vycTFi9aIhMLJU0au37h8qJ//1MmzjQyNZ84en5efK3UmE8ZP9/L0DQndPWfepPj499OnzyMHerJn5efnn58oNzy3AAAgAElEQVSfNy9wSkJinLFxi53BoYWFBfMCp/w8a9w/z59s3LDTzs5edniXPu7zA5fdjbw1L3DK5Svn5s1d4uH+36vo81NfJpPp0sej5kNaWlp3795r+YrAOXMnMZmsX7fuk2ywq82snxcMGTzi4KG9EyYO2/rrWvsOnVYu31i/dxc0HCFj/QIAUlYq//GVfO9JDf+JWHMiFotnz53U2rbt/MBlkolr1y3hcsuCd/yONRoqya9+cDZz7ApLvDEUHHybAUB98fn8zMz0S3+e+fw59Ze123DHAQ0ErQcoavnK+bGxUg7rghAa0N/v5xmB305P+5Qya/YES0urTRt2GRgYNn5G0ChgDRfUrVmu4RYU5FdVS/9dmrq6Bud/3w4rF1jDrQ8Y6wGKqnPnFdBcwXe4AABqgdYDAFALtB4AgFqg9QAA1AKtBwCgFmg9AAC1QOsBAKgFWg8AQC3QeqAO9+7d2759u0AgxB0EAPmA1gNSxMTELFy48MaNG+Tx1n19B+gYqeIOBepG0JCuMRyUtA7QeuBfaWlpq1evPnLkCEKopKRk8ODBXl5eCCEvL6/efTt9ei/rUO9AQRRmVdZ1TD8Av8OltoKCgtDQUFVV1YULFxYUFPTs2dPFxQUhRP5fgqVKM2utXlpUraXDxBcW1I1bXG3aWspJjkBNcMwVyuHz+SEhIYWFhevXr09MTHz37p2Li4u+fh0/xS/IqrwRlu03Dw7mobg+xXE/PC0aucAcdxBFB61HFadOnUpPT1+yZEl+fv5ff/3l6upqbv59fx6FOZWXf8v8aZgxR5+ppgFrCQqkOK8q93N5aix32BxTggaruHWA1mvOoqKiLl68OHHixC5dupw8edLBwaFDhw71eFytyoqq/7lVmPq+XNuAWZgt/eB0pGpBteRyzUWMxVTQdWQxEotEYjpNcbd0Vwuq6XQ6jfg6oV4L1Qpedesumt28dDFFUzLQes3Ns2fPLl++PGrUqE6dOl25ckVfX9/Z2bnO09Z8L365SPYsXV1dyQtisZggCIIgRCKRiYnJjh07TE1N5RtGLvh8/pAhQ27duoU7SK3evXsXERGxaNGi3NxcDQ0NDQ0NcjqNTjBZML77DrCe0hykpaWdPHmyY8eOAwcO/Pz5s5ubGzmmGzx4cCM9o6p6HWMioxa66enpNadoampOmDTG2kZBtzqpqKlP/3lSRWWptrY27izSOXVzcOrmgBCiMYR+w3wXLVo0cODAejwOfA3GesoqOzv7/Pnzurq6AQEBUVFRBQUFnp6ebDYbd67/dO3aVbJ00Wg0Dw+PzZs34w7VfMTGxnbo0OHkyZO6uro+Pj644ygTaD1lUllZefHiRaFQOG7cuHv37n3+/Nnb29vY2Bh3rq89ePBg3759+fn5PB6PnGJhYXHp0iXcuerw7t07Lpfbs2dP3EG+Q3Z29v79+/38/BwdHUtLS7W0tHAnUgKKu+0WSNy5c+fXX39FCKWnp2dlZfXo0QMh1Ldv34kTJypa5b18+XL8+PHXrl0LDg6Oioqi0+kIIWNj41WrVuGOVjehUBgWFoY7xfcxNjbeuHGjg4MDQmjYsGE7duzAnUgJwHY9BRUfH3/v3j1/f39dXd3Hjx/37t0bIdSqVaugoCDc0aSLjY3dv3+/ubn50qVL27dvT040MzPLy8sbMmRIly5dcAesm4ODw8yZM3GnaAgGg0H+6xgVFYUQ+vDhQ2ZmpoeHB+5cCgrWcBVIcXHx/fv3O3XqZGVltWHDBhMTkwkTJpALtCJLSUk5f/58XFzc7Nmzu3bt+tWtU6ZMOXz4MKZoFMXlcjdu3Ni2bduJEyfizqKIoPXwe/nypY6OjrW19erVq1VUVObOncvhKMfJWLOysvbv35+YmLhgwQJnZ2fcceTg4sWLrVu3tre3xx1EDrhcLpvN3rZtG4fDmT59utz3XlJe0Hp4FBQUVFRUmJmZrVmzJicnZ9WqVd/7Swm8SktLT548eePGjTlz5nh7e+OOIzfHjh0rKioKDAzEHURuBALBH3/80b9/f21tbZFIBF93IHInUtBkCgoKxGJxWFhYv3793r59KxaLq6urcYf6PgKBYPfu3a6urjdu3MCdRf6Ki4vj4uJwp2gU5eXlrq6u169fxx0EP/gOt9GRo+k7d+54eHi8evUKIdS/f//bt2+Tq1GKv9mupjNnzvTs2VNHR+f+/fv9+/fHHUf+OBxO27ZtcadoFGpqavfv39fR0UEIRUdHi0Qi3ImwgdZrRMnJyfPmzSN3hjA1NT1//jz5tVqLFi1wR/tuZ8+e7d27t0Ag+Oeff8aPH487TiNasmRJcXEx7hSNhdz8qq6u3r17969+PEMd0HpyVlFRcfToUfJby6KiolGjRk2bNg0hZGdnR/4zq3Ru3Ljh7e396dOnO3fujB07FnecRsfn89+/f487RePq3Lnz8+fPyeFeZGQk7jhNDb7NkI/4+PjY2Njhw4e/fPkyOjp66NChZmZmuEP9qEePHp05c0ZPT2/u3LkGBga44zSRL1++MBgMZRyPN0xwcHBmZmZwcDDuIE0HWu+HxMbG2tjYVFVVzZw5c/jw4X5+frgTycebN2/27t2rqakZGBhoZWWFOw5oXB8/fmzVqtXz58+/3d2yWYLWa4iioiIdHZ3ly5dnZmaGhoayWCyaAh+X7bukpaXt3bu3uLh43rx5nTp1wh0Hg9TU1NDQ0K1bt+IO0tSSk5MDAgJu3rypp6eHO0vjgtb7PtHR0du2bQsMDOzbt29hYaGubvM5jmNRUdGePXsyMzMDAgK+Om8GpfD5fHd39+joaNxBMBAIBJ8+fTIzMyMIgsVqtudag9arW2Vl5YULF1gs1ogRI549e2ZqatoMttnVJBKJ9u7de/369cDAQDhkG3mUB2NjY+XaqUiOhEJh7969w8LCJL+nbmaayXpZI3ny5AlC6PHjxzk5OW5ubgih7t27N7PKO3fuXPfu3fX09O7evQuVRzIzM6Ns5SGE6HT606dPExIScAdpLNB60olEoh49epA7Fbu7uy9cuLDOs4gpnatXr7q7u1dUVDx//nzcuHG44yiQgwcP3r59G3cKzIYOHYoQWrx4cVFREe4scgat9/9ERESMHz9eKBQSBPHo0aM5c+bgTtQooqOjR4wY8fr164sXL06YMAF3HIWjpqb24cMH3CkUwvLly1euXIk7hZzBdj1EHpCWx+O1atVqz549Hh4ezXVzBrlf4alTp4qLi+fPn29tbY07joLi8XhlZWWKdsRWvB49evTTTz/hTiEf0Hro77//3rBhQ2hoaDPbYPeV/Pz83bt3p6amLlq0qHPnzrjjACVz79699+/fz507F3cQOaDuGm5MTAz5uzFzc/MbN24078rbvXt3QEBAr169Tp48CZVXJy6Xu2jRItwpFEvfvn3btGmDO4V8ULH1qqqqMjMz9+3b16dPH/K4ALgTNaLz5887OTnp6elFRETAmbTqic1mR0dHV1XJOs05BXl6eubm5j569Ah3kB9Frdarqqpas2YN+cuKw4cP29ra4k7UiCIjIwcMGJCXlwdf0TbAgQMHqHwsptoYGhoymczZs2fjDvJDqLVdb+/eva1atRowYADuII3r/fv3O3fu1NPTW7hwIWySB3InEolEIpHy7tJIidYrKio6ceJE89gQK1thYeHx48dfvny5cOFCav6KVl7OnTvXqVOn1q1b4w6ioN6/f8/lcrt37447SENQYg13zpw5Q4YMwZ2i0R04cGDUqFEdO3Y8duwYVN4PiouLi4+Px51CcbVv3/7Zs2dKui93Mx/rPX36VLlOZd8wly9f3r59+5QpUyZPnow7SzMRExOjoqLSrl073EEUGo/HU1NTU7oDDinrmnl9rFmzZsSIEbhTNK7nz58fPnzY1NQ0MjJSVVUVd5zmAwbL9UGn01+9euXk5IQ7yPdpzq3n4uLSPE5sKlVWVtb27dvLy8uXLFkCv7KQuxcvXhQVFfXr1w93EIWmqqr65s2bf/75Z9asWbizfAclG5rWU1paWkFBgbu7O+4gjWXnzp3Tpk0bPHhwSEgIVF5jyMjIePr0Ke4USmDKlCl2dnZcLhd3kO/QDFvvzp07ISEhzfV4sBcuXOjdu7eRkdH169epfOzPxtarV6+RI0fiTqEcXF1d2Ww27hTfobm1nlAoZDKZzfLw3//888/w4cOTkpIePnwYEBCAO04zp6+v31xPjNsYli9f/ubNG9wp6quZf4fbPOTm5v7666/kJjw4d0/TiI2NvXXrFvwat57i4uLCwsKU5URrze3bjMmTJ+/evVtLSwt3ELnZu3fv69evJ0yY4OrqijsLhVRWViYlJeFOoTTatWunLJXX3NZwU1JSysrKmk3lXb16tVevXhwO58iRI1B5TaxNmzaBgYG4UyiToqIiZdmvu1mt4VZWVopEIjU1NdxBflRsbOyWLVtat269dOlS2AsPKAsPD4/z58/r6OjgDlKHZtV6zUBZWdnWrVtpNFpAQABsTccoLS0tPDx83bp1uIMok6ioKFVVVcX/cW6z2q738uXLyMjIJUuW4A7SQIcPHz5+/PiyZcu8vb1xZ6E6Pp8P2/W+l7LsStWsxnqfP38mt8VUV1cXFBQo0V6mDx48uHz5cuvWrZVrH/dmjMfjJScnOzg44A6iZMLDw4cMGaKtrY07iCzNYaw3e/bs1NTU0tLS8vJygiAIgkAIaWhoREdH9+rVC3e6OqSnp2/evFlNTW3VqlXN7+STSmfDhg1XrlxBCJGjAXJZEovFL1++xB1NOeTl5d26dcvf3x93EFmaw3e4Bw4cIAiCz+fTaDRyMUUIcTgcxT/V2c6dOwMDAydMmBAcHAyVpwjGjBlDnkFF8s8neep33LmUxsSJExV/l9Lm0HrkwlpzhxWxWGxqaqrIw+xr16717NnTyMjo4sWL8EelOFq1atW1a9eam320tLQmTpyINZQyMTAwUPzluZm0XkBAgIuLC51OJ6/S6XRnZ2fcoaSLjY0dO3bsmzdvoqKi4IdlCsjf39/CwkJy1c7Orlu3blgTKZl9+/alpaXhTiFLc9iuR1q7du3Hjx/JU9br6+sr4HZoPp+/ZcuWtLS0lStXwuEqFVarVq2cnJy+fPmCENLT05s0aRLuREqmuro6Ojq6ZcuWuIPUqpmM9Uhbtmwh/5VmMBgdO3bEHef/OX78uLu7e9euXY8ePQqVp+DGjBljbm6OEGrbtq2joyPuOEpm/PjxCj46blatZ2pqOmvWLC0tLYUa6D158mTQoEEFBQXR0dG+vr6444C6WVlZOTk5aWpqjh8/HncW5aOvr6/g51ytY3+9vIzK1/eKcz7zK7jCJkz1QwRCIeN/G/iwEyMkEFQzGAwCEQ14OFubQRDI1Eatu4+uipqivKjapLzjfvi7rIInLMpR+vNni8RioVDIVNqTH0po6THFYrGpjVrPAXpMVhONcubOnbtv376mea4GkPWhpn3gPblW0NFF185ZR42t9B+/MqLRUGlhdVlh9dH1n0YuNNc2YOJOVKtX94qyUiutOmrqmag22V8XqBONRpQUVJUVVYWtSh273EJTpykWoczMzLS0NIXdtFfrWC/+eemHf8r6jTVt8khAusv7P/lMMtY3UcEdRIroq/m8MlFPX0PcQYAsl/akDfrZRMeQ1dhPlJqaqqury+FwGvuJGkb6v8n8cuGHZ1B5isVjnMmTawW4U0iRlVpRViSAylN8HmNNoq/mN8ETWVlZKWzl1dp6WSl8OqMh26FA42FzmAVZVWVF1biDfC3jY4UqW3FXvYGElh4rO62yvEzQ2E908+bNM2fONPazNJj01istqDayVG/yMKAOlu3YBZkK90VBRZnIwBwOAqgcWrbXaIJFiEajvXv3rrGfpcGkf0dRyRcJFO6PC6DyMoFAoHDHyOGWCLSNFS4VkIpXIhA2/iLk4uKiyL+Ch+/aAABypqamRu7mrZig9QAAclZSUjJz5kzcKWoFrQcAkDM1NbWYmBjcKWoFrQcAkDMWi3XkyBGFPU47/OICACB/inyuKxjrAQDkLygoqKBAEXeqh9YDADSKtLS0srIy3Cmkg9YDAMjfr7/+amxsjDuFdLBdDwAgfzY2Nrgj1ArGegAA+du4cWNCQgLuFNJB6wEA5O/Lly8Ku10P1nABAPK3cuVKXV1d3Cmkg7HeD0nP+OLm7vTi5TPcQYCyaq6LkIWFBZvNxp1CuubWekOGemRlZ+JOARQdLCeNbceOHW/fvsWdQrpm1Xo5OdklJcW4UwBFB8tJE/j06ROXy8WdQjq5tV51dfWhsP0jRvn4DOg9N3BKbOwbcnpVVdXvIbtH+vfv59XDf4xv2OEDAsG/h3IdMtTjwsVTS5fP8/TuyeVy1/2y9Jf1y46Eh/gM6P306SOEUGJS/JKlcwb7uQ8Y2Gf1mkXZ2VmSp4uLi503f6p3/14j/fuHhO6pqqp6HfPCf4wvQmhMwKBVa4Jkpy0oyN+wccXAwa6DhvT9Zf2y3NwcHo/nM6D3iZN/SO4jFAqHDPU4FLY/MSnezd3p8eMHCxbO8B3kMtjP/feQ3SKRSHJPfkXFps2r+vv+5DvIZf+BYKHw3/PJ1Zb/z8vn/Ib1i46O8hvW7/eQ3fL6CJRIcXHR5q1rRo0e4N2/16w5E1/HvCCnB+/c5D/Gl8/nk1dPnjrS3/cn8n2r7SFSP02EUHzCBzd3p/iED5K7jR035PeQ3d8uJwKBIPxo6PiJw7x8nMeO97ty9UJ9XoLiLELnzp/4sU+jUQQFBSnaOakl5NZ6v4fsunHz8qyZC3fvOmRqar5k2ZzMrAyE0O49W/+6dfXnGfPDj1yYMnn2n5fPhh7cSz6EwWBcu37J2spmV3Coqqoqk8lMSU1OTIrfunmvnZ19Tk72wqAZBI22Kzg0eEdIaVlJ0OKZVVVVCKGs7MxFS2aZtDDbuSNk7pzFtyKu/R6yy75DpzWrtyCEQkNOLF+6XkZUgUCwbPm8zMz0X9Zt37g+OCsrY/nKQDU1NZc+Hnfu3pTcLebNy5KSYi9PXwadgRAKPbR32rS5Vy/fX7p47cVLp/+6dVVyz6PHDrZrZ7939+GxAVMuXjod9TCSHFDUlp/JZPL5FZf+PLN0ybrBg0fI6yNQFiKRaOmyue/fv126ZF3o7yfatrFbtnxeSkoyQmjG9ECRSHT8RBj5Bp44eXj6tHnGxi1kPETqp1mzUL7y7XISErrn7LnjAaMnHQ47O2J4wP4DO27cvCz7JSjUIuTm6imnT0aeWrZs2cy36/F4vBs3L48fN83NtV+b1u2CFqzs6tQzI+NLSUnx7Ts3xo+b2tfN09TErJ+Hz1A//+s3LlVXVyOECIJQVVGdMX1e+/YdGQyGGKHMzPRlS39xcOjC4WhfvXaBIIhVKzdZW9u0bWO3YtmGrKwMcmm4ceNPFktl8aLVdnb2P/V2m/XzgurqagaDoa6ugRDS1NTS0NCQkfZ1zIvkj4mLF63p0rlrx46dg4JWmZtZ5ufnDeg/5PPnNMno4OHDSDs7ewuLf89u18+jv127DjQazdm5T+dOThG3r0tm6OTUY6jfKBub1v6jxhsYGMbFxSKEZOQnCILP5w8fNqZH914mLSh3SqYXL58lJsUvClrVpXNXS0urObMXGRm1uPTnGYQQm81eOH/FufMnPn9O+z1kV5s2doMHDZf9kNo+zdqe/avlhMvlXrl6ftTIcV5evmam5oMHDffy9D11Olz2S1CoRcjAQBHP07R7926FPdiUfFovLe1jVVVVu7b/HjOayWT+sm5bV6ceH1OShEKhXTt7yT3btLHj8/np6Z/Jq+3b/78xsLm5JUfr31MrxcXFtm3TXpOtSV41MjJu0cI0OTkBIZSYGNfati39f6f69vQcsChoVf3TJibGsVgsa+t/9x23tWmzbu2vhoZG9vadLCxakv9Wi0SiR4/ve3sNlDyqte1/x5CwtLTOzEyXXG1v99+r0NHWragol52fZGf339tCKXFxsUwms5ODI3mVRqN1tO8seWd69Ojt6tpv5eqFz/6JXrxoDUEQsh9S26dZzzAfPyYKBAInxx6SKQ4OjpmZ6eXl5TIeBYtQnQoKCmS/hxjJZ3+9srJShJCKytenjCkv5yGEyH9aSWpq6ggh8kNFCGlo/L8xcM2rPB43KTnB07unZEp1dXVBYT75dIaGDf+JX1lZqaqqmtSbBvQfcup0+MwZ82Nj35SX82quO5DJ/3dZjcv9bw9MVbX/NzfysGIy8n/7YimlvJxXXV3t5eMsmSIUCnV19SRXB/kOu3v3r+7de5mamNX5EBmfZj3DIIQWBM0g61Xy8RUWFair13rCLFiE6jRhwgR9fX3cKaSTT+txtHUkC1BN5KdSczp5uT6floYG296+U9CClTUnkssNR1vn2+eqP21tnfJynlgslizoEl6evofC9r+OefH06cOfervV3DAhaWqEEK+cx/7fv8ANyE9xGhpsFot1KPRUzYk02r+rHSKR6PfQ3U6O3V++fPbP86fduvaU/ZDaPs1vP1x+JV9qGITQyhUbra3+3+9GDQ1kjRZhEapT8/8drrmZpaqq6pu3r8irIpEocMG0iIjr1ta2dDo99v0byT3fv3/LZrNNTes+k0i7dh0yMr6YmJhZWLQk/yMIQk9Pn1yhiIuPraysJO95+/aNefOnSjZg13kEVxubNgKB4MOHf89cl5aWMuPnsampHxFCHI52L2eXe/cioh5GetVYNyG3TEsuJyR8sDBv2eD8FNe2bfuqqiqhUCh5Z1gsFX39fzdOXbx0OiPjy6qVm0YMD9i5axOPx5P9kNo+TQ11DYSQZDxVVFRYUPD/ToBNLifW1rZMJrOoqFAyZy0tDoejzWKxZLwEWITqFBoaGh8fjzuFdPJpPTab7eM96OSpP27fvpGQGLdz1+bExLgO9p04Whwf70EnTx15/PhBTk52RMT1K1fPDxs6msGoe4w50HdYRUX5r9vWJSUnpKd/PnY8bNKUkfHx7xFCvgOGCgSCTZtXxca+efz4QeihvZYWVjQaTUtTCyH099+P09JSZMzZsUs3a2ub7cEbnr/4+927mOBdmyqrKs3NLclb+/cfcufuTQaD0aVz15qPevL0YeS9iMysjPMXTn748M7He1CD81OcY5dutjZtNm9ZHRPzMis7827krekzxly5eh4hlJmV8ceR33+eEcjhaI8fN41AxMFDe2U/pLZP09DQmMPRvn3nhkAgKOOW7d23Tet/m4xrLidsNtvXd2j40dB7929nZmW8jnmxaMmsrdvW1fkSYBGSLTY2trCwEHcK6eT2O9wZ0wMJGi3k4J6KinIrK5stm/aQG2XmzV2irq6xe+/W4uIiQwOjsQFTxoyeWJ8ZGhu32BkcevDg3nmBU+h0esuWrTZu2EluvjUyMv51y76Qg3uCFs/U0uK4uvabNmUOQqh163bdujmTe7HsDA6pbc4EQWzeuHvfge3rfllCp9EdHBxXLt8oKWInx+4qKireXgMl61ykyZNmRty+viN4A4ulMnnSzH79+jc4P8XR6fRft+77PXT32l+W8PkVxsYm48ZNHTE8ACEUHLzR1rYt+Q2Aqqpq4Lyly1fOd3Xt17mTU20PkfFpLlv6y4HfggcOdjU0NJ46ZXZuXg65QvDVcjLr5wWabM2Dh/YWFOTr6uo59+wzZfJs2S8BFqE6TZo0ycLCAncK6Qip64P/RBRW8ZGDq4L+eLhR/f0sevWaoNMnr+nrG5BTUlKSp0zz37s7zN6+E95sUeez23Zl2zgo1jbsv8KzzdqwW9opViqMFHkRunc60+EnTsv2snbtavaa1S/SflBeXu6TJw+371g/1M9fsrwCUH+wCEmcOHEiOTkZdwrpmueRpt69i1mxan5tt544fkWyV2BNO3dvjo2NcXXpN2XyrEYOCBTdqdPhp89I31fZwsLqwL4jUm+CRUjiyZMntra2ivlNbvNcwxUIBBX8itpuZWuwv93hQCnAGm6TqaysrKquknoTjaDJ/vGPImuyNdxHjx61adPG0FARfzfSPMd6DAZDs66doQCQQUVFRUVFBXcKJfbTTz/hjlAr2K4HAJC/M2fOZGRk4E4hHbQeAED+/vrrr6KiItwppIPWAwDI35gxY0xMTHCnkK55btcDAODl5eWFO0KtYKwHAJC/o0eP5ufn1+OOGEDrAQDk79KlS5IzASgaaD0AgPxNnTpVT0+vHnfEALbrAQDkb+DAgfW4Fx7Sx3oMJo2hopS/Xmje1Nh0BfxRiao6nQ7/eioJNU0GapJFaOvWreTpcRSQ9NbT4NALsyqbPAyoQ3ZaBUefiTvF11TUieJcBV2+wVeyU5toEbpw4QKTqXDLKkl66+kZs8SiOo5IDJqYWCxWUaPpGsk6xi8WBqYqlRUC3ClA3YQCsQaHrt34rScUCn/99dfGfpYGk956+qYqbG3Gm4cKeihUanp4IduuuxaNrnCruLadNYuyq9KTGn4mE9A0Hl7IsnfmELRGX4TodLq7u3tjP0uD1fodrsswg6oK4cu7+YLqWk+oDJpGVaXowbksy3bqdj20cGeRbvBMk/fRRckxpXWetARgUVUpijydaduZ3dqxKY7KkZOTs2HDhiZ4ooaRfqQpiee3C2OflDCYNDVN2F6Ngao6PS+dr6nLsHfmtHFS9KPIRF3Ie/ekxNRGXShQ/u4Ti0UiEe1/51xWXmpses6nCm19pn1vjm3nJlqEYmNjt2/ffvTo0aZ5uu9VR+shhEQicUl+dXmpsKkigZoILT06m8NogrUSecnLqKyqUPr1g/T09CNHjqxevRp3EDng6DPZ2k06aikpKcnLy1PMQ4rWa389Go3QMWTpKOLBAYEiMjBtDoel44nEJVWppjYNP784lXE4HA5HyuHKFQT8NgMAIGcPHz68cuUK7hS1gq11AEinvIeJxy4mJkaRx3rQegBIx+PBvjgN5OHhoZb7rfIAABqeSURBVKOjgztFraD1AJCCRqO1bNkSdwplZWdnhzuCLLBdDwAp6HR6UlIS7hTKauvWrQp7cD1oPQCkU1FRUcyzGiqFP//8U1tbG3eKWkHrASCFurp6QkIC7hRKqaqqKjQ0lMFQ3K1n0HoASMFms7lcLu4USonFYnXq1Al3Clmg9QCQgsFgmJiYlJeX4w6ifG7fvn348GHcKWSB1gNAOgaDkZ2djTuF8nn16pWWloIeJoOkuOveAODVoUOHgoICa2tr3EGUzMiRI42MjHCnkAXGegBIp6GhkZycjDuF8rG2tlbwn7VA6wEgna2tLeyy972ys7NXrlyJO0UdoPUAkK5169ZCIRxg7fs8e/ZMRUXRD7pT9/H1AKAsZ2fn+/fvK/6fseLIzs5WU1NT5EMPwFgPAFk6d+78+vVr3CmUibGxsYJXHrQeALK4uLgkJibiTqE0Pn36NH36dNwp6gatB0CtnJ2dL168iDuF0oiOju7RowfuFHWD/fUAqJWZmRmbzY6Pj2/bti3uLEpgzJgxuCPUC4z1AJDFz8/v6dOnuFMoAYFAkJubiztFvcB3uADIIhaLu3bt+uLFC9xBFN2uXbsMDAzGjh2LO0jdYKwHgCwEQYwZM+bkyZO4gyi6hISE4cOH405RLzDWA6AORUVFy5YtCw0NxR0EyAeM9QCog46OjoODg4IfPQmv27dvl5WV4U5RX9B6ANRt1qxZ4eHhcLg9qSIiIh48eKCpqYk7SH3BGi4A9XLnzp2YmJjFixfjDqJwnj596uDgoK6ujjtIfcFYD4B66devX35+/t27d3EHUTg9e/ZUosqDsR4A36d79+7R0dGKfCqcJubq6vrgwQPcKb4PjPUA+A6//fbbggULcKdQFCEhIatWrcKd4rvBWA+A7xMeHl5WVjZ37lzcQUADwVgPgO8zceLE4uLi6Oho3EEwO3r0aGVlJe4UDQGtB8B3W7169c6dO9PS0nAHwWbZsmUmJiZKerxVWMMFoIEo+81GVVWVQCBQru9ta4KxHgANdP369aCgINwpmhqXy3358qXyVh60HgANZ2BgMG/evJEjR+IO0nSqq6s9PDx69uyJO8gPgTVcAH7Imzdvzp07t2nTJtxBmkJsbKytra2Sbs6TgLEeAD/EwcFh6NChSnG+iB8UGxtraWmp7JUHrQeAHDg6Os6bN2/atGm4gzSiWbNm8Xg8JTrEgAywhguAfOTn5y9atCg8PBx3EPkrLi5WU1NrBqM8Eoz1AJAPfX39oKCglStX4g4iZ0eOHNHW1m42lQetB4A82dvbT5w4ccCAAZIpLi4uo0aNwhrq+8yZM6fmV7Q7duxwcXHBmkj+oPUAkCdbW9vDhw+PHz9eIBC4u7vzeLyioiJlOdlQSkrKp0+fqqur3dzcyCkjRoywtrbGnUvOoPUAkDNjY+PQ0NBu3bqVlJQghAoLC2/duoU7VL1ERkbm5OQghMrKyrp164YQsrS0xB1K/qD1AJA/Pz8/Gu2/P67nz58rxdHn7927JxQKycsikWjgwIG4EzUKaD0A5MzX1zc/P7/mlMLCwkePHuFLVC9Pnz7Ny8sjCEIyJSsra/DgwVhDNQpoPQDkjMPhmJqaEgQhEonIKeXl5X/99RfuXHW4fft2UVGR5KpYLFZRUamqqsIaqlFQ7nARADS2kydPxsTEvH79+tmzZ7m5uTk5ORUVFcnJyV++fDE3N8edTrri4uK3b98ihGg0mra2tp6enpOTU58+fbp27Yo7mvzBXspA0X1O4H2Or6isEJXkV+PO8t2qq6oq+Hwul8vn8xX8y9CUjx9VVFU1NDTU1dVZLBbuON+No89kqhCmrdRadWTLvie0HlBoj/7ML+cKtfRY+qaqRD3uD6iLRhRk8nkl1VUVQu8JxjLuCK0HFNfT6wXlPFE3bwPcQYAyefOwsJIncPc3rO0O8G0GUFAf33JLiwRQeeB7OfTRZbBo75+W1HYHaD2goJJecVtYK/EBewFGJjYa8c/LarsVWg8oqMoKkV4LVdwpgFLSN1ERCGrddgetBxRUYU4VnQFfYICGYDBpeV9qPWsltB4AgFqg9QAA1AKtBwCgFmg9AAC1QOsBAKgFWg8AQC3QegAAaoHWAwBQC7QeAIBaoPUAANQCrQcAoBZoPQAAtUDrAaDonr/4e0zAoH5ePRIS4wb7uR87HtbgWV3686x7v25yTad8oPUAaFxDhnpkZWf+yBxOnDysqal1YH+4hXnLWT8v6NGjt/zSURGcIw2ARpSTk11SUvyDMykrK3Xo2KW1bVuEkJeXr5yiUReM9UDzce36Jf8xvl4+zgsWzvj8Oc3N3en+gzvkTYlJ8UuWzhns5z5gYJ/VaxZlZ2eR069cvTBkqEdcXOzM2RN8B7mMCRh0868rkhlG3ov4eeY4nwG9hw733H8gmM/nk9PX/bL0l/XLjoSH+Azo/fTpI4TQ3chb02cE9Pf9abCf+4pVCzIy0xFCr2Ne+I/xRQiNCRi0ak0QQkggEIQfDR0/cZiXj/PY8X5Xrl6Q/YoEAoGbu1Nq6sfLV867uTt9+PBOsob76VOqm7vT65gXq9YEDfZz9xvWb+++bUKhkHyg1Dz1V1RUuHnrmuEjvcmcly6dIafLftIbNy9PmjLSu3+vwX7ua9Yuzs3NIT+Ft29fS95PN3cnyasmb42Lf1/Pt/rjx6TvehW1gdYDzURc/PuduzY7O7scCj3l4z1ow8YVCCGCIMgB18KgGQSNtis4NHhHSGlZSdDimeT5rRkMBo/HPXYi7Je1265deeDpOWDX7i15ebkIocePH2zctNLRsfuhg6eXLF778FFk8K5N5HMxmcyU1OTEpPitm/fa2dnHxb/ftHlV9+69Qn47vnXLXn5Fxdp1ixFC9h06rVm9BSEUGnJi+dL1CKGQ0D1nzx0PGD3pcNjZEcMD9h/YcePmZRkvisFgXL5018KiZX+fwZcv3W3dup3kJjqDgRA68Fvw6FETrvwZuWrlpj8vn3v46B75VkjNU3/bdqz/8P7t6pWbww6eHjN64oHfdz6OfiD7Sd++fb0jeOOwoaMPh53dsnlPSWnxLxuWWVi0NDQ0in3/hpzt27evDA2N3r37twTfvH2lydZs07pdPd/qFi1Mv3OhqOVdlctcAMDu9u3rOjq6s2cupNPpFhYts3Oykj8mkjddvXaBIIhVKzdpsjURQiuWbRgdMDDqYWQ/Dx9yPDXGf6KhoRFCyMd78NFjhz5+TDQwMDx1JtzBocu0qXMQQmam5tOmzt28ZfW0KXMMDY3ECGVmpu/dc5ijxUEI0emMkN+Pt7K2ZTAYCKHhw8asXL2wqKhQR0dXXV0DIaSpqaWhocHlcq9cPR8wZhK5lmpmap6UFH/qdPiA/kNkvC4OR5tGo7FYLA5H+9tbXfp4tG/fESHk2KWbSQvThIQPbq79zM0sa8tTzzdz9qwgGo1m0sIUIWRubnnlyvkXL/7u3ctVxpOmpn1UUVHx9hrIYDBMTczWrt6anZOFEOrcqeu72BjygTFvXg7o73f9xiXy6pu3r7p06Uaj0er/VssFtB5oJj5/Tmtv15FOp5NXf+rtdiQ8hLwcFxfbtk17svIQQkZGxi1amCYnJ5CthxCytrYlL2hqaiGEyrhlIpEoMTFu4oQZkvl3cnBECKWkJJH9aG5uKfk7ZLPZWVkZYWH7MzK+8Cv5gupqcmPcVy3z8WOiQCBwcuwhmeLg4Hjj5uXy8nJ19QaeF6nV/5IjhNhsTS63rP55ZFBTVTt1Jjwm5kVJSbFIJCorKzU1NZf9pJ07OREEMW/+1P4+gx0du7cwNtHV1SObcd/+7WKxuLi4KCPjy+BBw0+e+iMrO7OFsUlsbEzAmMnf9VbLBbQeaCZKS0v09P87jaRWjb8THo+blJzg6d1TMqW6urqgMF9yVUVF5f/NSyzm8/lCoTD8aOix44dq3iJ5lIYGWzLx3v3bGzauGDd2ytw5izU02O9iY35Zv+zbhOXlPITQgqAZ5Ho3Qog8G3VhUUGDW4/1/5OTM6xnntoIBIIly+YIhcI5sxdZmLek0+nkRknZT2ph0XL/3iOnzx49eGhf2c5N7dp1mDN7kV27Dl26dCvjlqWlpXz6nNrK2pbD0W7Txu7d29fklgdHx+7f9VbLBbQeaCaYLFbl/zaBk0MbyWUNDba9faegBStr3l9NTVbRqKqqMhiMoX7+X61+aksbLt248WfnTk6TJ80kr9aMURP517tyxUZrK5ua0w0NjOp6cd+nnnlqExcXm5KSvGfXoY4dO5NTSoqLWhib1PnAVq1sV63YKBQK372LOXzktxX/196dB0dR5XEAf9NzZo7c1+ROSLKEJEwgBAFJxAMKVnRLXVEXlQJ2OdQVFY/yoERx1dUFVDxQUc4FFEVlS5dDwnIpKBAICTEhEEIySSaTyTn3uX/MbqTKSYydaXrezPdT/JHMm375VYd85/Xr7tfPPvLp9m9iYmLT0zOrqs9cuFBXWDjGO915tuq0x+NJTkpJUie73e6h72q/wNkMCBIpKWm1dee84w5CyOEjB/qb8vIKtNqmpKSUtLQM7z+BQBATEztIbwzD5OSM1Ola+zdRq5OFIlG4KvyXb7Y77FdOuu0v390/AvLyfp2VlSMWi7u6Ovv7DA+PiIiIlEgkftoHQ61ncDa77crBcnV1ZWtby69uXlNTVV1dSQgRCoVFRcXz5i7u6enu7DQQQoqLr6mqPnOm8pRGM9abepVnK85WnS4uvua37mq/QOpBkJhSdpNO17Z+w9qWVu23+3d/9/2h/qZbZt5hsZj//try8/W1zc2XN21eN3f+rJ9+qh68w7vvuv/Q4fKt2zY0NTWer699+ZVlDy+ZbzKZfvnOvJEFJ04cq6mpamtrXf3GK9HRsYSQ2tpzVqvV+6d77NiRS5cuKpXKmTNv37Dx/fIDe1tatRWnTzz+5AOvvrbc77tikHqGsnn2iFyJRLLzi+0GQ8ePJ469tea1knETmpobu7o6B9nq+A/fPbvssYOH9mtbms/X1+7cuT0xQZ2QkEgIGVtUUlHxY2NjQ2FBESEkv0DT3Hz5xMlj3tT7TbvaL3CEC0Fi0qSyeXMX7/xi+2efb9Voih979JkFC2dLJVJCSGKietXK9z/44K2Hl8wXCoUZGSNeWrFq1KjCwTssK73hmadXbNu+Yf2GtQqFsqBAs3rl+wqF4pfvnD17Xktr89InFsvlipk3337/fX82GPT/WPUSIxReP2Xq+PGT3lu7urCgaNXKtQ8selSlVH3w4VsGQ0d0dMykiWXz5z3o910xSD1D2TwyMurJJ55ft+7tvfu+zs3Ne+rJ5fqO9hUvPf3Y44tWvLhyoK3unT3P6XSsXftGh0Hv3V2vvvKWdwZToynu7DSkpqZHRkYRQlRKVUZGVkPDhaKicd5th76r/UIw9HEvwNW0fvmlGfNSFBFD/WD2eDydnYb+49bKyoolj/7l43WfZGaO4LJMCFAbl9c/tDrbZxOOcCFInDlz6o+zpm/avK65+XJV1Zl331s1cmR+RkYW33VBwMERLgSJoqLip5964ZMdm7duW69Uqoo0xQsXLOm/RiSQbd22Ydv2DT6b0tIy31mz3u8/8ezZ088898hArVs2f+Xf6+MCDY5wIUD91iNcepnNZovF7LNJJBL5vCVjmBwOR29vz0Ct0dExVHxaDG6QI9zg/y8FEODkcjnrq5TZEYvFg1+4E9wwrwcAoQWpBwChBakHAKEFqQcAoQWpBwChBakHAKEFqQcAoQWpBwChBakHAUosZYLgDgHgi1g24I1nSD0IUBKpwNTr4LsKoJKp1ymRDPipidSDAJWYKes12PmuAqjUrbcljQgbqBWpBwFq3E1RJ/Ya+K4CqHRiT0fxTVEDtWLNFQhc+iZb+Q791PuSxBJ8PMNQ7d7QPGFGdGrugAs6IPUgoGkvWI59bXA6PMnZCpvVzXc5ELhkcmHLBRPDEM11kdmawR4midSDQOfxeHSNtq52u82C1PvZmjVrFi1aJBaL+S4kUIglTFS8ODFDxgh/5dQ/Ug+ASqWlpXv27LnKC/MFB0yXAEBoQeoBQGhB6gFQKSoqCveusIPUA6CSVCrluwRaIfUAqNTW1oZTkewg9QCopFQqcYTLDlIPgEpGoxFjPXaQegAQWpB6AFTKzc3luwRaIfUAqFRXV8d3CbRC6gFQKS4uDmcz2EHqAVBJr9fjbAY7SD0ACC1IPQAqFRQU8F0CrZB6AFSqqqriuwRaIfUAILQg9QCoNHr0aJzDZQepB0ClyspKnMNlB6kHAKEFqQdApfz8fL5LoBVSD4BK1dXVfJdAK6QeAIQWpB4AlbKzs/kugVZIPQAq1dfX810CrZB6ABBakHoAVMKTIVlD6gFQqaurC1cps4PUA6BSYmIixnrsIPUAqITn4bKG1AOA0ILUA6AS1lxhDakHQCWsucIaUg+ASpGRkRjrsYPUA6BSd3c3xnrsIPUAILQg9QColJyczHcJtELqAVBJq9XyXQKtkHoAVEpNTeW7BFoh9QCopNfrcQ6XHaQeAJWsVivO4bIjwI4DoEhxcTEhxPtnyzCMx+PxeDylpaVvvvkm36VRA2M9AJpkZWUJBAKGYRiGIYQIBIL4+PiFCxfyXRdNkHoANJk8ebI377w8Hk9hYeGoUaN4LYoySD0AmsyaNSspKan/29jY2Dlz5vBaEX2QegA0UavV1157rXdezzvQKygo4LsoyiD1ACgze/Zs740ZsbGxc+fO5bsc+iD1ACiTlJRUWlrq8Xg0Gk1+fj7f5dAHV64AcEtbbzH1OE19TqedWM0uv/RpMpn27dtXVlYWHR3tlw7DFEKhiMhVIkW4MDknLLivf0bqAXCi9mTf+QpjY40pPlPlsLmFYqFYJna7+S5rAAwjcNrsLodLJBLoGowpufKcMYr8CRF818UJpB6An9X80HvkK0NEolyqCguPkwsY+sZNvXqzpcvc2WycdEuMpiyS73L8DKkH4DfGHuc363VOlzB+RLRIKuS7nOFyO936i512k236nIS4ZCnf5fgNUg/APxprTHs2t6ePVUsVYr5r8SeHzdl0um3izVF5JeF81+IfSD0AP2htsOz/1JAyWs13IVxpPacbPy1iRKGC70L8AKkHMFx1FX3Hd/ekFgVt5Hlpq3SjSuRjplA/zYfr9QCGpavdfuSrzqCPPEJIckFC1ffG5noz34UMF1IPYFj2bNZnlCQN4Y3BILVIfXRXl9Xk5LuQYUHqAbB35KsOYZjsykVQgp5YpfjP5wa+qxiWEPptAfiX3eo+e7QnLpP6ea7fJDpFpa23dOvtfBfCHlIPgKWT+7vUI2P5rmJAO//1+utr7uGi5/jsmJPlPVz0fHUg9QBYOnesTxEl47sKHihj5D8dR+oBhJiOFrtQJBDLRHwXwgMBQyLiwy7/ROvJ3FD8nQEMX1OtOVyt4q7/isq9B49u1ekbpFL5mMJpM25aLJHICCHLX51+43Vzu3t0FZV77XZzZnrRnX94Jjw8lhDS06vf8eXf6htOymTKiSW3c1cbIUQRp2yut6SNlHP6UziCsR4AG7rLNoGQqz+fqnMH/7ljWW72+KUPbrnrtmWV1eWf7XrF28QwogOHNyfEZz679MvH/7pN21r77cGPvU3bPl/e1n5x/n2rF89912TqPnvuAEflEUJEEqa1wcpd/5xC6gGwYep1iiRcrS9QfnhTVsbY3099IDYmNS930s3THjx1Znd3j87bmhCfMX7sLUKhKDIi4Xc5E5u0NYSQ7p72+osnri+9PydrXEJ85m0zH5dJObx7TCwVmfv8s1bg1YfUA2DD3OcSSzmZIHK73c0tNbnZ4/tfycoYSwhpbav3fqtOyOlvkoeFmy29hJB2/SVCSFrK/x6WJhAIUlM4fHCaSCq0GGm9VhnzegBsCAQews26eQ6H1e127S3/cN+Bj658vbevw/uFWOxj0Seb3UwIEYl+bpJKuJx0ExCGwnUDvZB6AGyEKUVOm4so/d+zWCwTCkWTJ9x1TfGtV76uVAy2WLxEEkYIsVqN/a9YrH3+L+7/nFaXVE7rAoJIPQA2FBEii42TQzyGYZLVI7u6W+PjMryvOJ2O7h6dXD7Y8nZxMWmEkJa285npGkKIy+W80HBKLudqCXiHzSlX0Zp6mNcDYCM+VexxcfUUjCmT7z177kD5oY3t+kZtS+3Wz55/Z90Cq9U0yCbRUer01MLyQxtr649rW2p3fPmySMTh4qZuhysxg9bVlZF6AGykZMv7dMYhvJGN0fnX33PHCxWVe1e+/acPNj7scjkWz3tXJvuVc7Kz73wxLjbt4y1LP9y0JDIycaxmhoezpxMZO0zJI8I46pxrWFUUgKV1zzWkj0vi6ExuIPN4PNX7Lj20OpvvQljCWA+ApVETVMZOC99V8MDYYcm7huKHRobcxxSAv4y5PmrTisaoge9LO3psx7/3r/XZ5HTYRL4uQCGE3H378wV5Zf4qsqHx9EdblvquwWkXCcXE1wO/77ptWeGoKQP12dHQeeuCRH9VePXhCBeAvcNf6tt1TEya7yX2LFajxdLrs8ls6ZOH+Y5LpSLae8utXzgctj6j70VArVajRCL3uSSqQhEllfietutpNUqFlulzkHoAIcntdu94oyUhL/gfmtGv47xu+px4ZQTFh4mY1wNgj2GYG2bFNZ7U8l3IVdJS3VYyNYLqyEPqAQxXXIq0ZGqktqqN70I4p6vV52rC0vOofyQujnAB/KCpznxkV5c6n+LZrsG11+kLr1XkjeNwScGrBmM9AD9IzZWXTI24eLzJYaV1JZKBuJzupoqWvHGy4Ig8jPUA/Klbb9+7RScQS2LSoxlRMAwpDA2dpk7ztHsTEjOC5wkhSD0AP6s80n10lyEuI1yqkqliqVxj3dRpMXdbdPU9E2+OGXtjpMDXNX30QuoBcKL6+566ClPLBXPiiHC7zSMUCyVyMQnYvzaBwG5xuOxOsYToG41xybKcMQpNWXA+6hepB8Ahl9PTXGfu63L2dTttFmLuc/BdkW8KlUQk9YRHiZSRouTsMIksGA7PB4LUA4DQEsyJDgDwS0g9AAgtSD0ACC1IPQAILUg9AAgtSD0ACC3/BetH4i6RcAUZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "langgraph = StateGraph(OverallState, input=InputState, output=OutputState)\n",
    "# langgraph.add_node(guardrails)\n",
    "langgraph.add_node(generate_cypher)\n",
    "langgraph.add_node(validate_cypher)\n",
    "langgraph.add_node(correct_cypher)\n",
    "langgraph.add_node(execute_cypher)\n",
    "langgraph.add_node(generate_final_answer)\n",
    "\n",
    "langgraph.add_edge(START, \"generate_cypher\")\n",
    "# langgraph.add_conditional_edges(\"guardrails\",guardrails_condition)\n",
    "langgraph.add_edge(\"generate_cypher\", \"validate_cypher\")\n",
    "langgraph.add_conditional_edges(\"validate_cypher\",validate_cypher_condition)\n",
    "langgraph.add_edge(\"execute_cypher\", \"generate_final_answer\")\n",
    "langgraph.add_edge(\"correct_cypher\", \"validate_cypher\")\n",
    "langgraph.add_edge(\"generate_final_answer\", END)\n",
    "\n",
    "langgraph = langgraph.compile()\n",
    "\n",
    "# View\n",
    "display(Image(langgraph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH path = (m1:Module {id: 'Utils.Utils'})-[*..5]-(m2:Module {id: 'Deduplication.__Main__'}) \n",
      "WHERE NONE(n IN nodes(path) WHERE n:Package) \n",
      "RETURN path\n",
      "[{'path': [{'id': 'Utils.Utils'}, 'USES', {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'}, 'CONTAINS', {'id': 'Deduplication.Lsh.Lsh'}, 'CALLS', {'id': 'Deduplication.__Main__.Model'}, 'INITIALIZES', {'id': 'Deduplication.__Main__.__Main__'}, 'DEFINES', {'id': 'Deduplication.__Main__'}]}, {'path': [{'id': 'Utils.Utils'}, 'USES', {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'}, 'CONTAINS', {'id': 'Deduplication.Lsh.Lsh'}, 'CALLS', {'id': 'Deduplication.__Main__.Model'}, 'DEFINES', {'id': 'Deduplication.__Main__'}]}, {'path': [{'id': 'Utils.Utils'}, 'USES', {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'}, 'CONTAINS', {'id': 'Deduplication.Lsh.Lsh'}, 'CALLS', {'id': 'Deduplication.__Main__.Model'}, 'USES', {'id': 'Deduplication.Lshimproved.Lsh'}, 'IMPORTS', {'id': 'Deduplication.__Main__'}]}, {'path': [{'id': 'Utils.Utils'}, 'USES', {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'}, 'CONTAINS', {'id': 'Deduplication.Lsh.Lsh'}, 'CALLS', {'id': 'Deduplication.__Main__.Model'}, 'USES', {'id': 'Deduplication.Lshforest.Lshforest'}, 'IMPORTS', {'id': 'Deduplication.__Main__'}]}, {'path': [{'id': 'Utils.Utils'}, 'USES', {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'}, 'CONTAINS', {'id': 'Deduplication.Lsh.Lsh'}, 'INHERITS', {'id': 'Deduplication.Lshforest.Lshforest'}, 'IMPORTS', {'id': 'Deduplication.__Main__'}]}, {'path': [{'id': 'Utils.Utils'}, 'USES', {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'}, 'CONTAINS', {'id': 'Deduplication.Lsh.Lsh'}, 'INHERITS', {'id': 'Deduplication.Lshforest.Lshforest'}, 'USES', {'id': 'Deduplication.__Main__.Model'}, 'DEFINES', {'id': 'Deduplication.__Main__'}]}, {'path': [{'id': 'Utils.Utils'}, 'USES', {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'}, 'CONTAINS', {'id': 'Deduplication.Lsh.Lsh'}, 'USES', {'id': 'Deduplication.__Main__.Model'}, 'INITIALIZES', {'id': 'Deduplication.__Main__.__Main__'}, 'DEFINES', {'id': 'Deduplication.__Main__'}]}, {'path': [{'id': 'Utils.Utils'}, 'USES', {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'}, 'CONTAINS', {'id': 'Deduplication.Lsh.Lsh'}, 'USES', {'id': 'Deduplication.__Main__.Model'}, 'DEFINES', {'id': 'Deduplication.__Main__'}]}, {'path': [{'id': 'Utils.Utils'}, 'USES', {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'}, 'CONTAINS', {'id': 'Deduplication.Lsh.Lsh'}, 'USES', {'id': 'Deduplication.__Main__.Model'}, 'USES', {'id': 'Deduplication.Lshimproved.Lsh'}, 'IMPORTS', {'id': 'Deduplication.__Main__'}]}, {'path': [{'id': 'Utils.Utils'}, 'USES', {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'}, 'CONTAINS', {'id': 'Deduplication.Lsh.Lsh'}, 'USES', {'id': 'Deduplication.__Main__.Model'}, 'USES', {'id': 'Deduplication.Lshforest.Lshforest'}, 'IMPORTS', {'id': 'Deduplication.__Main__'}]}]\n"
     ]
    }
   ],
   "source": [
    "results = langgraph.invoke({\"question\": \"How is the Utils.Utils module related to the Deduplicatioin.__Main__ module?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'CALLS',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'INITIALIZES',\n",
       "   {'id': 'Deduplication.__Main__.__Main__'},\n",
       "   'DEFINES',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'CALLS',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'DEFINES',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'CALLS',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lshimproved.Lsh'},\n",
       "   'IMPORTS',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'CALLS',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lshforest.Lshforest'},\n",
       "   'IMPORTS',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'INHERITS',\n",
       "   {'id': 'Deduplication.Lshforest.Lshforest'},\n",
       "   'IMPORTS',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'INHERITS',\n",
       "   {'id': 'Deduplication.Lshforest.Lshforest'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'DEFINES',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'INITIALIZES',\n",
       "   {'id': 'Deduplication.__Main__.__Main__'},\n",
       "   'DEFINES',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'DEFINES',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lshimproved.Lsh'},\n",
       "   'IMPORTS',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lshforest.Lshforest'},\n",
       "   'IMPORTS',\n",
       "   {'id': 'Deduplication.__Main__'}]}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['cypher_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Utils.Utils module is related to the Deduplication.__Main__ module through several intermediate connections:\n",
      "\n",
      "1. Utils.Utils uses the Compute_Minhash_Signatures function from Deduplication.Lsh.Lsh.\n",
      "2. Deduplication.Lsh.Lsh calls or uses the Model class from Deduplication.__Main__.\n",
      "3. The Deduplication.__Main__ module defines the Model class and the __Main__ class.\n",
      "\n",
      "Additionally, there are indirect connections through other modules like Lshimproved.Lsh and Lshforest.Lshforest, which are imported by Deduplication.__Main__. \n",
      "\n",
      "In summary, Utils.Utils is primarily connected to Deduplication.__Main__ through the use of shared components and dependencies within the Deduplication system, particularly through the Lsh module and the Model class.\n"
     ]
    }
   ],
   "source": [
    "print(results.get(\"answer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Answer with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # You can pass the path if the file isn't in the same directory\n",
    "# load_dotenv(dotenv_path='../../.env')\n",
    "\n",
    "# # Access your variables\n",
    "# pinecone_api = os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_pinecone import PineconeVectorStore\n",
    "# from pinecone import Pinecone\n",
    "\n",
    "# pc = Pinecone(api_key=pinecone_api)\n",
    "# index = pc.Index('llama-text-embed-v2-index')\n",
    "# vector_store = PineconeVectorStore(embedding=embeddings, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── src/\n",
      "│   ├── deduplication/\n",
      "│   │   ├── bloom_filter.py\n",
      "│   │   ├── dedup.py\n",
      "│   │   ├── LSH.py\n",
      "│   │   ├── LSHForest.py\n",
      "│   │   ├── LSHImproved.py\n",
      "│   │   ├── __init__.py\n",
      "│   │   ├── __main__.py\n",
      "│   ├── utils/\n",
      "│   │   ├── use_cases.py\n",
      "│   │   ├── utils.py\n",
      "│   │   ├── visualizations.py\n",
      "│   │   ├── visualization_lsh.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def generate_repo_tree(repo_path, indent=\"\"):\n",
    "    tree_string = \"\"\n",
    "    for root, dirs, files in os.walk(repo_path):\n",
    "        # Filter out __pycache__ and hidden directories\n",
    "        dirs[:] = [d for d in dirs if d != \"__pycache__\" and not d.startswith(\".\")]\n",
    "        files = [f for f in files if not f.startswith(\".\")]\n",
    "\n",
    "        level = root.replace(repo_path, \"\").count(os.sep)\n",
    "        indent = \"│   \" * level + \"├── \"  # Formatting the tree\n",
    "        tree_string += f\"{indent}{os.path.basename(root)}/\\n\"\n",
    "\n",
    "        sub_indent = \"│   \" * (level + 1) + \"├── \"\n",
    "        for file in files:\n",
    "            tree_string += f\"{sub_indent}{file}\\n\"\n",
    "\n",
    "    return tree_string\n",
    "\n",
    "# Set your repo path\n",
    "repo_path = \"./assignment-2-mcdonald-s/src\"  # Change this to your cloned repo path\n",
    "\n",
    "# Generate tree and store as string\n",
    "repo_tree_string = generate_repo_tree(repo_path)\n",
    "\n",
    "# Print the repo tree\n",
    "print(repo_tree_string)\n",
    "\n",
    "# Store it as a variable to feed into an LLM\n",
    "# llm_input = f\"Here is the repository structure:\\n{repo_tree_string}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deduplication.bloom_filter.py\n",
      "deduplication.dedup.py\n",
      "deduplication.LSH.py\n",
      "deduplication.LSHForest.py\n",
      "deduplication.LSHImproved.py\n",
      "deduplication.__init__.py\n",
      "deduplication.__main__.py\n",
      "utils.use_cases.py\n",
      "utils.utils.py\n",
      "utils.visualizations.py\n",
      "utils.visualization_lsh.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "    You are an expert in translating code into natural language.\n",
    "    Your goal is to generate a natural language description of the code in the given file.\n",
    "    The description should be in a natural language format, and in great detail, but it should not be too verbose.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "i = 0\n",
    "descriptions = {}\n",
    "\n",
    "for root, dirs, files in os.walk(repo_path):\n",
    "    \n",
    "    # Skip hidden directories (e.g., .git, .idea, __pycache__)\n",
    "    dirs[:] = [d for d in dirs if not d.startswith(\".\") and d != \"__pycache__\"]\n",
    "\n",
    "    for file in files:\n",
    "        if file.startswith(\".\"):\n",
    "            continue  # Skip hidden files\n",
    "\n",
    "        file_path = os.path.join(root, file)\n",
    "        relative_path = os.path.relpath(file_path, repo_path)\n",
    "        rel_path = relative_path.replace(\"\\\\\", \".\")\n",
    "        print(rel_path)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                lsh_code = f.read()\n",
    "\n",
    "            messages = [\n",
    "                SystemMessage(system_prompt),\n",
    "                HumanMessage(f'''\n",
    "                    Tree:\n",
    "                    {repo_tree_string}\n",
    "\n",
    "                    Current File Path:\n",
    "                    {rel_path}\n",
    "\n",
    "                    Code:\n",
    "                    {lsh_code}\n",
    "                ''')\n",
    "            ]\n",
    "\n",
    "            response = llm.invoke(messages)\n",
    "            descriptions[rel_path] = response.content\n",
    "            i += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = {k.replace('\\\\', '.'): v for k, v in descriptions.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "\n",
    "all_docs = []\n",
    "for i in descriptions:\n",
    "    docs = text_splitter.create_documents([descriptions[i]])\n",
    "    for d in docs:\n",
    "        d.metadata['source'] = i\n",
    "    all_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['184d7df5-6d05-4210-ac5f-67e6cb44adb8',\n",
       " '89204364-381a-428a-b0f4-1df5b60c6b54',\n",
       " 'ada3274e-56a7-4a82-93a9-f48ade131bf6',\n",
       " 'eda80cd4-3ed4-4bd1-a1cf-7c778614bf52',\n",
       " '9c913c54-8f6d-419a-9c87-d23534498169',\n",
       " 'af9c56e3-1f06-464d-bc53-e96822a5981f',\n",
       " 'b8ea34b2-0a72-4928-a277-e4dba4f200eb',\n",
       " 'dbf201b2-1ea4-41a9-87b3-191569b37b3f',\n",
       " '5cb92725-f21c-467d-b649-4ef1d02128fe',\n",
       " '784bfa80-e615-4ebc-bf3a-e79bb95a172f',\n",
       " '8dbf4008-dd62-491c-9614-44ed8cb38367',\n",
       " 'c8677b4e-6bb6-423b-bd75-ed2b1be87f8c',\n",
       " '6b9f04eb-4bdc-45db-803c-91e55872c2d8',\n",
       " '7958c971-0705-4858-8a76-7972c1353590',\n",
       " 'fd70693c-ad54-472a-bb60-334bf36791f6',\n",
       " '4dd23362-ff22-4fe2-b5fc-11ef31c5dffb',\n",
       " 'd2915f97-a32d-40cf-a484-2e6943129c16',\n",
       " 'bf5ea85a-6957-412d-84ac-f41bb6e6b053',\n",
       " 'e8328835-7ef0-4859-b7da-6cf1d9f94088',\n",
       " 'f93397ea-0056-4140-90c7-55a2af0b900e',\n",
       " '88fe1e2b-4728-48fa-b14b-fcfad8de7fe1',\n",
       " 'f093b9bd-e97d-4c37-80d8-b84754913ed9',\n",
       " '24c19ec0-bf60-41db-b6c4-8c65abfe6a7b',\n",
       " 'fb3b64c6-7713-4894-bae7-67055dcb94d5',\n",
       " '5d894556-cc9d-47e3-bff6-2c1cfbdfe12d',\n",
       " '7b855c99-46da-424a-8757-9918364952ff',\n",
       " '1f414f1b-5df4-464c-9bc1-704076822316',\n",
       " 'cb3ef1ae-0ab9-4312-9d1d-30b9d4ec8b03',\n",
       " '07d3f64f-a89a-4b53-9fd7-e160417103ec',\n",
       " '9c43d8b4-4122-4e87-8df1-0b28180e8894',\n",
       " 'd576a821-8ed5-437f-b05b-8303371ba1f5',\n",
       " '635d5aaf-e78f-48a3-8901-d40cf16dca86',\n",
       " '619d809a-6196-4ca9-ae1f-60a9f48d63a0',\n",
       " 'bec05deb-bd90-48c9-9b24-77dd4ef5d9bd',\n",
       " '50724a58-2eaa-45a1-a4e6-efbc4f54c9b3',\n",
       " '571058fb-d300-42f7-ac70-273381e5b110',\n",
       " '08a35d29-f487-4a6c-8b5c-fe07b61534d1',\n",
       " '9c9a3967-154b-4e0e-bcae-bdf0a72ddb2c',\n",
       " 'c027da8a-cba2-404f-88b2-b9a0005c8dc2',\n",
       " '87116e09-8247-4ccf-be0f-b21410e8bbd3',\n",
       " '8dc88316-dde9-4352-b59f-0eb666599011',\n",
       " '5540ebd4-4989-4050-955c-fab089e2c77c',\n",
       " '9c896dea-66be-464a-a015-61edca950190',\n",
       " 'e6bd1810-dec5-4640-851f-c0da1297aef2',\n",
       " '63d782ac-7e33-4fb1-b66b-72621ab8716c',\n",
       " 'bcd33afe-7584-455b-8765-d462ec40e607',\n",
       " 'a87471a2-ebdf-4838-abfd-96c468580d98',\n",
       " '40efad9f-de77-4ede-b8f1-5f266f9dfa0a',\n",
       " '780335d0-81ee-45be-b6fd-ab76fa45062e',\n",
       " '1eee0bc7-4a17-46b9-a02b-85877f5b21d8']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ - vector_store.add_documents(documents=all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert in adding relevant details to a GRAPH RAG queried statement. You will be given a sentence to analyze (which is the output of a cypher query) and a context (which is additional information on the nodes and relationships). \n",
    "Your task is to add relevant details to the sentence to make it more informative and useful. The context will be used to provide additional information about the entities and relationships in the sentence.\n",
    "Sentence to analyze: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(system_prompt)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"], k=10)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": results.get(\"answer\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Utils.Utils module is intricately related to the Deduplication.__Main__ module through several intermediate connections, reflecting a well-structured framework that enhances document deduplication capabilities. Here are the key points of this relationship:\n",
      "\n",
      "1. **Function Utilization**: The Utils.Utils module utilizes the `Compute_Minhash_Signatures` function from Deduplication.Lsh.Lsh, which plays a crucial role in generating MinHash signatures for documents. This computational function is essential for the efficiency of the deduplication process, as it allows for quick similarity comparisons between documents based on their hashed representations.\n",
      "\n",
      "2. **Class Interdependency**: The Deduplication.Lsh.Lsh module invokes the `Model` class from Deduplication.__Main__. This class serves as the backbone of the deduplication system, encapsulating core functionalities and configurations necessary for implementing various LSH-based methods effectively. The relationship emphasizes a modular design where the Lsh module extends the capabilities defined in the __Main__ module, facilitating code maintainability and scalability.\n",
      "\n",
      "3. **Definition of Key Classes**: The Deduplication.__Main__ module independently defines both the `Model` class and the `__Main__` class. The `Model` class encompasses methods for executing the deduplication algorithms and managing the data structures involved, while the `__Main__` class is responsible for orchestrating the overall execution flow of the deduplication process. This design fosters a clear separation of concerns, allowing more straightforward debugging and enhancement in future iterations.\n",
      "\n",
      "4. **Indirect Connections through Variants**: Additional relationships exist through other modules like `Lshimproved.Lsh` and `Lshforest.Lshforest`, which are specifically imported by Deduplication.__Main__. These imports signify that the main deduplication script leverages advancements in LSH techniques, such as improved processes for handling larger datasets and enhanced accuracy in identifying duplicate documents.\n",
      "\n",
      "In summary, the Utils.Utils module is primarily connected to Deduplication.__Main__ through shared components and dependencies within the overall Deduplication system. These connections enhance the utility and efficiency of the deduplication process, particularly through the Lsh module and its associated classes and functions. The architecture aligns with best practices in software development by promoting modularity, enabling future enhancements like the implementation of new LSH-based algorithms without extensive modifications to the existing structure. This design not only streamlines the deduplication process but also positions the system for potential application in various scenarios, including plagiarism detection and content clustering.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rag_graph import create_rag_graph, RAGGraph\n",
    "\n",
    "def main():\n",
    "    # Set your repo path\n",
    "    repo_path = \"./assignment-2-mcdonald-s/src\"  # Change this to your cloned repo path\n",
    "    \n",
    "    # You can provide API keys here or they will be requested via getpass\n",
    "    # openai_api_key = \"your-openai-api-key\"\n",
    "    # anthropic_api_key = \"your-anthropic-api-key\"\n",
    "    \n",
    "    # Create the RAG graph\n",
    "    rag = create_rag_graph(\n",
    "        repo_path=repo_path,\n",
    "        # openai_api_key=openai_api_key,  # Uncomment to provide key directly\n",
    "        # anthropic_api_key=anthropic_api_key,  # Uncomment to provide key directly\n",
    "        embedding_model=\"text-embedding-3-large\",\n",
    "        llm_model=\"claude-3-5-sonnet-20240620\",\n",
    "    )\n",
    "    \n",
    "    # Alternative: Initialize step by step if you want more control\n",
    "    # rag = RAGGraph(repo_path=repo_path)\n",
    "    # rag.generate_repo_tree()\n",
    "    # rag.generate_code_descriptions()\n",
    "    # rag.build_vector_store()\n",
    "    # rag.build_graph()\n",
    "    \n",
    "    # Query the graph\n",
    "    question = \"How does the McDonald's application handle orders?\"\n",
    "    answer = rag.query(question)\n",
    "    \n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def visualize_cypher_results(cypher_results: List[Dict[str, Any]], output_file: str = \"cypher_graph.html\"):\n",
    "    \"\"\"\n",
    "    Visualize Cypher query results using Pyvis.\n",
    "    \n",
    "    Args:\n",
    "        cypher_results: List of path results from Cypher query\n",
    "        output_file: Output HTML file name\n",
    "    \"\"\"\n",
    "    # Create Pyvis network\n",
    "    net = Network(notebook=False, cdn_resources='in_line', height=\"800px\", width=\"100%\")\n",
    "    \n",
    "    # Create a NetworkX graph\n",
    "    G = nx.DiGraph()  # Using DiGraph for directed relationships\n",
    "    \n",
    "    # Track unique nodes and edges to avoid duplicates\n",
    "    unique_nodes = set()\n",
    "    unique_edges = set()\n",
    "    \n",
    "    # Extract node metadata (type from ID prefix)\n",
    "    node_metadata = {}\n",
    "    \n",
    "    # Process each path in the results\n",
    "    for result in cypher_results:\n",
    "        path = result.get('path', [])\n",
    "        \n",
    "        # Paths alternate between nodes and relationships\n",
    "        for i in range(0, len(path), 2):\n",
    "            # Add node\n",
    "            if i < len(path):\n",
    "                node = path[i]\n",
    "                node_id = node.get('id')\n",
    "                if node_id and node_id not in unique_nodes:\n",
    "                    unique_nodes.add(node_id)\n",
    "                    # Extract node type from ID (assuming format like \"Type.Name\")\n",
    "                    node_parts = node_id.split('.')\n",
    "                    node_type = node_parts[0] if len(node_parts) > 0 else \"Unknown\"\n",
    "                    \n",
    "                    # Store node metadata\n",
    "                    node_metadata[node_id] = {\n",
    "                        \"id\": node_id,\n",
    "                        \"type\": node_type,\n",
    "                        \"properties\": {}\n",
    "                    }\n",
    "                    \n",
    "                    # Add node to NetworkX graph\n",
    "                    G.add_node(node_id)\n",
    "            \n",
    "            # Add relationship/edge\n",
    "            if i + 1 < len(path) and i + 2 < len(path):\n",
    "                source_id = path[i].get('id')\n",
    "                relationship = path[i + 1]  # This is a string like \"USES\"\n",
    "                target_id = path[i + 2].get('id')\n",
    "                \n",
    "                if source_id and target_id:\n",
    "                    edge_key = (source_id, target_id, relationship)\n",
    "                    if edge_key not in unique_edges:\n",
    "                        unique_edges.add(edge_key)\n",
    "                        # Add edge to NetworkX graph\n",
    "                        G.add_edge(source_id, target_id, label=relationship)\n",
    "    \n",
    "    # Get unique types for coloring\n",
    "    unique_types = list(set(meta[\"type\"] for meta in node_metadata.values()))\n",
    "    color_map = plt.get_cmap(\"tab10\")\n",
    "    type_colors = {t: color_map(i / len(unique_types)) for i, t in enumerate(unique_types)}\n",
    "    type_colors_rgba = {\n",
    "        t: f'rgba({int(c[0]*255)}, {int(c[1]*255)}, {int(c[2]*255)}, 0.8)' \n",
    "        for t, c in type_colors.items()\n",
    "    }\n",
    "    \n",
    "    # Degree-based sizing\n",
    "    degrees = dict(G.degree())\n",
    "    min_size, max_size = 15, 50\n",
    "    max_degree = max(degrees.values()) if degrees else 1\n",
    "    size_scale = {\n",
    "        node: min_size + (max_size - min_size) * (deg / max_degree)\n",
    "        for node, deg in degrees.items()\n",
    "    }\n",
    "    \n",
    "    # Add nodes to Pyvis with proper styling\n",
    "    for node_id in G.nodes():\n",
    "        metadata = node_metadata.get(node_id, {})\n",
    "        label = node_id.split('.')[-1]  # Use last part of ID as label for cleaner display\n",
    "        node_type = metadata.get(\"type\", \"Unknown\")\n",
    "        color = type_colors_rgba.get(node_type, \"gray\")\n",
    "        \n",
    "        # Add node to Pyvis network\n",
    "        net.add_node(\n",
    "            node_id,\n",
    "            label=label,\n",
    "            size=size_scale[node_id],\n",
    "            color=color,\n",
    "            title=f\"<b>{node_type}</b><br>{node_id}\"\n",
    "        )\n",
    "    \n",
    "    # Add edges to Pyvis\n",
    "    for source, target, attr in G.edges(data=True):\n",
    "        rel_label = attr.get(\"label\", \"\")\n",
    "        net.add_edge(source, target, title=rel_label, label=rel_label, arrows='to')\n",
    "    \n",
    "   \n",
    "    # Save graph\n",
    "    net.save_graph(output_file)\n",
    "    \n",
    "    # Build legend\n",
    "    legend_html = \"\"\"\n",
    "    <div id=\"legend\" style=\"position: absolute; top: 10px; left: 10px; background: white; padding: 10px; border-radius: 8px; box-shadow: 0px 0px 5px rgba(0,0,0,0.2); font-family: Arial, sans-serif; z-index: 1000;\">\n",
    "        <h4 style=\"margin: 0; padding-bottom: 5px;\">Node Legend</h4>\n",
    "    \"\"\"\n",
    "    \n",
    "    for node_type, color in type_colors_rgba.items():\n",
    "        legend_html += f'<div style=\"display: flex; align-items: center; margin-bottom: 5px;\"><div style=\"width: 15px; height: 15px; background:{color}; margin-right: 5px; border-radius: 50%;\"></div> {node_type}</div>'\n",
    "    \n",
    "    legend_html += \"\"\"\n",
    "        <h4 style=\"margin: 5px 0; padding-bottom: 5px;\">Relationship Legend</h4>\n",
    "    \"\"\"\n",
    "    \n",
    "    for rel_type in sorted(set(attr.get(\"label\", \"\") for _, _, attr in G.edges(data=True))):\n",
    "        legend_html += f'<div style=\"display: flex; align-items: center; margin-bottom: 5px;\"><div style=\"width: 20px; height: 2px; background: #666; margin-right: 5px;\"></div> {rel_type}</div>'\n",
    "    \n",
    "    legend_html += \"</div>\"\n",
    "    \n",
    "    # Inject legend into the HTML\n",
    "    with open(output_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    html_content = html_content.replace(\"</body>\", legend_html + \"</body>\")\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "    \n",
    "    print(f\"Graph visualization saved as {output_file}\")\n",
    "    \n",
    "    # Return graph stats\n",
    "    return {\n",
    "        \"nodes\": len(G.nodes()),\n",
    "        \"edges\": len(G.edges()),\n",
    "        \"node_types\": unique_types,\n",
    "        \"relationship_types\": list(set(attr.get(\"label\", \"\") for _, _, attr in G.edges(data=True)))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph visualization saved as code_relationships_graph.html\n"
     ]
    }
   ],
   "source": [
    "stats = visualize_cypher_results(results['cypher_results'], \"code_relationships_graph.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualize a graph from Cypher query results using Pyvis and NetworkX.\n",
    "\"\"\"\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def visualize_cypher_results(cypher_results: List[Dict[str, Any]], output_file: str = \"cypher_graph.html\"):\n",
    "    \"\"\"\n",
    "    Visualize Cypher query results using Pyvis.\n",
    "    \n",
    "    Args:\n",
    "        cypher_results: List of path results from Cypher query\n",
    "        output_file: Output HTML file name\n",
    "    \"\"\"\n",
    "    # Create Pyvis network\n",
    "    net = Network(notebook=False, cdn_resources='in_line', height=\"800px\", width=\"100%\")\n",
    "    \n",
    "    # Create a NetworkX graph\n",
    "    G = nx.DiGraph()  # Using DiGraph for directed relationships\n",
    "    \n",
    "    # Track unique nodes and edges to avoid duplicates\n",
    "    unique_nodes = set()\n",
    "    unique_edges = set()\n",
    "    \n",
    "    # Extract node metadata (type from ID prefix)\n",
    "    node_metadata = {}\n",
    "    \n",
    "    # Process each path in the results\n",
    "    for result in cypher_results:\n",
    "        path = result.get('path', [])\n",
    "        \n",
    "        # Paths alternate between nodes and relationships\n",
    "        for i in range(0, len(path), 2):\n",
    "            # Add node\n",
    "            if i < len(path):\n",
    "                node = path[i]\n",
    "                node_id = node.get('id')\n",
    "                if node_id and node_id not in unique_nodes:\n",
    "                    unique_nodes.add(node_id)\n",
    "                    # Extract node type from ID (assuming format like \"Type.Name\")\n",
    "                    node_parts = node_id.split('.')\n",
    "                    node_type = node_parts[0] if len(node_parts) > 0 else \"Unknown\"\n",
    "                    \n",
    "                    # Store node metadata\n",
    "                    node_metadata[node_id] = {\n",
    "                        \"id\": node_id,\n",
    "                        \"type\": node_type,\n",
    "                        \"properties\": {}\n",
    "                    }\n",
    "                    \n",
    "                    # Add node to NetworkX graph\n",
    "                    G.add_node(node_id)\n",
    "            \n",
    "            # Add relationship/edge\n",
    "            if i + 1 < len(path) and i + 2 < len(path):\n",
    "                source_id = path[i].get('id')\n",
    "                relationship = path[i + 1]  # This is a string like \"USES\"\n",
    "                target_id = path[i + 2].get('id')\n",
    "                \n",
    "                if source_id and target_id:\n",
    "                    edge_key = (source_id, target_id, relationship)\n",
    "                    if edge_key not in unique_edges:\n",
    "                        unique_edges.add(edge_key)\n",
    "                        # Add edge to NetworkX graph\n",
    "                        G.add_edge(source_id, target_id, label=relationship)\n",
    "    \n",
    "    # Get unique types for coloring\n",
    "    unique_types = list(set(meta[\"type\"] for meta in node_metadata.values()))\n",
    "    color_map = plt.get_cmap(\"tab10\")\n",
    "    type_colors = {t: color_map(i / len(unique_types)) for i, t in enumerate(unique_types)}\n",
    "    type_colors_rgba = {\n",
    "        t: f'rgba({int(c[0]*255)}, {int(c[1]*255)}, {int(c[2]*255)}, 0.8)' \n",
    "        for t, c in type_colors.items()\n",
    "    }\n",
    "    \n",
    "    # Degree-based sizing\n",
    "    degrees = dict(G.degree())\n",
    "    min_size, max_size = 15, 50\n",
    "    max_degree = max(degrees.values()) if degrees else 1\n",
    "    size_scale = {\n",
    "        node: min_size + (max_size - min_size) * (deg / max_degree)\n",
    "        for node, deg in degrees.items()\n",
    "    }\n",
    "    \n",
    "    # Add nodes to Pyvis with proper styling\n",
    "    for node_id in G.nodes():\n",
    "        metadata = node_metadata.get(node_id, {})\n",
    "        node_type = metadata.get(\"type\", \"Unknown\")\n",
    "        color = type_colors_rgba.get(node_type, \"gray\")\n",
    "        \n",
    "        # Show full node ID as the label\n",
    "        # Add node to Pyvis network\n",
    "        net.add_node(\n",
    "            node_id,\n",
    "            label=node_id,  # Using full node_id as the label\n",
    "            size=size_scale[node_id],\n",
    "            color=color,\n",
    "            title=f\"<b>{node_type}</b><br>{node_id}\"\n",
    "        )\n",
    "    \n",
    "    # Get all unique relationship types\n",
    "    relationship_types = list(set(attr.get(\"label\", \"\") for _, _, attr in G.edges(data=True)))\n",
    "    \n",
    "    # Create colors for each relationship type\n",
    "    rel_color_map = plt.get_cmap(\"Set2\")  # Using a different colormap for relationships\n",
    "    rel_colors = {\n",
    "        rel_type: f'rgba({int(rel_color_map(i / len(relationship_types))[0]*255)}, {int(rel_color_map(i / len(relationship_types))[1]*255)}, {int(rel_color_map(i / len(relationship_types))[2]*255)}, 0.9)'\n",
    "        for i, rel_type in enumerate(relationship_types)\n",
    "    }\n",
    "    \n",
    "    # Add edges to Pyvis with longer length and different colors\n",
    "    for source, target, attr in G.edges(data=True):\n",
    "        rel_label = attr.get(\"label\", \"\")\n",
    "        edge_color = rel_colors.get(rel_label, \"#888888\")  # Default gray if not found\n",
    "        # Adding longer length to edges (300 instead of default)\n",
    "        net.add_edge(source, target, title=rel_label, label=rel_label, arrows='to', length=300, color=edge_color)\n",
    "    \n",
    "    # Save graph\n",
    "    net.save_graph(output_file)\n",
    "    \n",
    "    # Build legend\n",
    "    legend_html = \"\"\"\n",
    "    <div id=\"legend\" style=\"position: absolute; top: 10px; left: 10px; background: white; padding: 10px; border-radius: 8px; box-shadow: 0px 0px 5px rgba(0,0,0,0.2); font-family: Arial, sans-serif; z-index: 1000;\">\n",
    "        <h4 style=\"margin: 0; padding-bottom: 5px;\">Node Legend</h4>\n",
    "    \"\"\"\n",
    "    \n",
    "    for node_type, color in type_colors_rgba.items():\n",
    "        legend_html += f'<div style=\"display: flex; align-items: center; margin-bottom: 5px;\"><div style=\"width: 15px; height: 15px; background:{color}; margin-right: 5px; border-radius: 50%;\"></div> {node_type}</div>'\n",
    "    \n",
    "    legend_html += \"\"\"\n",
    "        <h4 style=\"margin: 5px 0; padding-bottom: 5px;\">Relationship Legend</h4>\n",
    "    \"\"\"\n",
    "    \n",
    "    for rel_type in sorted(relationship_types):\n",
    "        rel_color = rel_colors.get(rel_type, \"#888888\")\n",
    "        legend_html += f'<div style=\"display: flex; align-items: center; margin-bottom: 5px;\"><div style=\"width: 20px; height: 3px; background: {rel_color}; margin-right: 5px;\"></div> {rel_type}</div>'\n",
    "    \n",
    "    legend_html += \"</div>\"\n",
    "    \n",
    "    # Inject legend into the HTML\n",
    "    with open(output_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    html_content = html_content.replace(\"</body>\", legend_html + \"</body>\")\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "    \n",
    "    print(f\"Graph visualization saved as {output_file}\")\n",
    "    \n",
    "    # Return graph stats\n",
    "    return {\n",
    "        \"nodes\": len(G.nodes()),\n",
    "        \"edges\": len(G.edges()),\n",
    "        \"node_types\": unique_types,\n",
    "        \"relationship_types\": list(set(attr.get(\"label\", \"\") for _, _, attr in G.edges(data=True)))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph visualization saved as code_relationships_graph.html\n"
     ]
    }
   ],
   "source": [
    "stats = visualize_cypher_results(results['cypher_results'], \"code_relationships_graph.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': 8,\n",
       " 'edges': 12,\n",
       " 'node_types': ['Utils', 'Deduplication'],\n",
       " 'relationship_types': ['CONTAINS',\n",
       "  'USES',\n",
       "  'DEFINES',\n",
       "  'IMPORTS',\n",
       "  'INHERITS',\n",
       "  'INITIALIZES']}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
