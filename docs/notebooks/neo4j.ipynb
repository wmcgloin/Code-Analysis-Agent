{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graph-RAG with Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to Natural Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── src/\n",
      "│   ├── deduplication/\n",
      "│   │   ├── bloom_filter.py\n",
      "│   │   ├── dedup.py\n",
      "│   │   ├── LSH.py\n",
      "│   │   ├── LSHForest.py\n",
      "│   │   ├── LSHImproved.py\n",
      "│   │   ├── __init__.py\n",
      "│   │   ├── __main__.py\n",
      "│   ├── utils/\n",
      "│   │   ├── use_cases.py\n",
      "│   │   ├── utils.py\n",
      "│   │   ├── visualizations.py\n",
      "│   │   ├── visualization_lsh.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def generate_repo_tree(repo_path, indent=\"\"):\n",
    "    tree_string = \"\"\n",
    "    for root, dirs, files in os.walk(repo_path):\n",
    "        # Filter out __pycache__ and hidden directories\n",
    "        dirs[:] = [d for d in dirs if d != \"__pycache__\" and not d.startswith(\".\")]\n",
    "        files = [f for f in files if not f.startswith(\".\")]\n",
    "\n",
    "        level = root.replace(repo_path, \"\").count(os.sep)\n",
    "        indent = \"│   \" * level + \"├── \"  # Formatting the tree\n",
    "        tree_string += f\"{indent}{os.path.basename(root)}/\\n\"\n",
    "\n",
    "        sub_indent = \"│   \" * (level + 1) + \"├── \"\n",
    "        for file in files:\n",
    "            tree_string += f\"{sub_indent}{file}\\n\"\n",
    "\n",
    "    return tree_string\n",
    "\n",
    "# Set your repo path\n",
    "repo_path = \"./assignment-2-mcdonald-s/src\"  # Change this to your cloned repo path\n",
    "\n",
    "# Generate tree and store as string\n",
    "repo_tree_string = generate_repo_tree(repo_path)\n",
    "\n",
    "# Print the repo tree\n",
    "print(repo_tree_string)\n",
    "\n",
    "# Store it as a variable to feed into an LLM\n",
    "# llm_input = f\"Here is the repository structure:\\n{repo_tree_string}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deduplication\\bloom_filter.py\n",
      "deduplication\\dedup.py\n",
      "deduplication\\LSH.py\n",
      "deduplication\\LSHForest.py\n",
      "deduplication\\LSHImproved.py\n",
      "deduplication\\__init__.py\n",
      "deduplication\\__main__.py\n",
      "utils\\use_cases.py\n",
      "utils\\utils.py\n",
      "utils\\visualizations.py\n",
      "utils\\visualization_lsh.py\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "    You are an expert in analyzing Python code and generating structured natural language descriptions for graph-based querying in Cypher. \n",
    "    Given a Python codebase, extract meaningful relationships between functions, classes, and imported modules. \n",
    "    \n",
    "    Only use the list of types provided below:\n",
    "    - class : classes defined in a module\n",
    "    - method : methods defined in a class\n",
    "    - function : functions defined in a module\n",
    "    - module : python scripts defined within the repository. Exclude .py when mentioning the module name.\n",
    "    - package : packages imported that are not modules.\n",
    "    Do not include information on variables, parameters, arguments.\n",
    "    Python scripts must be modules and pre defined packages such as numpy and pandas must be packages\n",
    "\n",
    "    When generating the structured natural language description, follow these rules:    \n",
    "    - Do not give explanations for the code logic or functionality.\n",
    "    - Do not use adjectives and adverbs. \n",
    "    - Only describe the code and do not give an overall summary.\n",
    "    - Do not use ambiguous pronouns and use exact names in every description.\n",
    "    - Explain each class, function separately and do not include explanations such as 'as mentioned before' or anything that refers to a previous explanation.\n",
    "    - make each description sufficient for a standalone statement for one relationship in the graph.    \n",
    "    - Each class and funciton should be connected to the module where it was defined.\n",
    "    - Each imported package should be connected to the function, method or class where it was used.\n",
    "    - Always include an explanation on how the outermost class or method is connected to the module where it is defined.\n",
    "    - If the outermost layer is an 'if __name__ == \"__main__\":' block, then the outermost layer is whatever is inside the block. Plus whatever is defined outside the block. Make sure to mention the connection between the module and the closses and functions.\n",
    "    - When mentioning modules, take note of the current file path(relative repository) given in input, and change slashes to dots and remove the .py extension.\n",
    "    - If a function or class is used in another function or class, make sure to mention the connection between them.\n",
    "    - \n",
    "            \n",
    "    Natural language should follow a similar format as below:\n",
    "        {source.id} is a {source.type} with properties {source.properties} defined in {target.id} which is a {target.type}.        \n",
    "    Example: \n",
    "    - When mentioning classes, always refer them as {relative_repository}.{module_name}.{class_name}\n",
    "    - When mentioning methods, always refer to them as {relative_repository}.{module_name}.{class_name}.{method_name}\n",
    "    - When mentioning functions, always refer them as {relative_repository}.{module_name}.{function_name}\n",
    "    - If the file path is deduplication/LSH.py and there is a class LSH in it, the module is deduplication.LSH and the class is deduplication.LSH.LSH.\n",
    "\n",
    "    Example:\n",
    "    deduplication.LSHImproved.LSHImproved is a module that defines the class deduplication.LSH.lsh_base, which consists of  method deduplication.LSH.lsh_base.hash_function.\n",
    "    deduplication.LSH.lsh_base is a class and inherits from the class utils.utils.BaseLSH.\n",
    "    numpy is a package and is used in the method deduplication.LSH.lsh_base.hash_function.\n",
    "    bitarray is a package and is used in the deduplication.bloom_filter.BloomFilter_KM_Opt.__init__ method of the class deduplication.bloom_filter.BloomFilter_KM_Opt.  \n",
    "    deduplication.LSH.lsh_base is a class defined in the module deduplication.LSH.\n",
    "    \n",
    "    If a module from our repository is imported in another module in our repository, refer to it as the entire path of the module.\n",
    "    Example:\n",
    "    code within deduplication\\\\__main__.py : from deduplication.LSHImproved import LSHImproved\n",
    "    Natural Language Description:\n",
    "    The Class deduplication.LSHImproved.LSHImproved is imported into the module deduplication.__main__.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "i = 0\n",
    "descriptions = {}\n",
    "\n",
    "for root, dirs, files in os.walk(repo_path):\n",
    "    \n",
    "    # Skip hidden directories (e.g., .git, .idea, __pycache__)\n",
    "    dirs[:] = [d for d in dirs if not d.startswith(\".\") and d != \"__pycache__\"]\n",
    "\n",
    "    for file in files:\n",
    "        if file.startswith(\".\"):\n",
    "            continue  # Skip hidden files\n",
    "\n",
    "        file_path = os.path.join(root, file)\n",
    "        relative_path = os.path.relpath(file_path, repo_path)\n",
    "        print(relative_path)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                lsh_code = f.read()\n",
    "\n",
    "            messages = [\n",
    "                SystemMessage(system_prompt),\n",
    "                HumanMessage(f'''\n",
    "                    Tree:\n",
    "                    {repo_tree_string}\n",
    "\n",
    "                    Current File Path:\n",
    "                    {relative_path}\n",
    "\n",
    "                    Code:\n",
    "                    {lsh_code}\n",
    "                ''')\n",
    "            ]\n",
    "\n",
    "            response = llm.invoke(messages)\n",
    "            descriptions[relative_path] = response.content\n",
    "            i += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "        \n",
    "        # if i > 1:\n",
    "        #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deduplication\\bloom_filter.py\n",
      "deduplication.bloom_filter.BloomFilter is a class defined in the module deduplication.bloom_filter. \n",
      "deduplication.bloom_filter.BloomFilter.__init__ is a method defined in the class deduplication.bloom_filter.BloomFilter. \n",
      "math is a package and is used in the method deduplication.bloom_filter.BloomFilter.__init__. \n",
      "bitarray is a package and is used in the method deduplication.bloom_filter.BloomFilter.__init__.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter.add.\n",
      "ngrams is a package and is used in the method deduplication.bloom_filter.BloomFilter.add.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter.query.\n",
      "ngrams is a package and is used in the method deduplication.bloom_filter.BloomFilter.query.\n",
      "\n",
      "deduplication.bloom_filter.BloomFilter_KM_Opt is a class defined in the module deduplication.bloom_filter. \n",
      "deduplication.bloom_filter.BloomFilter_KM_Opt.__init__ is a method defined in the class deduplication.bloom_filter.BloomFilter_KM_Opt. \n",
      "math is a package and is used in the method deduplication.bloom_filter.BloomFilter_KM_Opt.__init__.\n",
      "bitarray is a package and is used in the method deduplication.bloom_filter.BloomFilter_KM_Opt.__init__.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_KM_Opt.add.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_KM_Opt.query.\n",
      "\n",
      "deduplication.bloom_filter.BloomFilter_Uni_Hash is a class defined in the module deduplication.bloom_filter. \n",
      "deduplication.bloom_filter.BloomFilter_Uni_Hash.__init__ is a method defined in the class deduplication.bloom_filter.BloomFilter_Uni_Hash. \n",
      "math is a package and is used in the method deduplication.bloom_filter.BloomFilter_Uni_Hash.__init__.\n",
      "bitarray is a package and is used in the method deduplication.bloom_filter.BloomFilter_Uni_Hash.__init__.\n",
      "random is a package and is used in the method deduplication.bloom_filter.BloomFilter_Uni_Hash.__init__.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_Uni_Hash.add.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_Uni_Hash.query.\n",
      "\n",
      "deduplication.bloom_filter.BloomFilter_QF is a class defined in the module deduplication.bloom_filter. \n",
      "deduplication.bloom_filter.BloomFilter_QF.__init__ is a method defined in the class deduplication.bloom_filter.BloomFilter_QF. \n",
      "math is a package and is used in the method deduplication.bloom_filter.BloomFilter_QF.__init__.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_QF._hash.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_QF.add.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_QF.query.\n",
      "-------------------\n",
      "deduplication\\dedup.py\n",
      "deduplication.dedup.Baseline is a class defined in the module deduplication.dedup.  \n",
      "deduplication.dedup.Baseline.__init__ is a method defined in the class deduplication.dedup.Baseline.  \n",
      "deduplication.dedup.Baseline.collection_deduplication is a method defined in the class deduplication.dedup.Baseline.  \n",
      "hashlib is a package and is used in the method deduplication.dedup.Baseline.collection_deduplication.  \n",
      "deduplication.dedup.Baseline.detect_duplicates is a method defined in the class deduplication.dedup.Baseline.  \n",
      "hashlib is a package and is used in the method deduplication.dedup.Baseline.detect_duplicates.  \n",
      "deduplication.dedup.Baseline.length_based_baseline is a method defined in the class deduplication.dedup.Baseline.  \n",
      "deduplication.dedup.Baseline.tokenize is a method defined in the class deduplication.dedup.Baseline.  \n",
      "deduplication.dedup.Baseline.word_count_baseline is a method defined in the class deduplication.dedup.Baseline.  \n",
      "deduplication.dedup.Baseline.tokenize is a method used within the method deduplication.dedup.Baseline.word_count_baseline.  \n",
      "Counter is a package and is used in the method deduplication.dedup.Baseline.tokenize.  \n",
      "Counter is a package and is used in the method deduplication.dedup.Baseline.word_count_baseline.\n",
      "-------------------\n",
      "deduplication\\LSH.py\n",
      "deduplication.LSH.LSH is a class defined in the module deduplication.LSH.  \n",
      "deduplication.LSH.LSH.__init__ is a method defined in the class deduplication.LSH.LSH.  \n",
      "deduplication.LSH.LSH.remove_duplicates is a method defined in the class deduplication.LSH.LSH.  \n",
      "deduplication.LSH.LSH.compute_minhash_signatures is a method defined in the class deduplication.LSH.LSH.  \n",
      "deduplication.LSH.LSH.banding is a method defined in the class deduplication.LSH.LSH.  \n",
      "utils.utils is a package and is used in the method deduplication.LSH.LSH.compute_minhash_signatures.  \n",
      "joblib is a package and is used in the method deduplication.LSH.LSH.compute_minhash_signatures.\n",
      "-------------------\n",
      "deduplication\\LSHForest.py\n",
      "deduplication.LSHForest.LSHForest is a class defined in the module deduplication.LSHForest. \n",
      "deduplication.LSHForest.LSHForest.__init__ is a method defined in the class deduplication.LSHForest.LSHForest.\n",
      "deduplication.LSHForest.LSHForest.banding is a method defined in the class deduplication.LSHForest.LSHForest.\n",
      "deduplication.LSH.LSH is a class and is inherited by the class deduplication.LSHForest.LSHForest.\n",
      "utils.utils.split_dict is a function used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "utils.utils.majority_vote is a function used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "defaultdict is a package and is used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "itertools is a package and is used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "-------------------\n",
      "deduplication\\LSHImproved.py\n",
      "deduplication.LSHImproved.LSHImproved is a class defined in the module deduplication.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.__init__ is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.remove_duplicates is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.compute_minhash_signatures is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.nearby_banding is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.bit_flip is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.gaussian is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.banding is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "numpy is a package and is used in the methods deduplication.LSHImproved.LSHImproved.nearby_banding, deduplication.LSHImproved.LSHImproved.bit_flip, and deduplication.LSHImproved.LSHImproved.gaussian.  \n",
      "utils.utils is a module that defines the functions clean_document, shingle, and minhash, which are used in the methods deduplication.LSHImproved.LSHImproved.compute_minhash_signatures and deduplication.LSHImproved.LSHImproved.__init__.  \n",
      "hashlib is a package that is imported into the module deduplication.LSHImproved.  \n",
      "re is a package that is imported into the module deduplication.LSHImproved.  \n",
      "collections is a package that is imported into the module deduplication.LSHImproved.  \n",
      "itertools is a package that is imported into the module deduplication.LSHImproved.  \n",
      "joblib is a package that is imported into the module deduplication.LSHImproved.  \n",
      "The method deduplication.LSHImproved.LSHImproved.compute_minhash_signatures calls the method deduplication.LSHImproved.LSHImproved.remove_duplicates.  \n",
      "The method deduplication.LSHImproved.LSHImproved.banding uses the methods deduplication.LSHImproved.LSHImproved.nearby_banding, deduplication.LSHImproved.LSHImproved.bit_flip, and deduplication.LSHImproved.LSHImproved.gaussian.  \n",
      "-------------------\n",
      "deduplication\\__init__.py\n",
      "deduplication.__init__ is a module that defines the variable __version__ and uses the package importlib.metadata.\n",
      "-------------------\n",
      "deduplication\\__main__.py\n",
      "deduplication.__main__ is a module that defines the function deduplication.__main__.log_memory_usage.  \n",
      "deduplication.__main__.log_memory_usage is a function that uses the package psutil.  \n",
      "deduplication.__main__ is a module that defines the function deduplication.__main__.model.  \n",
      "deduplication.__main__.model is a function that uses the class deduplication.LSHImproved.LSH to initialize lsh when method is \"LSH_mp\".  \n",
      "deduplication.__main__.model is a function that uses the class deduplication.LSHForest.LSHForest to initialize lsh when method is \"LSH_forest\".  \n",
      "deduplication.__main__.model is a function that uses the class deduplication.LSH.LSH to initialize lsh when method is not \"LSH_mp\" or \"LSH_forest\".  \n",
      "deduplication.__main__.model is a function that uses the class deduplication.LSH.LSH to call the method compute_minhash_signatures.  \n",
      "deduplication.__main__ is a module that defines the function deduplication.__main__.parser.  \n",
      "deduplication.__main__.parser is a function that defines various command-line arguments for processing input files.\n",
      "deduplication.__main__ is a module that defines the method deduplication.__main__.__main__.  \n",
      "deduplication.__main__.__main__ is a block that initializes the argument parser and calls deduplication.__main__.log_memory_usage.\n",
      "deduplication.__main__.__main__ is a block that defines the default parameter values for method.\n",
      "deduplication.__main__.parser is a function that uses the package argparse.  \n",
      "deduplication.__main__.__main__ is a block that reads input file from args.indir and uses the function utils.utils.read_tsv.\n",
      "deduplication.__main__.__main__ is a block that processes the deduplication or nearest neighbor search based on args.case.\n",
      "deduplication.__main__.__main__ is a block that initializes lsh using deduplication.dedup.Baseline when method is 'baseline'.  \n",
      "deduplication.__main__.__main__ is a block that initializes lsh using deduplication.__main__.model when method is not 'baseline'.  \n",
      "deduplication.__main__.__main__ is a block that calls the function utils.use_cases.collection_deduplication when method is not 'baseline'.  \n",
      "deduplication.__main__ is a module that uses the package logging.\n",
      "deduplication.__main__ is a module that imports the class deduplication.dedup.Baseline which is used for initialization when method is 'baseline'.  \n",
      "deduplication.__main__ is a module that imports the function utils.use_cases.nearest_neighbor_search, which is called in the case of 'ann'.  \n",
      "deduplication.__main__ is a module that imports the class deduplication.LSHImproved.LSH for use in the case of 'LSH_mp'.  \n",
      "deduplication.__main__ is a module that imports the class deduplication.LSHForest.LSHForest for use in the case of 'LSH_forest'.  \n",
      "deduplication.__main__ is a module that defines the function deduplication.__main__.parser which sets up argument parsing.\n",
      "-------------------\n",
      "utils\\use_cases.py\n",
      "utils.use_cases.collection_deduplication is a function defined in the module utils.use_cases.  \n",
      "utils.utils.UnionFind is a package used in the function utils.use_cases.collection_deduplication.  \n",
      "utils.utils.clean_document is a package used in the function utils.use_cases.nearest_neighbor_search.  \n",
      "utils.utils.shingle is a package used in the function utils.use_cases.nearest_neighbor_search.  \n",
      "utils.utils.minhash is a package used in the function utils.use_cases.nearest_neighbor_search.  \n",
      "utils.use_cases.nearest_neighbor_search is a function defined in the module utils.use_cases.  \n",
      "-------------------\n",
      "utils\\utils.py\n",
      "src.utils.utils.clean_document is a function defined in the module src.utils.utils that cleans and normalizes the input text.\n",
      "\n",
      "src.utils.utils.shingle is a function defined in the module src.utils.utils that generates k-shingles from the input text.\n",
      "\n",
      "src.utils.utils.minhash is a function defined in the module src.utils.utils that generates a MinHash signature for a given set of shingles.\n",
      "\n",
      "xxhash is a package and is used in the function src.utils.utils.minhash.\n",
      "\n",
      "src.utils.utils.UnionFind is a class defined in the module src.utils.utils that implements a Union-Find data structure for efficient merging and finding of sets.\n",
      "\n",
      "src.utils.utils.UnionFind.__init__ is a method defined in the class src.utils.utils.UnionFind that initializes an empty Union-Find structure.\n",
      "\n",
      "src.utils.utils.UnionFind.find is a method defined in the class src.utils.utils.UnionFind that finds the root of the set containing the element.\n",
      "\n",
      "src.utils.utils.UnionFind.union is a method defined in the class src.utils.utils.UnionFind that merges the sets containing two elements.\n",
      "\n",
      "src.utils.utils.read_tsv is a function defined in the module src.utils.utils that reads a TSV file and returns a dictionary of its contents.\n",
      "\n",
      "src.utils.utils.split_dict is a function defined in the module src.utils.utils that splits a dictionary into a specified number of smaller dictionaries.\n",
      "\n",
      "src.utils.utils.majority_vote is a function defined in the module src.utils.utils that performs a majority vote on a list of sets of candidate pairs.\n",
      "\n",
      "src.utils.utils.split_dict uses the module src.utils.utils.\n",
      "\n",
      "src.utils.utils.majority_vote uses the module src.utils.utils.\n",
      "-------------------\n",
      "utils\\visualizations.py\n",
      "utils.visualizations.BloomFilter is a class defined in the module utils.visualizations.  \n",
      "utils.visualizations.BloomFilter.__init__ is a method defined in the class utils.visualizations.BloomFilter.  \n",
      "mmh3 is a package and is used in the method utils.visualizations.BloomFilter.add.  \n",
      "bitarray is a package and is used in the method utils.visualizations.BloomFilter.__init__.  \n",
      "math is a package and is used in the methods utils.visualizations.BloomFilter.__init__ and utils.visualizations.calculate_false_positive_rate.  \n",
      "utils.visualizations.BloomFilter.add is a method defined in the class utils.visualizations.BloomFilter.  \n",
      "mmh3 is a package and is used in the method utils.visualizations.BloomFilter.query.  \n",
      "utils.visualizations.BloomFilter.query is a method defined in the class utils.visualizations.BloomFilter.  \n",
      "random is a package and is used in the functions utils.visualizations.calculate_false_positive_rate and utils.visualizations.plot_false_positive_rate_vs_hash_functions.  \n",
      "utils.visualizations.calculate_false_positive_rate is a function defined in the module utils.visualizations.  \n",
      "utils.visualizations.BloomFilter is used in the function utils.visualizations.calculate_false_positive_rate.  \n",
      "utils.visualizations.plot_false_positive_rate_vs_hash_functions is a function defined in the module utils.visualizations.  \n",
      "matplotlib.pyplot is a package and is used in the function utils.visualizations.plot_false_positive_rate_vs_hash_functions.  \n",
      "numpy is a package and is used in the function utils.visualizations.plot_false_positive_rate_vs_hash_functions.  \n",
      "utils.visualizations.calculate_false_positive_rate is used in the function utils.visualizations.plot_false_positive_rate_vs_hash_functions.  \n",
      "plotly.graph_objects is a package and is imported but not used in the module utils.visualizations.  \n",
      "plotly.io is a package and is imported but not used in the module utils.visualizations.  \n",
      "The function utils.visualizations.plot_false_positive_rate_vs_hash_functions is called in the block if __name__ == \"__main__\": in the module utils.visualizations.\n",
      "\n",
      "-------------------\n",
      "utils\\visualization_lsh.py\n",
      "utils.visualization_lsh.plot_s_curves is a function defined in the module utils.visualization_lsh.  \n",
      "numpy is a package and is used in the function utils.visualization_lsh.plot_s_curves.  \n",
      "matplotlib is a package and is used in the function utils.visualization_lsh.plot_s_curves.\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for i in descriptions:\n",
    "    print(i)\n",
    "    print(descriptions[i])\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are an expert text editor. Your goal is to modyfy the text in a way that it is consistent with the given repository tree and file path.\n",
    "    Keep in mind this natural language is meant to be used for graph-based querying in Cypher.\n",
    "    Only output the modified text, do not give any explanations or anything else.\n",
    "    The only change you have to make is to modify potential node ids, so they are consistent and can be connected by a graph.\n",
    "    \n",
    "    Rules:\n",
    "    - When mentioning modules, take note of the current file path(relative repository) given in input, and change slashes to dots and remove the .py extension.\n",
    "    - This means that the current file path or module name should be the beginning of all classes/methods/functions defined in the module.    \n",
    "    - When mentioning classes, always refer them as {module_location_name}.{class_name}\n",
    "    - When mentioning methods, always refer to them as {module_location_name}.{class_name}.{method_name}\n",
    "    - When mentioning functions, always refer them as {module_location_name}.{function_name}\n",
    "\n",
    "    Example: \n",
    "    - if the relative path is deduplication/LSH.py and there is a class LSH in it, the module is deduplication.LSH and the class is deduplication.LSH.LSH.\n",
    "    - Given the current file path deduplication\\\\dedup.py\n",
    "        'deduplication.Baseline is a class defined in deduplication.dedup' is extremely incorrect. \n",
    "        The correct description is 'deduplication.dedup.Baseline is a class defined in deduplication.dedup'\n",
    "    \n",
    "    \n",
    "    Example:\n",
    "    - If the file location is deduplication/LSH.py and there is a class LSH in it, the module should be deduplication.LSH and the class should be deduplication.LSH.LSH. in the natural language description.\n",
    "    - If the original text is bloom_filter.BloomFilter is a class, and the current file is deduplication\\\\bloom_filter.py, the modified text should be deduplication.bloom_filter.BloomFilter is a class.\n",
    "    - If my current module imports a function from a module 'utils.utils import clean_document' the modified text should be utils.utils.clean_document is a function.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "refined_descriptions = {}\n",
    "for i in descriptions:\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(system_prompt),\n",
    "        HumanMessage(f'''\n",
    "                     \n",
    "            Repository Tree:\n",
    "            {repo_tree_string}\n",
    "\n",
    "            Current File Path:\n",
    "            {i}\n",
    "\n",
    "            Natural Language Desccription:\n",
    "            {descriptions[i]}\n",
    "        ''')\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    refined_descriptions[i] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deduplication\\bloom_filter.py\n",
      "deduplication.bloom_filter.BloomFilter is a class defined in the module deduplication.bloom_filter. \n",
      "deduplication.bloom_filter.BloomFilter.__init__ is a method defined in the class deduplication.bloom_filter.BloomFilter. \n",
      "math is a package and is used in the method deduplication.bloom_filter.BloomFilter.__init__. \n",
      "bitarray is a package and is used in the method deduplication.bloom_filter.BloomFilter.__init__.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter.add.\n",
      "ngrams is a package and is used in the method deduplication.bloom_filter.BloomFilter.add.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter.query.\n",
      "ngrams is a package and is used in the method deduplication.bloom_filter.BloomFilter.query.\n",
      "\n",
      "deduplication.bloom_filter.BloomFilter_KM_Opt is a class defined in the module deduplication.bloom_filter. \n",
      "deduplication.bloom_filter.BloomFilter_KM_Opt.__init__ is a method defined in the class deduplication.bloom_filter.BloomFilter_KM_Opt. \n",
      "math is a package and is used in the method deduplication.bloom_filter.BloomFilter_KM_Opt.__init__.\n",
      "bitarray is a package and is used in the method deduplication.bloom_filter.BloomFilter_KM_Opt.__init__.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_KM_Opt.add.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_KM_Opt.query.\n",
      "\n",
      "deduplication.bloom_filter.BloomFilter_Uni_Hash is a class defined in the module deduplication.bloom_filter. \n",
      "deduplication.bloom_filter.BloomFilter_Uni_Hash.__init__ is a method defined in the class deduplication.bloom_filter.BloomFilter_Uni_Hash. \n",
      "math is a package and is used in the method deduplication.bloom_filter.BloomFilter_Uni_Hash.__init__.\n",
      "bitarray is a package and is used in the method deduplication.bloom_filter.BloomFilter_Uni_Hash.__init__.\n",
      "random is a package and is used in the method deduplication.bloom_filter.BloomFilter_Uni_Hash.__init__.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_Uni_Hash.add.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_Uni_Hash.query.\n",
      "\n",
      "deduplication.bloom_filter.BloomFilter_QF is a class defined in the module deduplication.bloom_filter. \n",
      "deduplication.bloom_filter.BloomFilter_QF.__init__ is a method defined in the class deduplication.bloom_filter.BloomFilter_QF. \n",
      "math is a package and is used in the method deduplication.bloom_filter.BloomFilter_QF.__init__.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_QF._hash.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_QF.add.\n",
      "mmh3 is a package and is used in the method deduplication.bloom_filter.BloomFilter_QF.query.\n",
      "-------------------\n",
      "deduplication\\dedup.py\n",
      "deduplication.dedup.Baseline is a class defined in the module deduplication.dedup.  \n",
      "deduplication.dedup.Baseline.__init__ is a method defined in the class deduplication.dedup.Baseline.  \n",
      "deduplication.dedup.Baseline.collection_deduplication is a method defined in the class deduplication.dedup.Baseline.  \n",
      "hashlib is a package and is used in the method deduplication.dedup.Baseline.collection_deduplication.  \n",
      "deduplication.dedup.Baseline.detect_duplicates is a method defined in the class deduplication.dedup.Baseline.  \n",
      "hashlib is a package and is used in the method deduplication.dedup.Baseline.detect_duplicates.  \n",
      "deduplication.dedup.Baseline.length_based_baseline is a method defined in the class deduplication.dedup.Baseline.  \n",
      "deduplication.dedup.Baseline.tokenize is a method defined in the class deduplication.dedup.Baseline.  \n",
      "deduplication.dedup.Baseline.word_count_baseline is a method defined in the class deduplication.dedup.Baseline.  \n",
      "deduplication.dedup.Baseline.tokenize is a method used within the method deduplication.dedup.Baseline.word_count_baseline.  \n",
      "Counter is a package and is used in the method deduplication.dedup.Baseline.tokenize.  \n",
      "Counter is a package and is used in the method deduplication.dedup.Baseline.word_count_baseline.\n",
      "-------------------\n",
      "deduplication\\LSH.py\n",
      "deduplication.LSH.LSH is a class defined in the module deduplication.LSH.  \n",
      "deduplication.LSH.LSH.__init__ is a method defined in the class deduplication.LSH.LSH.  \n",
      "deduplication.LSH.LSH.remove_duplicates is a method defined in the class deduplication.LSH.LSH.  \n",
      "deduplication.LSH.LSH.compute_minhash_signatures is a method defined in the class deduplication.LSH.LSH.  \n",
      "deduplication.LSH.LSH.banding is a method defined in the class deduplication.LSH.LSH.  \n",
      "utils.utils is a module and is used in the method deduplication.LSH.LSH.compute_minhash_signatures.  \n",
      "joblib is a library and is used in the method deduplication.LSH.LSH.compute_minhash_signatures.\n",
      "-------------------\n",
      "deduplication\\LSHForest.py\n",
      "deduplication.LSHForest.LSHForest is a class defined in the module deduplication.LSHForest. \n",
      "deduplication.LSHForest.LSHForest.__init__ is a method defined in the class deduplication.LSHForest.LSHForest.\n",
      "deduplication.LSHForest.LSHForest.banding is a method defined in the class deduplication.LSHForest.LSHForest.\n",
      "deduplication.LSH.LSH is a class and is inherited by the class deduplication.LSHForest.LSHForest.\n",
      "utils.utils.split_dict is a function used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "utils.utils.majority_vote is a function used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "collections.defaultdict is a package and is used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "itertools is a package and is used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "-------------------\n",
      "deduplication\\LSHImproved.py\n",
      "deduplication.LSHImproved.LSHImproved is a class defined in the module deduplication.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.__init__ is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.remove_duplicates is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.compute_minhash_signatures is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.nearby_banding is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.bit_flip is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.gaussian is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "deduplication.LSHImproved.LSHImproved.banding is a method defined in the class deduplication.LSHImproved.LSHImproved.  \n",
      "numpy is a package and is used in the methods deduplication.LSHImproved.LSHImproved.nearby_banding, deduplication.LSHImproved.LSHImproved.bit_flip, and deduplication.LSHImproved.LSHImproved.gaussian.  \n",
      "utils.utils.clean_document is a function, utils.utils.shingle is a function, and utils.utils.minhash is a function that are used in the methods deduplication.LSHImproved.LSHImproved.compute_minhash_signatures and deduplication.LSHImproved.LSHImproved.__init__.  \n",
      "hashlib is a package that is imported into the module deduplication.LSHImproved.  \n",
      "re is a package that is imported into the module deduplication.LSHImproved.  \n",
      "collections is a package that is imported into the module deduplication.LSHImproved.  \n",
      "itertools is a package that is imported into the module deduplication.LSHImproved.  \n",
      "joblib is a package that is imported into the module deduplication.LSHImproved.  \n",
      "The method deduplication.LSHImproved.LSHImproved.compute_minhash_signatures calls the method deduplication.LSHImproved.LSHImproved.remove_duplicates.  \n",
      "The method deduplication.LSHImproved.LSHImproved.banding uses the methods deduplication.LSHImproved.LSHImproved.nearby_banding, deduplication.LSHImproved.LSHImproved.bit_flip, and deduplication.LSHImproved.LSHImproved.gaussian.  \n",
      "-------------------\n",
      "deduplication\\__init__.py\n",
      "deduplication.__init__ is a module that defines the variable __version__ and uses the package importlib.metadata.\n",
      "-------------------\n",
      "deduplication\\__main__.py\n",
      "deduplication.__main__ is a module that defines the function deduplication.__main__.log_memory_usage.  \n",
      "deduplication.__main__.log_memory_usage is a function that uses the package psutil.  \n",
      "deduplication.__main__ is a module that defines the function deduplication.__main__.model.  \n",
      "deduplication.__main__.model is a function that uses the class deduplication.LSHImproved.LSH to initialize lsh when method is \"LSH_mp\".  \n",
      "deduplication.__main__.model is a function that uses the class deduplication.LSHForest.LSHForest to initialize lsh when method is \"LSH_forest\".  \n",
      "deduplication.__main__.model is a function that uses the class deduplication.LSH.LSH to initialize lsh when method is not \"LSH_mp\" or \"LSH_forest\".  \n",
      "deduplication.__main__.model is a function that uses the class deduplication.LSH.LSH to call the method deduplication.LSH.LSH.compute_minhash_signatures.  \n",
      "deduplication.__main__ is a module that defines the function deduplication.__main__.parser.  \n",
      "deduplication.__main__.parser is a function that defines various command-line arguments for processing input files.  \n",
      "deduplication.__main__ is a module that defines the method deduplication.__main__.__main__.  \n",
      "deduplication.__main__.__main__ is a block that initializes the argument parser and calls deduplication.__main__.log_memory_usage.  \n",
      "deduplication.__main__.__main__ is a block that defines the default parameter values for method.  \n",
      "deduplication.__main__.parser is a function that uses the package argparse.  \n",
      "deduplication.__main__.__main__ is a block that reads input file from args.indir and uses the function utils.utils.read_tsv.  \n",
      "deduplication.__main__.__main__ is a block that processes the deduplication or nearest neighbor search based on args.case.  \n",
      "deduplication.__main__.__main__ is a block that initializes lsh using deduplication.dedup.Baseline when method is 'baseline'.  \n",
      "deduplication.__main__.__main__ is a block that initializes lsh using deduplication.__main__.model when method is not 'baseline'.  \n",
      "deduplication.__main__.__main__ is a block that calls the function utils.use_cases.collection_deduplication when method is not 'baseline'.  \n",
      "deduplication.__main__ is a module that uses the package logging.  \n",
      "deduplication.__main__ is a module that imports the class deduplication.dedup.Baseline which is used for initialization when method is 'baseline'.  \n",
      "deduplication.__main__ is a module that imports the function utils.use_cases.nearest_neighbor_search, which is called in the case of 'ann'.  \n",
      "deduplication.__main__ is a module that imports the class deduplication.LSHImproved.LSH for use in the case of 'LSH_mp'.  \n",
      "deduplication.__main__ is a module that imports the class deduplication.LSHForest.LSHForest for use in the case of 'LSH_forest'.  \n",
      "deduplication.__main__ is a module that defines the function deduplication.__main__.parser which sets up argument parsing.\n",
      "-------------------\n",
      "utils\\use_cases.py\n",
      "utils.use_cases.collection_deduplication is a function defined in the module utils.use_cases.  \n",
      "utils.utils.UnionFind is a class used in the function utils.use_cases.collection_deduplication.  \n",
      "utils.utils.clean_document is a function used in the function utils.use_cases.nearest_neighbor_search.  \n",
      "utils.utils.shingle is a function used in the function utils.use_cases.nearest_neighbor_search.  \n",
      "utils.utils.minhash is a function used in the function utils.use_cases.nearest_neighbor_search.  \n",
      "utils.use_cases.nearest_neighbor_search is a function defined in the module utils.use_cases.  \n",
      "-------------------\n",
      "utils\\utils.py\n",
      "src.utils.utils.clean_document is a function defined in the module src.utils.utils that cleans and normalizes the input text.\n",
      "\n",
      "src.utils.utils.shingle is a function defined in the module src.utils.utils that generates k-shingles from the input text.\n",
      "\n",
      "src.utils.utils.minhash is a function defined in the module src.utils.utils that generates a MinHash signature for a given set of shingles.\n",
      "\n",
      "xxhash is a package and is used in the function src.utils.utils.minhash.\n",
      "\n",
      "src.utils.utils.UnionFind is a class defined in the module src.utils.utils that implements a Union-Find data structure for efficient merging and finding of sets.\n",
      "\n",
      "src.utils.utils.UnionFind.__init__ is a method defined in the class src.utils.utils.UnionFind that initializes an empty Union-Find structure.\n",
      "\n",
      "src.utils.utils.UnionFind.find is a method defined in the class src.utils.utils.UnionFind that finds the root of the set containing the element.\n",
      "\n",
      "src.utils.utils.UnionFind.union is a method defined in the class src.utils.utils.UnionFind that merges the sets containing two elements.\n",
      "\n",
      "src.utils.utils.read_tsv is a function defined in the module src.utils.utils that reads a TSV file and returns a dictionary of its contents.\n",
      "\n",
      "src.utils.utils.split_dict is a function defined in the module src.utils.utils that splits a dictionary into a specified number of smaller dictionaries.\n",
      "\n",
      "src.utils.utils.majority_vote is a function defined in the module src.utils.utils that performs a majority vote on a list of sets of candidate pairs.\n",
      "\n",
      "src.utils.utils.split_dict uses the module src.utils.utils.\n",
      "\n",
      "src.utils.utils.majority_vote uses the module src.utils.utils.\n",
      "-------------------\n",
      "utils\\visualizations.py\n",
      "utils.visualizations.BloomFilter is a class defined in the module utils.visualizations.  \n",
      "utils.visualizations.BloomFilter.__init__ is a method defined in the class utils.visualizations.BloomFilter.  \n",
      "mmh3 is a package and is used in the method utils.visualizations.BloomFilter.add.  \n",
      "bitarray is a package and is used in the method utils.visualizations.BloomFilter.__init__.  \n",
      "math is a package and is used in the methods utils.visualizations.BloomFilter.__init__ and utils.visualizations.calculate_false_positive_rate.  \n",
      "utils.visualizations.BloomFilter.add is a method defined in the class utils.visualizations.BloomFilter.  \n",
      "mmh3 is a package and is used in the method utils.visualizations.BloomFilter.query.  \n",
      "utils.visualizations.BloomFilter.query is a method defined in the class utils.visualizations.BloomFilter.  \n",
      "random is a package and is used in the functions utils.visualizations.calculate_false_positive_rate and utils.visualizations.plot_false_positive_rate_vs_hash_functions.  \n",
      "utils.visualizations.calculate_false_positive_rate is a function defined in the module utils.visualizations.  \n",
      "utils.visualizations.BloomFilter is used in the function utils.visualizations.calculate_false_positive_rate.  \n",
      "utils.visualizations.plot_false_positive_rate_vs_hash_functions is a function defined in the module utils.visualizations.  \n",
      "matplotlib.pyplot is a package and is used in the function utils.visualizations.plot_false_positive_rate_vs_hash_functions.  \n",
      "numpy is a package and is used in the function utils.visualizations.plot_false_positive_rate_vs_hash_functions.  \n",
      "utils.visualizations.calculate_false_positive_rate is used in the function utils.visualizations.plot_false_positive_rate_vs_hash_functions.  \n",
      "plotly.graph_objects is a package and is imported but not used in the module utils.visualizations.  \n",
      "plotly.io is a package and is imported but not used in the module utils.visualizations.  \n",
      "The function utils.visualizations.plot_false_positive_rate_vs_hash_functions is called in the block if __name__ == \"__main__\": in the module utils.visualizations.\n",
      "-------------------\n",
      "utils\\visualization_lsh.py\n",
      "utils.visualization_lsh.plot_s_curves is a function defined in the module utils.visualization_lsh.  \n",
      "numpy is a package and is used in the function utils.visualization_lsh.plot_s_curves.  \n",
      "matplotlib is a package and is used in the function utils.visualization_lsh.plot_s_curves.\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for i in refined_descriptions:\n",
    "    print(i)\n",
    "    print(refined_descriptions[i])\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "description_document = []\n",
    "# for i in descriptions:\n",
    "for i in refined_descriptions:\n",
    "    \n",
    "    document = Document(\n",
    "        # page_content = descriptions[i],\n",
    "        page_content = refined_descriptions[i],\n",
    "        metadata = {\"source\": i}\n",
    "    )\n",
    "    \n",
    "    description_document.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     # Set a really small chunk size, just to show.\n",
    "#     chunk_size=1000,\n",
    "#     # chunk_overlap=100,\n",
    "#     length_function=len,\n",
    "#     is_separator_regex=False,\n",
    "# )\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     separators=[\n",
    "#         r\"\\n\\n\",\n",
    "#         r\"\\n\",\n",
    "#         r\"\\\\n\"\n",
    "#     ],\n",
    "#     is_separator_regex=True,\n",
    "#     keep_separator=False,\n",
    "#     chunk_size=500,\n",
    "#     chunk_overlap=0,\n",
    "# )\n",
    "\n",
    "# docs = text_splitter.create_documents([description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language to GraphDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate, PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "a = \"\"\"# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrificing accuracy. Do not add any information that is not explicitly mentioned in the text.\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'.- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.\\n\"\"\"\n",
    "# Define the prompt template with variables\n",
    "system_prompt = a\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(system_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"\"\"\n",
    "                A period does not mean an end of a sentence. It is part of a node id. Only a line break means an end of a sentence.\n",
    "                Take this into account when identifying node ids.\n",
    "\n",
    "                When translating names into node ids, do not shorten anything. use the entire name as it is.\n",
    "                For example, if the class name is deduplication.LSHForest.LSHForest, do not shorten it to LSHForest or deduplication.LSHForest.\n",
    "                Use the full name deduplication.LSHForest.LSHForest.\n",
    "                Here is the text to analyze:\\n\\n{input}\"\"\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"class\", \"method\", \"function\",'package','module'],\n",
    "    # allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    "    # node_properties=['defined_in'],\n",
    "    # prompt=chat_prompt\n",
    ")\n",
    "\n",
    "\n",
    "# llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "# logger.info(f\"documents:{documents}\")\n",
    "# graph_documents = llm_transformer.convert_to_graph_documents(docs)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(description_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Relationship(source=Node(id='Deduplication.__Main__', type='Module', properties={}), target=Node(id='Deduplication.__Main__.Log_Memory_Usage', type='Function', properties={}), type='DEFINES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.Log_Memory_Usage', type='Function', properties={}), target=Node(id='Psutil', type='Package', properties={}), type='USES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__', type='Module', properties={}), target=Node(id='Deduplication.__Main__.Model', type='Function', properties={}), type='DEFINES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.Model', type='Function', properties={}), target=Node(id='Deduplication.Lshimproved.Lsh', type='Class', properties={}), type='USES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.Model', type='Function', properties={}), target=Node(id='Deduplication.Lshforest.Lshforest', type='Class', properties={}), type='USES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.Model', type='Function', properties={}), target=Node(id='Deduplication.Lsh.Lsh', type='Class', properties={}), type='USES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.Model', type='Function', properties={}), target=Node(id='Deduplication.Lsh.Lsh', type='Class', properties={}), type='CALLS', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__', type='Module', properties={}), target=Node(id='Deduplication.__Main__.Parser', type='Function', properties={}), type='DEFINES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.Parser', type='Function', properties={}), target=Node(id='Argparse', type='Package', properties={}), type='USES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__', type='Module', properties={}), target=Node(id='Deduplication.__Main__.__Main__', type='Method', properties={}), type='DEFINES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.__Main__', type='Method', properties={}), target=Node(id='Deduplication.__Main__.Log_Memory_Usage', type='Function', properties={}), type='CALLS', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.__Main__', type='Method', properties={}), target=Node(id='Args.Indir', type='Class', properties={}), type='READS', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.__Main__', type='Method', properties={}), target=Node(id='Args.Case', type='Class', properties={}), type='PROCESSES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.__Main__', type='Method', properties={}), target=Node(id='Deduplication.Dedup.Baseline', type='Class', properties={}), type='INITIALIZES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.__Main__', type='Method', properties={}), target=Node(id='Deduplication.__Main__.Model', type='Function', properties={}), type='INITIALIZES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__.__Main__', type='Method', properties={}), target=Node(id='Utils.Use_Cases.Collection_Deduplication', type='Function', properties={}), type='CALLS', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__', type='Module', properties={}), target=Node(id='Logging', type='Package', properties={}), type='USES', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__', type='Module', properties={}), target=Node(id='Deduplication.Dedup.Baseline', type='Class', properties={}), type='IMPORTS', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__', type='Module', properties={}), target=Node(id='Utils.Use_Cases.Nearest_Neighbor_Search', type='Function', properties={}), type='IMPORTS', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__', type='Module', properties={}), target=Node(id='Deduplication.Lshimproved.Lsh', type='Class', properties={}), type='IMPORTS', properties={}),\n",
       " Relationship(source=Node(id='Deduplication.__Main__', type='Module', properties={}), target=Node(id='Deduplication.Lshforest.Lshforest', type='Class', properties={}), type='IMPORTS', properties={})]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[6].relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deduplication.LSHForest.LSHForest is a class defined in the module deduplication.LSHForest. \n",
      "deduplication.LSHForest.LSHForest.__init__ is a method defined in the class deduplication.LSHForest.LSHForest.\n",
      "deduplication.LSHForest.LSHForest.banding is a method defined in the class deduplication.LSHForest.LSHForest.\n",
      "deduplication.LSH.LSH is a class and is inherited by the class deduplication.LSHForest.LSHForest.\n",
      "utils.utils.split_dict is a function used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "utils.utils.majority_vote is a function used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "collections.defaultdict is a package and is used in the method deduplication.LSHForest.LSHForest.banding.\n",
      "itertools is a package and is used in the method deduplication.LSHForest.LSHForest.banding.\n"
     ]
    }
   ],
   "source": [
    "print(refined_descriptions['deduplication\\\\LSHForest.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with fully disambiguated nodes saved as graph_simple.html\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create Pyvis network\n",
    "net = Network(notebook=True, cdn_resources='in_line', height=\"1000px\", width=\"100%\")\n",
    "\n",
    "# Create a NetworkX graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Dictionary to track unique nodes and metadata\n",
    "node_metadata = {}\n",
    "\n",
    "# Helper to create a hashable key from type, id, and properties\n",
    "def make_node_key(node):\n",
    "    return (\n",
    "        node.type,\n",
    "        node.id,\n",
    "        tuple(sorted(node.properties.items()))\n",
    "    )\n",
    "\n",
    "# Add nodes and edges\n",
    "for graph in graph_documents:\n",
    "    for rel in graph.relationships:\n",
    "        if rel.source.type == \"Package\" or rel.target.type == \"Package\":\n",
    "            continue  # Skip packages entirely\n",
    "        # Get full, unique node keys\n",
    "        source_key = make_node_key(rel.source)\n",
    "        target_key = make_node_key(rel.target)\n",
    "        rel_type = rel.type\n",
    "\n",
    "        # Store node metadata\n",
    "        node_metadata[source_key] = {\n",
    "            \"id\": rel.source.id,\n",
    "            \"type\": rel.source.type,\n",
    "            \"properties\": rel.source.properties\n",
    "        }\n",
    "        node_metadata[target_key] = {\n",
    "            \"id\": rel.target.id,\n",
    "            \"type\": rel.target.type,\n",
    "            \"properties\": rel.target.properties\n",
    "        }\n",
    "\n",
    "        # Add nodes and edges\n",
    "        G.add_node(source_key)\n",
    "        G.add_node(target_key)\n",
    "        G.add_edge(source_key, target_key, label=rel_type)\n",
    "\n",
    "# Get unique types for coloring\n",
    "unique_types = list(set(meta[\"type\"] for meta in node_metadata.values()))\n",
    "color_map = plt.get_cmap(\"tab10\")\n",
    "type_colors = {t: color_map(i / len(unique_types)) for i, t in enumerate(unique_types)}\n",
    "type_colors_rgba = {\n",
    "    t: f'rgba({int(c[0]*255)}, {int(c[1]*255)}, {int(c[2]*255)}, 0.8)' for t, c in type_colors.items()\n",
    "}\n",
    "\n",
    "# Degree-based sizing\n",
    "degrees = dict(G.degree())\n",
    "min_size, max_size = 10, 50\n",
    "max_degree = max(degrees.values()) if degrees else 1\n",
    "size_scale = {\n",
    "    node: min_size + (max_size - min_size) * (deg / max_degree)\n",
    "    for node, deg in degrees.items()\n",
    "}\n",
    "\n",
    "# Add nodes to Pyvis\n",
    "for node_key in G.nodes():\n",
    "    metadata = node_metadata[node_key]\n",
    "    label = metadata[\"id\"]\n",
    "    node_type = metadata[\"type\"]\n",
    "    properties = metadata.get(\"properties\", {})\n",
    "    color = type_colors_rgba.get(node_type, \"gray\")\n",
    "\n",
    "    # Property display\n",
    "    props_html = \"<br>\".join(f\"{k}: {v}\" for k, v in properties.items()) if properties else \"No properties\"\n",
    "\n",
    "    net.add_node(\n",
    "        str(node_key),  # string key for Pyvis\n",
    "        label=label,\n",
    "        size=size_scale[node_key],\n",
    "        color=color,\n",
    "        title=f\"<b>{node_type}</b> ({label})<br>{props_html}\"\n",
    "    )\n",
    "\n",
    "# Add edges\n",
    "for source, target, attr in G.edges(data=True):\n",
    "    rel_label = attr.get(\"label\", \"\")\n",
    "    net.add_edge(str(source), str(target), title=rel_label, label=rel_label)\n",
    "\n",
    "# Save graph\n",
    "net.save_graph(\"graph_simple.html\")\n",
    "\n",
    "# Build legend\n",
    "legend_html = \"\"\"\n",
    "<div id=\"legend\" style=\"position: absolute; top: 10px; left: 10px; background: white; padding: 10px; border-radius: 8px; box-shadow: 0px 0px 5px rgba(0,0,0,0.2); font-family: Arial, sans-serif; z-index: 1000;\">\n",
    "    <h4 style=\"margin: 0; padding-bottom: 5px;\">Node Legend</h4>\n",
    "\"\"\"\n",
    "\n",
    "for node_type, color in type_colors_rgba.items():\n",
    "    legend_html += f'<div style=\"display: flex; align-items: center; margin-bottom: 5px;\"><div style=\"width: 15px; height: 15px; background:{color}; margin-right: 5px; border-radius: 50%;\"></div> {node_type}</div>'\n",
    "\n",
    "legend_html += \"</div>\"\n",
    "\n",
    "# Inject legend\n",
    "with open(\"graph_simple.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "html_content = html_content.replace(\"</body>\", legend_html + \"</body>\")\n",
    "\n",
    "with open(\"graph_simple.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(html_content)\n",
    "\n",
    "print(\"Graph with fully disambiguated nodes saved as graph_simple.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# from neo4j import GraphDatabase\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# URI = os.getenv(\"NEO4J_URI\")\n",
    "# USER = os.getenv(\"NEO4J_USERNAME\")\n",
    "# PWD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# print(\"Trying:\", URI)\n",
    "\n",
    "# driver = GraphDatabase.driver(uri=URI, auth=(USER, PWD))\n",
    "\n",
    "# try:\n",
    "#     driver.verify_connectivity()\n",
    "#     print(\"✅ Connected to Aura!\")\n",
    "# except Exception as e:\n",
    "#     print(\"❌ Still not working:\", e)\n",
    "# finally:\n",
    "#     driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create / Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# You can pass the path if the file isn't in the same directory\n",
    "load_dotenv(dotenv_path='../../.env')\n",
    "\n",
    "# Access your variables\n",
    "url = os.getenv('NEO4J_URI')\n",
    "username = os.getenv('NEO4J_USERNAME')\n",
    "password = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "graph = Neo4jGraph(url=url, username=username, password=password)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add graphdocuments do Neo4j Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add documents\n",
    "graph.add_graph_documents(graph_documents)\n",
    "\n",
    "\n",
    "\n",
    "# graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "# graph.query(QUERY, genre=\"action\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Class {id: STRING}\n",
      "Method {id: STRING}\n",
      "Package {id: STRING}\n",
      "Module {id: STRING}\n",
      "Function {id: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Class)-[:INCLUDES]->(:Method)\n",
      "(:Class)-[:USES]->(:Package)\n",
      "(:Class)-[:CONTAINS]->(:Method)\n",
      "(:Class)-[:INHERITS]->(:Class)\n",
      "(:Class)-[:DEFINES]->(:Method)\n",
      "(:Class)-[:IMPORTS]->(:Package)\n",
      "(:Class)-[:METHOD_OF]->(:Method)\n",
      "(:Class)-[:DEFINED_IN]->(:Module)\n",
      "(:Class)-[:DEFINED_IN]->(:Method)\n",
      "(:Method)-[:USES]->(:Package)\n",
      "(:Method)-[:USES]->(:Method)\n",
      "(:Method)-[:USES]->(:Module)\n",
      "(:Method)-[:USES]->(:Function)\n",
      "(:Method)-[:USED_IN]->(:Function)\n",
      "(:Method)-[:USED_IN]->(:Package)\n",
      "(:Method)-[:CALLS]->(:Method)\n",
      "(:Method)-[:CALLS]->(:Function)\n",
      "(:Method)-[:READS]->(:Class)\n",
      "(:Method)-[:PROCESSES]->(:Class)\n",
      "(:Method)-[:INITIALIZES]->(:Class)\n",
      "(:Method)-[:INITIALIZES]->(:Function)\n",
      "(:Method)-[:DEFINED_IN]->(:Class)\n",
      "(:Module)-[:CONTAINS]->(:Class)\n",
      "(:Module)-[:USES]->(:Package)\n",
      "(:Module)-[:DEFINES]->(:Function)\n",
      "(:Module)-[:DEFINES]->(:Method)\n",
      "(:Module)-[:IMPORTS]->(:Class)\n",
      "(:Module)-[:IMPORTS]->(:Function)\n",
      "(:Module)-[:IMPORTS]->(:Package)\n",
      "(:Module)-[:CALLS]->(:Function)\n",
      "(:Function)-[:USES]->(:Package)\n",
      "(:Function)-[:USES]->(:Class)\n",
      "(:Function)-[:USES]->(:Function)\n",
      "(:Function)-[:USES]->(:Module)\n",
      "(:Function)-[:CALLS]->(:Class)\n",
      "(:Function)-[:DEFINED_IN]->(:Module)\n",
      "(:Function)-[:USED_IN]->(:Package)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "- **Class**\n",
      "  - `id`: STRING Example: \"Deduplication.Bloom_Filter.Bloomfilter\"\n",
      "- **Method**\n",
      "  - `id`: STRING Example: \"Deduplication.Bloom_Filter.Bloomfilter.__Init__\"\n",
      "- **Package**\n",
      "  - `id`: STRING Example: \"Math\"\n",
      "- **Module**\n",
      "  - `id`: STRING Available options: ['Deduplication.Lsh', 'Utils.Utils', 'Joblib', 'Deduplication.__Init__', 'Deduplication.__Main__', 'Utils.Use_Cases', 'Src.Utils.Utils', 'Utils.Visualizations', 'Utils.Visualization_Lsh']\n",
      "- **Function**\n",
      "  - `id`: STRING Example: \"Utils.Utils.Split_Dict\"\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Class)-[:INCLUDES]->(:Method)\n",
      "(:Class)-[:USES]->(:Package)\n",
      "(:Class)-[:CONTAINS]->(:Method)\n",
      "(:Class)-[:INHERITS]->(:Class)\n",
      "(:Class)-[:DEFINES]->(:Method)\n",
      "(:Class)-[:IMPORTS]->(:Package)\n",
      "(:Class)-[:METHOD_OF]->(:Method)\n",
      "(:Class)-[:DEFINED_IN]->(:Module)\n",
      "(:Class)-[:DEFINED_IN]->(:Method)\n",
      "(:Method)-[:USES]->(:Package)\n",
      "(:Method)-[:USES]->(:Method)\n",
      "(:Method)-[:USES]->(:Module)\n",
      "(:Method)-[:USES]->(:Function)\n",
      "(:Method)-[:USED_IN]->(:Function)\n",
      "(:Method)-[:USED_IN]->(:Package)\n",
      "(:Method)-[:CALLS]->(:Method)\n",
      "(:Method)-[:CALLS]->(:Function)\n",
      "(:Method)-[:READS]->(:Class)\n",
      "(:Method)-[:PROCESSES]->(:Class)\n",
      "(:Method)-[:INITIALIZES]->(:Class)\n",
      "(:Method)-[:INITIALIZES]->(:Function)\n",
      "(:Method)-[:DEFINED_IN]->(:Class)\n",
      "(:Module)-[:CONTAINS]->(:Class)\n",
      "(:Module)-[:USES]->(:Package)\n",
      "(:Module)-[:DEFINES]->(:Function)\n",
      "(:Module)-[:DEFINES]->(:Method)\n",
      "(:Module)-[:IMPORTS]->(:Class)\n",
      "(:Module)-[:IMPORTS]->(:Function)\n",
      "(:Module)-[:IMPORTS]->(:Package)\n",
      "(:Module)-[:CALLS]->(:Function)\n",
      "(:Function)-[:USES]->(:Package)\n",
      "(:Function)-[:USES]->(:Class)\n",
      "(:Function)-[:USES]->(:Function)\n",
      "(:Function)-[:USES]->(:Module)\n",
      "(:Function)-[:CALLS]->(:Class)\n",
      "(:Function)-[:DEFINED_IN]->(:Module)\n",
      "(:Function)-[:USED_IN]->(:Package)\n"
     ]
    }
   ],
   "source": [
    "enhanced_graph = Neo4jGraph(enhanced_schema=True)\n",
    "print(enhanced_graph.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement GRAPH-RAG\n",
    "https://python.langchain.com/v0.1/docs/use_cases/graph/prompting/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual GraphRAG Chain**\n",
    "\n",
    "https://python.langchain.com/docs/tutorials/graph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How is the Utils.Utils module related to the Deduplicatioin.__Main__ module?',\n",
       " 'result': \"I don't know the answer.\"}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_neo4j import GraphCypherQAChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.graph_qa.prompts import CYPHER_GENERATION_PROMPT, CYPHER_QA_PROMPT\n",
    "\n",
    "\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "cypher_prompt = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Translate user input into available nodes.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "\n",
    "Guidelines:\n",
    "Always try and use MATCH path ..... RETURN path to get the entire relationship and do not gnenerate query that returns paris of nodes.\n",
    "Never use relationships that include packages : WHERE NONE(n IN nodes(path) WHERE n:Package)\n",
    "\n",
    "Example:\n",
    "Question : \"How is the Utils.Utils module related to the Deduplicatioin.__Main__ module?\"\n",
    "Cypher Query : MATCH path = (m1:Module {{id: 'Utils.Utils'}})-[*..8]-(m2:Module {{id: 'Deduplication.__Main__'}}) WHERE NONE(n IN nodes(path) WHERE n:Package) RETURN path\n",
    "\n",
    "\n",
    "The question is:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(cypher_prompt)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    graph=enhanced_graph, \n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True, \n",
    "    validate_cypher=True,\n",
    "    # cypher_prompt=prompt\n",
    ")\n",
    "response = chain.invoke({\"query\": \"How is the Utils.Utils module related to the Deduplicatioin.__Main__ module?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = graph.query(\"\"\"\n",
    "MATCH path = allShortestPaths(\n",
    "  (m1:Module {id: 'Utils.Utils'})-[*..8]-(m2:Module {id: 'Deduplication.__Main__'})\n",
    ")\n",
    "WHERE NONE(n IN nodes(path) WHERE n:Package)\n",
    "RETURN path\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'DEFINES',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'CALLS',\n",
       "   {'id': 'Deduplication.__Main__.Model'},\n",
       "   'DEFINES',\n",
       "   {'id': 'Deduplication.__Main__'}]},\n",
       " {'path': [{'id': 'Utils.Utils'},\n",
       "   'USES',\n",
       "   {'id': 'Deduplication.Lsh.Lsh.Compute_Minhash_Signatures'},\n",
       "   'CONTAINS',\n",
       "   {'id': 'Deduplication.Lsh.Lsh'},\n",
       "   'INHERITS',\n",
       "   {'id': 'Deduplication.Lshforest.Lshforest'},\n",
       "   'IMPORTS',\n",
       "   {'id': 'Deduplication.__Main__'}]}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant that helps to form nice and human understandable answers.\n",
      "The information part contains the provided information that you must use to construct an answer.\n",
      "The provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
      "Make the answer sound as a response to the question. Do not mention that you based the result on the given information.\n",
      "Here is an example:\n",
      "\n",
      "Question: Which managers own Neo4j stocks?\n",
      "Context:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\n",
      "Helpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\n",
      "\n",
      "Follow this example when generating answers.\n",
      "If the provided information is empty, say that you don't know the answer.\n",
      "Information:\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "print(CYPHER_QA_PROMPT.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
